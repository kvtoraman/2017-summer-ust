{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification of text documents using sparse features\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#\t\t  Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#\t\t  Mathieu Blondel <mathieu@mblondel.org>\n",
    "#\t\t  Lars Buitinck\n",
    "# Updated by: Kisti\n",
    "# Finalized by: Kamil Veli TORAMAN <kvtoraman@kaist.ac.kr>\n",
    "# 23 August 2017\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import nltk.stem\n",
    "from optparse import OptionParser\n",
    "import sys, copy\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def transform_label(clf, prob, topk):\n",
    "    rst_arr = np.empty( (len(prob), topk), dtype=object) \n",
    "    for i in range(len(prob)):\n",
    "        s_items = np.argsort(prob[i])[-topk:]\n",
    "\n",
    "        for j in range(len(s_items)):\n",
    "            rst_arr[i][j] = clf.classes_[s_items[j]]\n",
    "    return rst_arr\n",
    "\n",
    "def apk_per_class(actual, predicted, k=1):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items per each class\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : multi list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    class_score = {}\n",
    "    micro_correct = 0.0\n",
    "    length = 0\n",
    "    global cumulative_class_score\n",
    "    if len(actual) == len(predicted):\n",
    "\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] not in class_score:\n",
    "                class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "            if actual[i] not in cumulative_class_score:\n",
    "                cumulative_class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "             \n",
    "            well_classified = False\n",
    "            for pred in predicted[i]:\n",
    "                if actual[i] == pred:\n",
    "                    class_score[actual[i]][0] += 1.0\n",
    "                    micro_correct += 1.0\n",
    "                    well_classified = True\n",
    "                    \n",
    "            if(actual[i] == CODE and well_classified == False):\n",
    "                print(well_classified , \"docID:\",i,\"prediction of \",CODE,\" was:\",predicted[i])\n",
    "                fail_list_for_code.append(i)\n",
    "            class_score[actual[i]][1] += 1.0\n",
    "            length+=1\n",
    "\n",
    "    avg_acc = 0.0 \n",
    "    for cl in class_score.keys():\n",
    "        avg = class_score[cl][0]/class_score[cl][1]\n",
    "        if(avg<0.5 and count[cl]-class_score[cl][1] > class_score[cl][1]):\n",
    "            print(\"!Low precision :! #Correct:\", class_score[cl][0], \"#Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "            fail_list.append(cl)\n",
    "        print (\"\\t\", cl, \"Acc.:\", avg, \"Correct:\", class_score[cl][0], \"Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "        cumulative_class_score[cl][0] += class_score[cl][0]\n",
    "        cumulative_class_score[cl][1] += class_score[cl][1]\n",
    "        \n",
    "        avg_acc +=avg\n",
    "\n",
    "    print ('Total Test Examples', length, \"\\nMicro Acc.(item level)\", micro_correct/length)\n",
    "    global cumulative_micro_avg\n",
    "    cumulative_micro_avg += micro_correct/length\n",
    "    return avg_acc/len(class_score)\n",
    "\n",
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    pred = clf.predict(X_test)\t  \n",
    "    probs = clf.predict_proba(X_test)\n",
    "\n",
    "    #Right now, it only uses top-5\n",
    "    for topk in range(5, 6):\n",
    "        best_n_label = transform_label(clf, probs, topk)\n",
    "\n",
    "        test_time = time() - t0\n",
    "        print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "        pred = best_n_label\n",
    "        print (\"Top-\", topk)\n",
    "        print (\"Macro Acc.(class level)\", apk_per_class(y_test, best_n_label, topk), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NSCC\t dataset for categories:\n",
      "['EA99', 'EI02', 'EI03', 'EI01', 'EI06', 'EI07', 'EI04', 'EI05', 'EG08', 'EI08', 'EI09', 'EG09', 'EA08', 'EA09', 'EA02', 'EA03', 'EA01', 'EA06', 'EA07', 'EA04', 'EA05', 'EC10', 'EE99', 'EB08', 'EF99', 'EI11', 'EI10', 'EI12', 'EA15', 'EA14', 'EA11', 'EA10', 'EA13', 'EB99', 'EA12', 'EE08', 'EE09', 'EE06', 'EE07', 'EE04', 'EE05', 'EE02', 'EE03', 'EE01', 'EB01', 'EB03', 'EB02', 'EB05', 'EB04', 'EB07', 'EB06', 'EE11', 'EE10', 'EE13', 'EE12', 'EI99', 'EE14', 'EC08', 'EC09', 'EC01', 'EC02', 'EC03', 'EC04', 'EC05', 'EC06', 'EC07', 'EF05', 'EF04', 'EF06', 'EF01', 'EF03', 'EF02', 'ED10', 'ED11', 'EG04', 'EG05', 'EG06', 'EG07', 'EG01', 'EG02', 'EG03', 'ED07', 'ED06', 'ED05', 'ED04', 'ED03', 'ED02', 'ED01', 'ED09', 'ED08', 'EH10', 'EH11', 'EH12', 'EH13', 'EH14', 'EH15', 'EG99', 'EC99', 'ED99', 'EC11', 'EH09', 'EH08', 'EH03', 'EH02', 'EH01', 'EH07', 'EH06', 'EH05', 'EH04', 'EH99', 'EG10']\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################\n",
    "### Define train/test/code list files \n",
    "#################################################################\n",
    "code_list_fn = \"NSCC_sample_data_170309_Codelist.dat\"\n",
    "train_fn = \"rev_utf8_train_big.dat\"\n",
    "test_fn = \"test_5500_from_izip_all_kkma_1col.dat\"\n",
    "all_fn ='kkma_koreanonly_withsentencebreaker_3col.dat'\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "categories =  [x for x in open(code_list_fn,'r').read().split('\\n') if len(x) > 0]\n",
    "\n",
    "print(\"Loading NSCC\t dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "print(len(categories))\n",
    "\n",
    "data_train = open(train_fn).readlines()\n",
    "data_test = open(test_fn).readlines()\n",
    "all_data = open(all_fn).readlines()\n",
    "\n",
    "data_train_data, data_test_data = [], []\n",
    "y_train, y_test = [], []\n",
    "all_x, all_y = [], []\n",
    "count = {}\n",
    "\n",
    "for cat in categories:\n",
    "    count[cat] = 0\n",
    "\n",
    "for line in all_data:\n",
    "    #Shape of training file:CODE + '\\t' + name + ' %% ' + kor_kywd + ' %% ' + goal + ' %% ' + abstract + ' %% ' + efct\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        #if document code is not E, ignore that\n",
    "        if(items[0][0] != 'E'): \n",
    "            continue\n",
    "        items[1] = items[1].split('%%') \n",
    "        occur_many_times = \"\"\n",
    "        occur_many_times += items[1][0]*1 + \" \"\n",
    "        occur_many_times += items[1][1]*1 + \" \"\n",
    "        items[1] =occur_many_times + ' '.join(items[1][2:])\n",
    "        all_x.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        all_y.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print('ERROR IN READING')\n",
    "    \"\"\"\n",
    "for line in data_train:\n",
    "\titems = line.split('\\t')\n",
    "\tif len(items) == 2:\n",
    "\t\tdata_train_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "\t\ty_train.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "for line in data_test:\n",
    "\titems = line.split('\\t')\n",
    "\tif len(items) == 2:\n",
    "\t\tdata_test_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "\t\ty_test.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    \"\"\"\n",
    "\n",
    "#divides data to train&test with 9:1 ratio\n",
    "def divide_data(r_s):\n",
    "    global data_train_data,data_test_data,y_train,y_test\n",
    "    data_train_data,data_test_data,y_train,y_test = train_test_split(all_x,all_y,random_state =r_s, train_size = 0.9)\n",
    "    #trash_a,data_test_data,trash_b,y_test = train_test_split(all_x,all_y,random_state =1, train_size = 0.60)\n",
    "    print (len(data_train_data), len(data_test_data))\n",
    "    print('data loaded')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = 0\n",
    "X_train,X_test = 0,0\n",
    "#vectorize training data using tfidf vectorizer\n",
    "def vectorize():\n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "    t0 = time()\n",
    "    my_stop_words = [unicode(x.strip(), 'utf-8') for x in open('kor_stop_word.txt','r').read().split('\\n')]\n",
    "\n",
    "    #print (len(data_train_data))\n",
    "    global vectorizer,X_train,X_test\n",
    "    #vectorizer = StemmedTfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 200000,min_df=5)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 200000,min_df=5,ngram_range=(1,1))\n",
    "    X_train = vectorizer.fit_transform(data_train_data)\n",
    "\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "    \n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "    X_test = vectorizer.transform(data_test_data)\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 R_s 5\n",
      "54297 6033\n",
      "data loaded\n",
      "Vectorizing:  5\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 54297, n_features: 76989\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 6033, n_features: 76989\n",
      "Learning:  5\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=10, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 29.145s\n",
      "test time:  0.396s\n",
      "Top- 5\n",
      "False docID: 551 prediction of  ED99  was: ['EF99' 'EB03' 'EA02' 'EA09' 'ED05']\n",
      "False docID: 1180 prediction of  ED99  was: ['EC07' 'ED01' 'ED08' 'EA09' 'ED06']\n",
      "False docID: 1415 prediction of  ED99  was: ['ED05' 'EB05' 'EB03' 'EB06' 'EB01']\n",
      "False docID: 1668 prediction of  ED99  was: ['ED06' 'EE07' 'EE99' 'EE11' 'EE02']\n",
      "False docID: 1883 prediction of  ED99  was: ['EC04' 'EB03' 'ED07' 'EA06' 'ED04']\n",
      "False docID: 1897 prediction of  ED99  was: ['EH06' 'EI08' 'ED05' 'ED03' 'EA10']\n",
      "False docID: 2212 prediction of  ED99  was: ['ED06' 'EE09' 'EE06' 'EE10' 'EE02']\n",
      "False docID: 2502 prediction of  ED99  was: ['ED06' 'EF99' 'EB02' 'EB01' 'ED04']\n",
      "False docID: 2598 prediction of  ED99  was: ['EF04' 'EF99' 'EB02' 'EB01' 'ED04']\n",
      "False docID: 2702 prediction of  ED99  was: ['ED06' 'EF99' 'EE02' 'EA07' 'EE09']\n",
      "False docID: 2755 prediction of  ED99  was: ['EA02' 'EE06' 'ED10' 'EE09' 'ED02']\n",
      "False docID: 2992 prediction of  ED99  was: ['EA03' 'ED07' 'ED05' 'EA10' 'ED08']\n",
      "False docID: 3216 prediction of  ED99  was: ['EB06' 'EF99' 'EE02' 'EA02' 'EA09']\n",
      "False docID: 3294 prediction of  ED99  was: ['EF04' 'EA02' 'EA08' 'EE09' 'EA05']\n",
      "False docID: 3345 prediction of  ED99  was: ['EA03' 'ED10' 'EE10' 'EE02' 'ED01']\n",
      "False docID: 4154 prediction of  ED99  was: ['EI12' 'ED05' 'EF05' 'ED09' 'EF06']\n",
      "False docID: 4827 prediction of  ED99  was: ['EA09' 'EI10' 'ED03' 'ED05' 'EF99']\n",
      "False docID: 4985 prediction of  ED99  was: ['ED04' 'EA06' 'EB01' 'EB03' 'EC02']\n",
      "False docID: 5461 prediction of  ED99  was: ['ED10' 'EB01' 'EA99' 'EB99' 'EF99']\n",
      "False docID: 5695 prediction of  ED99  was: ['EE07' 'EA01' 'ED08' 'EE02' 'EE99']\n",
      "False docID: 5720 prediction of  ED99  was: ['EB06' 'ED05' 'ED04' 'EB01' 'EF06']\n",
      "False docID: 5954 prediction of  ED99  was: ['EE14' 'EE01' 'ED08' 'EE02' 'EE03']\n",
      "!Low precision :! #Correct: 15.0 #Tested: 35.0 #Train 357.0\n",
      "\t EA99 Acc.: 0.428571428571 Correct: 15.0 Tested: 35.0 #Train 357.0\n",
      "\t EI02 Acc.: 0.857142857143 Correct: 18.0 Tested: 21.0 #Train 255.0\n",
      "\t EI03 Acc.: 0.9375 Correct: 90.0 Tested: 96.0 #Train 878.0\n",
      "\t EI01 Acc.: 0.964285714286 Correct: 27.0 Tested: 28.0 #Train 213.0\n",
      "\t EI06 Acc.: 0.978260869565 Correct: 45.0 Tested: 46.0 #Train 261.0\n",
      "\t EI07 Acc.: 1.0 Correct: 6.0 Tested: 6.0 #Train 52.0\n",
      "\t EI04 Acc.: 0.990909090909 Correct: 109.0 Tested: 110.0 #Train 899.0\n",
      "\t EI05 Acc.: 1.0 Correct: 31.0 Tested: 31.0 #Train 316.0\n",
      "\t EG08 Acc.: 1.0 Correct: 10.0 Tested: 10.0 #Train 118.0\n",
      "\t EI08 Acc.: 0.842105263158 Correct: 16.0 Tested: 19.0 #Train 87.0\n",
      "\t EI09 Acc.: 0.928571428571 Correct: 26.0 Tested: 28.0 #Train 344.0\n",
      "\t EG09 Acc.: 0.944444444444 Correct: 17.0 Tested: 18.0 #Train 117.0\n",
      "\t EA08 Acc.: 0.731958762887 Correct: 71.0 Tested: 97.0 #Train 785.0\n",
      "\t EA09 Acc.: 0.935960591133 Correct: 190.0 Tested: 203.0 #Train 1598.0\n",
      "\t EA02 Acc.: 0.833333333333 Correct: 85.0 Tested: 102.0 #Train 870.0\n",
      "\t EA03 Acc.: 0.805194805195 Correct: 62.0 Tested: 77.0 #Train 712.0\n",
      "\t EA01 Acc.: 0.786885245902 Correct: 48.0 Tested: 61.0 #Train 531.0\n",
      "\t EA06 Acc.: 0.875 Correct: 77.0 Tested: 88.0 #Train 761.0\n",
      "\t EA07 Acc.: 0.830357142857 Correct: 93.0 Tested: 112.0 #Train 1046.0\n",
      "\t EA04 Acc.: 0.88 Correct: 66.0 Tested: 75.0 #Train 621.0\n",
      "\t EA05 Acc.: 0.931972789116 Correct: 137.0 Tested: 147.0 #Train 1306.0\n",
      "\t EC10 Acc.: 0.714285714286 Correct: 5.0 Tested: 7.0 #Train 45.0\n",
      "\t EE99 Acc.: 0.752941176471 Correct: 64.0 Tested: 85.0 #Train 774.0\n",
      "\t EB08 Acc.: 0.75 Correct: 6.0 Tested: 8.0 #Train 101.0\n",
      "\t EF99 Acc.: 0.771428571429 Correct: 54.0 Tested: 70.0 #Train 657.0\n",
      "\t EI11 Acc.: 0.943396226415 Correct: 50.0 Tested: 53.0 #Train 567.0\n",
      "\t EI10 Acc.: 1.0 Correct: 12.0 Tested: 12.0 #Train 130.0\n",
      "\t EI12 Acc.: 0.925925925926 Correct: 50.0 Tested: 54.0 #Train 490.0\n",
      "\t EA15 Acc.: 0.789473684211 Correct: 15.0 Tested: 19.0 #Train 132.0\n",
      "\t EA14 Acc.: 0.727272727273 Correct: 16.0 Tested: 22.0 #Train 236.0\n",
      "\t EA11 Acc.: 0.878048780488 Correct: 36.0 Tested: 41.0 #Train 334.0\n",
      "\t EA10 Acc.: 0.969387755102 Correct: 95.0 Tested: 98.0 #Train 917.0\n",
      "\t EA13 Acc.: 0.944444444444 Correct: 17.0 Tested: 18.0 #Train 194.0\n",
      "\t EB99 Acc.: 0.54 Correct: 27.0 Tested: 50.0 #Train 398.0\n",
      "\t EA12 Acc.: 0.8 Correct: 12.0 Tested: 15.0 #Train 133.0\n",
      "\t EE08 Acc.: 0.714285714286 Correct: 15.0 Tested: 21.0 #Train 258.0\n",
      "\t EE09 Acc.: 0.761904761905 Correct: 32.0 Tested: 42.0 #Train 583.0\n",
      "\t EE06 Acc.: 0.88 Correct: 66.0 Tested: 75.0 #Train 742.0\n",
      "\t EE07 Acc.: 0.875 Correct: 21.0 Tested: 24.0 #Train 255.0\n",
      "\t EE04 Acc.: 0.848484848485 Correct: 28.0 Tested: 33.0 #Train 277.0\n",
      "\t EE05 Acc.: 1.0 Correct: 14.0 Tested: 14.0 #Train 274.0\n",
      "\t EE02 Acc.: 0.937304075235 Correct: 299.0 Tested: 319.0 #Train 2829.0\n",
      "\t EE03 Acc.: 0.973333333333 Correct: 73.0 Tested: 75.0 #Train 754.0\n",
      "\t EE01 Acc.: 0.906432748538 Correct: 155.0 Tested: 171.0 #Train 1532.0\n",
      "\t EB01 Acc.: 0.868055555556 Correct: 125.0 Tested: 144.0 #Train 1386.0\n",
      "\t EB03 Acc.: 0.886597938144 Correct: 172.0 Tested: 194.0 #Train 1586.0\n",
      "\t EB02 Acc.: 0.901515151515 Correct: 119.0 Tested: 132.0 #Train 1190.0\n",
      "\t EB05 Acc.: 0.766666666667 Correct: 23.0 Tested: 30.0 #Train 280.0\n",
      "\t EB04 Acc.: 0.794117647059 Correct: 27.0 Tested: 34.0 #Train 228.0\n",
      "\t EB07 Acc.: 0.787878787879 Correct: 26.0 Tested: 33.0 #Train 318.0\n",
      "\t EB06 Acc.: 0.763636363636 Correct: 42.0 Tested: 55.0 #Train 473.0\n",
      "\t EE11 Acc.: 0.820512820513 Correct: 64.0 Tested: 78.0 #Train 639.0\n",
      "\t EE10 Acc.: 0.837209302326 Correct: 36.0 Tested: 43.0 #Train 507.0\n",
      "\t EE13 Acc.: 0.8 Correct: 16.0 Tested: 20.0 #Train 251.0\n",
      "\t EE12 Acc.: 0.869565217391 Correct: 20.0 Tested: 23.0 #Train 215.0\n",
      "\t EI99 Acc.: 0.689655172414 Correct: 20.0 Tested: 29.0 #Train 301.0\n",
      "\t EE14 Acc.: 0.636363636364 Correct: 7.0 Tested: 11.0 #Train 145.0\n",
      "\t EC08 Acc.: 0.9 Correct: 9.0 Tested: 10.0 #Train 85.0\n",
      "\t EC09 Acc.: 0.941176470588 Correct: 48.0 Tested: 51.0 #Train 411.0\n",
      "\t EC01 Acc.: 0.929577464789 Correct: 66.0 Tested: 71.0 #Train 664.0\n",
      "\t EC02 Acc.: 0.905660377358 Correct: 96.0 Tested: 106.0 #Train 958.0\n",
      "\t EC03 Acc.: 0.833333333333 Correct: 50.0 Tested: 60.0 #Train 461.0\n",
      "\t EC04 Acc.: 0.911111111111 Correct: 41.0 Tested: 45.0 #Train 375.0\n",
      "\t EC05 Acc.: 0.765957446809 Correct: 36.0 Tested: 47.0 #Train 416.0\n",
      "\t EC06 Acc.: 0.730769230769 Correct: 19.0 Tested: 26.0 #Train 196.0\n",
      "\t EC07 Acc.: 0.939393939394 Correct: 31.0 Tested: 33.0 #Train 251.0\n",
      "\t EF05 Acc.: 0.950819672131 Correct: 58.0 Tested: 61.0 #Train 470.0\n",
      "\t EF04 Acc.: 0.78125 Correct: 25.0 Tested: 32.0 #Train 317.0\n",
      "\t EF06 Acc.: 0.987234042553 Correct: 232.0 Tested: 235.0 #Train 2219.0\n",
      "\t EF01 Acc.: 0.869565217391 Correct: 20.0 Tested: 23.0 #Train 256.0\n",
      "\t EF03 Acc.: 0.785714285714 Correct: 11.0 Tested: 14.0 #Train 201.0\n",
      "\t EF02 Acc.: 0.821428571429 Correct: 23.0 Tested: 28.0 #Train 286.0\n",
      "\t ED10 Acc.: 0.85393258427 Correct: 76.0 Tested: 89.0 #Train 819.0\n",
      "\t ED11 Acc.: 0.777777777778 Correct: 28.0 Tested: 36.0 #Train 346.0\n",
      "\t EG04 Acc.: 0.918918918919 Correct: 34.0 Tested: 37.0 #Train 334.0\n",
      "\t EG05 Acc.: 0.882352941176 Correct: 15.0 Tested: 17.0 #Train 125.0\n",
      "\t EG06 Acc.: 1.0 Correct: 23.0 Tested: 23.0 #Train 196.0\n",
      "\t EG07 Acc.: 1.0 Correct: 63.0 Tested: 63.0 #Train 541.0\n",
      "\t EG01 Acc.: 1.0 Correct: 7.0 Tested: 7.0 #Train 107.0\n",
      "\t EG02 Acc.: 0.904761904762 Correct: 19.0 Tested: 21.0 #Train 151.0\n",
      "\t EG03 Acc.: 0.875 Correct: 14.0 Tested: 16.0 #Train 135.0\n",
      "\t ED07 Acc.: 0.846153846154 Correct: 55.0 Tested: 65.0 #Train 573.0\n",
      "\t ED06 Acc.: 0.878048780488 Correct: 72.0 Tested: 82.0 #Train 616.0\n",
      "\t ED05 Acc.: 0.77358490566 Correct: 82.0 Tested: 106.0 #Train 876.0\n",
      "\t ED04 Acc.: 0.923076923077 Correct: 180.0 Tested: 195.0 #Train 1586.0\n",
      "\t ED03 Acc.: 0.928571428571 Correct: 91.0 Tested: 98.0 #Train 787.0\n",
      "\t ED02 Acc.: 0.820512820513 Correct: 32.0 Tested: 39.0 #Train 353.0\n",
      "\t ED01 Acc.: 0.863157894737 Correct: 82.0 Tested: 95.0 #Train 917.0\n",
      "\t ED09 Acc.: 0.915254237288 Correct: 54.0 Tested: 59.0 #Train 462.0\n",
      "\t EG10 Acc.: 1.0 Correct: 17.0 Tested: 17.0 #Train 159.0\n",
      "\t EH10 Acc.: 0.916666666667 Correct: 22.0 Tested: 24.0 #Train 214.0\n",
      "\t EH11 Acc.: 0.608695652174 Correct: 14.0 Tested: 23.0 #Train 209.0\n",
      "\t EH12 Acc.: 0.6 Correct: 9.0 Tested: 15.0 #Train 123.0\n",
      "\t EH13 Acc.: 0.833333333333 Correct: 10.0 Tested: 12.0 #Train 145.0\n",
      "\t EH14 Acc.: 0.5 Correct: 4.0 Tested: 8.0 #Train 93.0\n",
      "\t EH15 Acc.: 1.0 Correct: 3.0 Tested: 3.0 #Train 34.0\n",
      "\t EG99 Acc.: 0.914893617021 Correct: 43.0 Tested: 47.0 #Train 371.0\n",
      "\t EC99 Acc.: 0.5 Correct: 5.0 Tested: 10.0 #Train 93.0\n",
      "\t ED99 Acc.: 0.592592592593 Correct: 32.0 Tested: 54.0 #Train 610.0\n",
      "\t EC11 Acc.: 1.0 Correct: 2.0 Tested: 2.0 #Train 28.0\n",
      "\t EH09 Acc.: 0.911764705882 Correct: 31.0 Tested: 34.0 #Train 284.0\n",
      "\t EH08 Acc.: 0.785714285714 Correct: 11.0 Tested: 14.0 #Train 146.0\n",
      "\t EH03 Acc.: 0.857142857143 Correct: 18.0 Tested: 21.0 #Train 229.0\n",
      "\t EH02 Acc.: 0.925925925926 Correct: 75.0 Tested: 81.0 #Train 731.0\n",
      "\t EH01 Acc.: 0.925925925926 Correct: 50.0 Tested: 54.0 #Train 439.0\n",
      "\t EH07 Acc.: 0.954545454545 Correct: 42.0 Tested: 44.0 #Train 479.0\n",
      "\t EH06 Acc.: 0.954545454545 Correct: 21.0 Tested: 22.0 #Train 251.0\n",
      "!Low precision :! #Correct: 2.0 #Tested: 5.0 #Train 67.0\n",
      "\t EH05 Acc.: 0.4 Correct: 2.0 Tested: 5.0 #Train 67.0\n",
      "\t EH04 Acc.: 1.0 Correct: 10.0 Tested: 10.0 #Train 152.0\n",
      "\t EH99 Acc.: 0.818181818182 Correct: 18.0 Tested: 22.0 #Train 188.0\n",
      "\t ED08 Acc.: 0.898305084746 Correct: 53.0 Tested: 59.0 #Train 504.0\n",
      "Total Test Examples 6033 \n",
      "Micro Acc.(item level) 0.875517984419\n",
      "Macro Acc.(class level) 0.850629801942 \n",
      "\n",
      "\n",
      "Trial: 1 R_s 6\n",
      "54297 6033\n",
      "data loaded\n",
      "Vectorizing:  6\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 54297, n_features: 77131\n",
      "Extracting features from the training data using a sparse vectorizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 6033, n_features: 77131\n",
      "Learning:  6\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=10, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 26.956s\n",
      "test time:  0.359s\n",
      "Top- 5\n",
      "False docID: 54 prediction of  ED99  was: ['EB02' 'EI05' 'EI04' 'EF05' 'EF06']\n",
      "False docID: 81 prediction of  ED99  was: ['EE99' 'EE06' 'EE04' 'EE11' 'EE02']\n",
      "False docID: 245 prediction of  ED99  was: ['EA09' 'EA07' 'EB06' 'ED01' 'ED06']\n",
      "False docID: 487 prediction of  ED99  was: ['EE09' 'EI11' 'EA14' 'EE13' 'EE02']\n",
      "False docID: 738 prediction of  ED99  was: ['ED03' 'EE11' 'ED07' 'EE02' 'ED10']\n",
      "False docID: 959 prediction of  ED99  was: ['EI09' 'EF03' 'EA07' 'EI03' 'EF06']\n",
      "False docID: 1188 prediction of  ED99  was: ['ED05' 'ED04' 'EE05' 'ED11' 'EA09']\n",
      "False docID: 1372 prediction of  ED99  was: ['ED03' 'EE04' 'EE06' 'EE01' 'ED11']\n",
      "False docID: 1375 prediction of  ED99  was: ['EI99' 'EE01' 'EE99' 'EA09' 'ED08']\n",
      "False docID: 1445 prediction of  ED99  was: ['EF04' 'EB01' 'EE03' 'EI11' 'EA14']\n",
      "False docID: 2464 prediction of  ED99  was: ['ED05' 'ED04' 'ED01' 'ED06' 'ED03']\n",
      "False docID: 2684 prediction of  ED99  was: ['ED11' 'ED07' 'ED08' 'EA09' 'EE02']\n",
      "False docID: 2774 prediction of  ED99  was: ['EE11' 'EB06' 'EE02' 'EA02' 'EA09']\n",
      "False docID: 3124 prediction of  ED99  was: ['EI11' 'EE14' 'EE08' 'EE10' 'EE02']\n",
      "False docID: 3399 prediction of  ED99  was: ['ED05' 'EA06' 'EE01' 'EA02' 'ED04']\n",
      "False docID: 3887 prediction of  ED99  was: ['ED05' 'EA09' 'ED01' 'EA11' 'ED07']\n",
      "False docID: 3998 prediction of  ED99  was: ['EE09' 'EE06' 'ED08' 'EE12' 'EE02']\n",
      "False docID: 4388 prediction of  ED99  was: ['EC02' 'EF99' 'EG99' 'ED11' 'EE02']\n",
      "False docID: 4406 prediction of  ED99  was: ['EF05' 'EA08' 'EE04' 'EF99' 'EA07']\n",
      "False docID: 4522 prediction of  ED99  was: ['EA02' 'ED10' 'EB06' 'EB03' 'EA01']\n",
      "False docID: 4567 prediction of  ED99  was: ['EA07' 'EB02' 'EA09' 'EA08' 'ED06']\n",
      "False docID: 4574 prediction of  ED99  was: ['ED05' 'EF99' 'EA07' 'ED03' 'EA09']\n",
      "False docID: 4760 prediction of  ED99  was: ['EE99' 'ED04' 'ED05' 'ED06' 'EE06']\n",
      "False docID: 4792 prediction of  ED99  was: ['EA05' 'EE14' 'ED11' 'ED09' 'EA15']\n",
      "False docID: 4804 prediction of  ED99  was: ['EA09' 'EB06' 'ED01' 'ED05' 'EB02']\n",
      "False docID: 4820 prediction of  ED99  was: ['EA05' 'EA07' 'EC11' 'EA03' 'ED07']\n",
      "False docID: 5197 prediction of  ED99  was: ['ED07' 'EA01' 'ED05' 'EA05' 'EA08']\n",
      "False docID: 5367 prediction of  ED99  was: ['EE11' 'EE09' 'ED06' 'EE10' 'EE02']\n",
      "False docID: 5556 prediction of  ED99  was: ['EC07' 'ED03' 'EA07' 'ED06' 'EF06']\n",
      "False docID: 5826 prediction of  ED99  was: ['EA01' 'EA03' 'ED05' 'EB02' 'EA09']\n",
      "False docID: 5911 prediction of  ED99  was: ['EE11' 'EA02' 'EE01' 'ED11' 'EA05']\n",
      "\t EA99 Acc.: 0.581395348837 Correct: 25.0 Tested: 43.0 #Train 349.0\n",
      "\t EI02 Acc.: 0.8 Correct: 24.0 Tested: 30.0 #Train 246.0\n",
      "\t EI03 Acc.: 0.98 Correct: 98.0 Tested: 100.0 #Train 874.0\n",
      "\t EI01 Acc.: 0.965517241379 Correct: 28.0 Tested: 29.0 #Train 212.0\n",
      "\t EI06 Acc.: 1.0 Correct: 19.0 Tested: 19.0 #Train 288.0\n",
      "\t EI07 Acc.: 1.0 Correct: 2.0 Tested: 2.0 #Train 56.0\n",
      "\t EI04 Acc.: 0.987654320988 Correct: 80.0 Tested: 81.0 #Train 928.0\n",
      "\t EI05 Acc.: 0.967741935484 Correct: 30.0 Tested: 31.0 #Train 316.0\n",
      "\t ED10 Acc.: 0.905263157895 Correct: 86.0 Tested: 95.0 #Train 813.0\n",
      "\t EI08 Acc.: 1.0 Correct: 11.0 Tested: 11.0 #Train 95.0\n",
      "\t EI09 Acc.: 1.0 Correct: 38.0 Tested: 38.0 #Train 334.0\n",
      "\t ED11 Acc.: 0.837837837838 Correct: 31.0 Tested: 37.0 #Train 345.0\n",
      "\t EA08 Acc.: 0.752808988764 Correct: 67.0 Tested: 89.0 #Train 793.0\n",
      "\t EA09 Acc.: 0.948863636364 Correct: 167.0 Tested: 176.0 #Train 1625.0\n",
      "\t EA02 Acc.: 0.778947368421 Correct: 74.0 Tested: 95.0 #Train 877.0\n",
      "\t EA03 Acc.: 0.841463414634 Correct: 69.0 Tested: 82.0 #Train 707.0\n",
      "\t EA01 Acc.: 0.75 Correct: 30.0 Tested: 40.0 #Train 552.0\n",
      "\t EA06 Acc.: 0.883720930233 Correct: 76.0 Tested: 86.0 #Train 763.0\n",
      "\t EA07 Acc.: 0.821782178218 Correct: 83.0 Tested: 101.0 #Train 1057.0\n",
      "\t EA04 Acc.: 0.786666666667 Correct: 59.0 Tested: 75.0 #Train 621.0\n",
      "\t EA05 Acc.: 0.907894736842 Correct: 138.0 Tested: 152.0 #Train 1301.0\n",
      "\t EG07 Acc.: 0.963636363636 Correct: 53.0 Tested: 55.0 #Train 549.0\n",
      "\t EE99 Acc.: 0.76404494382 Correct: 68.0 Tested: 89.0 #Train 770.0\n",
      "\t EE10 Acc.: 0.777777777778 Correct: 42.0 Tested: 54.0 #Train 496.0\n",
      "\t EF99 Acc.: 0.692307692308 Correct: 45.0 Tested: 65.0 #Train 662.0\n",
      "\t EI11 Acc.: 0.876923076923 Correct: 57.0 Tested: 65.0 #Train 555.0\n",
      "\t EI10 Acc.: 1.0 Correct: 14.0 Tested: 14.0 #Train 128.0\n",
      "\t EI12 Acc.: 0.98 Correct: 49.0 Tested: 50.0 #Train 494.0\n",
      "\t EA15 Acc.: 0.642857142857 Correct: 9.0 Tested: 14.0 #Train 137.0\n",
      "\t EA14 Acc.: 0.710526315789 Correct: 27.0 Tested: 38.0 #Train 220.0\n",
      "\t EA11 Acc.: 0.882352941176 Correct: 30.0 Tested: 34.0 #Train 341.0\n",
      "\t EA10 Acc.: 0.983050847458 Correct: 116.0 Tested: 118.0 #Train 897.0\n",
      "\t EA13 Acc.: 0.95 Correct: 19.0 Tested: 20.0 #Train 192.0\n",
      "\t EA12 Acc.: 1.0 Correct: 13.0 Tested: 13.0 #Train 135.0\n",
      "\t EB99 Acc.: 0.617021276596 Correct: 29.0 Tested: 47.0 #Train 401.0\n",
      "\t EE08 Acc.: 0.689655172414 Correct: 20.0 Tested: 29.0 #Train 250.0\n",
      "\t EE09 Acc.: 0.814285714286 Correct: 57.0 Tested: 70.0 #Train 555.0\n",
      "\t EE06 Acc.: 0.8875 Correct: 71.0 Tested: 80.0 #Train 737.0\n",
      "\t EE07 Acc.: 0.928571428571 Correct: 26.0 Tested: 28.0 #Train 251.0\n",
      "\t EE04 Acc.: 0.9 Correct: 36.0 Tested: 40.0 #Train 270.0\n",
      "\t EE05 Acc.: 0.714285714286 Correct: 20.0 Tested: 28.0 #Train 260.0\n",
      "\t EE02 Acc.: 0.962199312715 Correct: 280.0 Tested: 291.0 #Train 2857.0\n",
      "\t EE03 Acc.: 0.966666666667 Correct: 87.0 Tested: 90.0 #Train 739.0\n",
      "\t EE01 Acc.: 0.901234567901 Correct: 146.0 Tested: 162.0 #Train 1541.0\n",
      "\t EB01 Acc.: 0.85635359116 Correct: 155.0 Tested: 181.0 #Train 1349.0\n",
      "\t EB03 Acc.: 0.899441340782 Correct: 161.0 Tested: 179.0 #Train 1601.0\n",
      "\t EB02 Acc.: 0.918699186992 Correct: 113.0 Tested: 123.0 #Train 1199.0\n",
      "\t EB05 Acc.: 0.88 Correct: 22.0 Tested: 25.0 #Train 285.0\n",
      "\t EB04 Acc.: 0.64 Correct: 16.0 Tested: 25.0 #Train 237.0\n",
      "\t EB07 Acc.: 0.7 Correct: 21.0 Tested: 30.0 #Train 321.0\n",
      "\t EB06 Acc.: 0.803278688525 Correct: 49.0 Tested: 61.0 #Train 467.0\n",
      "\t EE11 Acc.: 0.768115942029 Correct: 53.0 Tested: 69.0 #Train 648.0\n",
      "\t EB08 Acc.: 0.818181818182 Correct: 9.0 Tested: 11.0 #Train 98.0\n",
      "\t EE13 Acc.: 0.620689655172 Correct: 18.0 Tested: 29.0 #Train 242.0\n",
      "\t EE12 Acc.: 1.0 Correct: 31.0 Tested: 31.0 #Train 207.0\n",
      "\t EI99 Acc.: 0.826086956522 Correct: 19.0 Tested: 23.0 #Train 307.0\n",
      "\t EE14 Acc.: 0.785714285714 Correct: 11.0 Tested: 14.0 #Train 142.0\n",
      "\t EC08 Acc.: 0.928571428571 Correct: 13.0 Tested: 14.0 #Train 81.0\n",
      "\t EC09 Acc.: 0.94 Correct: 47.0 Tested: 50.0 #Train 412.0\n",
      "\t EC01 Acc.: 0.941176470588 Correct: 80.0 Tested: 85.0 #Train 650.0\n",
      "\t EC02 Acc.: 0.896226415094 Correct: 95.0 Tested: 106.0 #Train 958.0\n",
      "\t EC03 Acc.: 0.811320754717 Correct: 43.0 Tested: 53.0 #Train 468.0\n",
      "\t EC04 Acc.: 0.961538461538 Correct: 50.0 Tested: 52.0 #Train 368.0\n",
      "\t EC05 Acc.: 0.8125 Correct: 39.0 Tested: 48.0 #Train 415.0\n",
      "\t EC06 Acc.: 0.76 Correct: 19.0 Tested: 25.0 #Train 197.0\n",
      "\t EC07 Acc.: 0.939393939394 Correct: 31.0 Tested: 33.0 #Train 251.0\n",
      "\t EF05 Acc.: 0.80701754386 Correct: 46.0 Tested: 57.0 #Train 474.0\n",
      "\t EF04 Acc.: 0.727272727273 Correct: 24.0 Tested: 33.0 #Train 316.0\n",
      "\t EF06 Acc.: 0.9670781893 Correct: 235.0 Tested: 243.0 #Train 2211.0\n",
      "\t EF01 Acc.: 0.857142857143 Correct: 24.0 Tested: 28.0 #Train 251.0\n",
      "\t EF03 Acc.: 0.92 Correct: 23.0 Tested: 25.0 #Train 190.0\n",
      "\t EF02 Acc.: 0.92 Correct: 23.0 Tested: 25.0 #Train 289.0\n",
      "\t EG08 Acc.: 0.571428571429 Correct: 8.0 Tested: 14.0 #Train 114.0\n",
      "\t EG09 Acc.: 1.0 Correct: 17.0 Tested: 17.0 #Train 118.0\n",
      "\t EG04 Acc.: 0.904761904762 Correct: 38.0 Tested: 42.0 #Train 329.0\n",
      "\t EG05 Acc.: 1.0 Correct: 11.0 Tested: 11.0 #Train 131.0\n",
      "\t EG06 Acc.: 1.0 Correct: 22.0 Tested: 22.0 #Train 197.0\n",
      "\t EC10 Acc.: 0.75 Correct: 3.0 Tested: 4.0 #Train 48.0\n",
      "\t EG01 Acc.: 0.909090909091 Correct: 10.0 Tested: 11.0 #Train 103.0\n",
      "\t EG02 Acc.: 0.8 Correct: 12.0 Tested: 15.0 #Train 157.0\n",
      "\t EG03 Acc.: 0.866666666667 Correct: 13.0 Tested: 15.0 #Train 136.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t ED07 Acc.: 0.876923076923 Correct: 57.0 Tested: 65.0 #Train 573.0\n",
      "\t ED06 Acc.: 0.888888888889 Correct: 56.0 Tested: 63.0 #Train 635.0\n",
      "\t ED05 Acc.: 0.715789473684 Correct: 68.0 Tested: 95.0 #Train 887.0\n",
      "\t ED04 Acc.: 0.939890710383 Correct: 172.0 Tested: 183.0 #Train 1598.0\n",
      "\t ED03 Acc.: 0.93137254902 Correct: 95.0 Tested: 102.0 #Train 783.0\n",
      "\t ED02 Acc.: 0.857142857143 Correct: 42.0 Tested: 49.0 #Train 343.0\n",
      "\t ED01 Acc.: 0.887640449438 Correct: 79.0 Tested: 89.0 #Train 923.0\n",
      "\t ED09 Acc.: 0.941176470588 Correct: 64.0 Tested: 68.0 #Train 453.0\n",
      "\t EG10 Acc.: 0.9375 Correct: 15.0 Tested: 16.0 #Train 160.0\n",
      "\t EH10 Acc.: 0.9 Correct: 18.0 Tested: 20.0 #Train 218.0\n",
      "\t EH11 Acc.: 0.8 Correct: 20.0 Tested: 25.0 #Train 207.0\n",
      "\t EH12 Acc.: 0.5625 Correct: 9.0 Tested: 16.0 #Train 122.0\n",
      "\t EH13 Acc.: 0.692307692308 Correct: 9.0 Tested: 13.0 #Train 144.0\n",
      "!Low precision :! #Correct: 7.0 #Tested: 17.0 #Train 84.0\n",
      "\t EH14 Acc.: 0.411764705882 Correct: 7.0 Tested: 17.0 #Train 84.0\n",
      "!Low precision :! #Correct: 1.0 #Tested: 4.0 #Train 33.0\n",
      "\t EH15 Acc.: 0.25 Correct: 1.0 Tested: 4.0 #Train 33.0\n",
      "\t EG99 Acc.: 0.945945945946 Correct: 35.0 Tested: 37.0 #Train 381.0\n",
      "!Low precision :! #Correct: 3.0 #Tested: 7.0 #Train 96.0\n",
      "\t EC99 Acc.: 0.428571428571 Correct: 3.0 Tested: 7.0 #Train 96.0\n",
      "!Low precision :! #Correct: 30.0 #Tested: 61.0 #Train 603.0\n",
      "\t ED99 Acc.: 0.491803278689 Correct: 30.0 Tested: 61.0 #Train 603.0\n",
      "\t EC11 Acc.: 1.0 Correct: 1.0 Tested: 1.0 #Train 29.0\n",
      "\t EH09 Acc.: 0.974358974359 Correct: 38.0 Tested: 39.0 #Train 279.0\n",
      "\t EH08 Acc.: 0.846153846154 Correct: 11.0 Tested: 13.0 #Train 147.0\n",
      "\t EH03 Acc.: 0.96 Correct: 24.0 Tested: 25.0 #Train 225.0\n",
      "\t EH02 Acc.: 0.918918918919 Correct: 68.0 Tested: 74.0 #Train 738.0\n",
      "\t EH01 Acc.: 0.924528301887 Correct: 49.0 Tested: 53.0 #Train 440.0\n",
      "\t EH07 Acc.: 0.914893617021 Correct: 43.0 Tested: 47.0 #Train 476.0\n",
      "\t EH06 Acc.: 0.961538461538 Correct: 25.0 Tested: 26.0 #Train 247.0\n",
      "\t EH05 Acc.: 0.666666666667 Correct: 2.0 Tested: 3.0 #Train 69.0\n",
      "\t EH04 Acc.: 0.941176470588 Correct: 16.0 Tested: 17.0 #Train 145.0\n",
      "\t EH99 Acc.: 0.9 Correct: 18.0 Tested: 20.0 #Train 190.0\n",
      "\t ED08 Acc.: 0.88 Correct: 44.0 Tested: 50.0 #Train 513.0\n",
      "Total Test Examples 6033 \n",
      "Micro Acc.(item level) 0.873860434278\n",
      "Macro Acc.(class level) 0.846465367629 \n",
      "\n",
      "\n",
      "Trial: 2 R_s 7\n",
      "54297 6033\n",
      "data loaded\n",
      "Vectorizing:  7\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 54297, n_features: 77292\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 6033, n_features: 77292\n",
      "Learning:  7\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=10, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 28.146s\n",
      "test time:  0.385s\n",
      "Top- 5\n",
      "False docID: 202 prediction of  ED99  was: ['EE11' 'EA08' 'EA07' 'EG07' 'ED01']\n",
      "False docID: 291 prediction of  ED99  was: ['ED09' 'EA07' 'EB04' 'EB03' 'EA09']\n",
      "False docID: 368 prediction of  ED99  was: ['EH13' 'EE10' 'ED06' 'EE02' 'EE09']\n",
      "False docID: 462 prediction of  ED99  was: ['EA14' 'EA06' 'EE03' 'ED08' 'ED07']\n",
      "False docID: 624 prediction of  ED99  was: ['EE09' 'EE99' 'EA03' 'EA02' 'EE02']\n",
      "False docID: 633 prediction of  ED99  was: ['EA06' 'ED04' 'EB99' 'ED01' 'EB01']\n",
      "False docID: 1950 prediction of  ED99  was: ['EE05' 'EE06' 'EA10' 'EE99' 'EE09']\n",
      "False docID: 2046 prediction of  ED99  was: ['EA11' 'EA13' 'EA03' 'ED05' 'ED03']\n",
      "False docID: 2237 prediction of  ED99  was: ['ED05' 'EA02' 'EE01' 'ED11' 'EA05']\n",
      "False docID: 2310 prediction of  ED99  was: ['EB01' 'EA15' 'EA09' 'ED08' 'EE11']\n",
      "False docID: 2349 prediction of  ED99  was: ['EE99' 'EE11' 'EC09' 'EE06' 'ED04']\n",
      "False docID: 2698 prediction of  ED99  was: ['EA03' 'ED02' 'EA01' 'EA05' 'ED07']\n",
      "False docID: 2700 prediction of  ED99  was: ['ED07' 'EA01' 'ED01' 'ED04' 'ED05']\n",
      "False docID: 2992 prediction of  ED99  was: ['EA05' 'EE01' 'EA01' 'ED10' 'ED08']\n",
      "False docID: 3070 prediction of  ED99  was: ['EE06' 'EA05' 'ED10' 'EE09' 'ED02']\n",
      "False docID: 3149 prediction of  ED99  was: ['EH02' 'EB99' 'EI03' 'EI11' 'EG99']\n",
      "False docID: 3279 prediction of  ED99  was: ['EA06' 'EB01' 'EB99' 'EB03' 'EC02']\n",
      "False docID: 3711 prediction of  ED99  was: ['EB02' 'ED05' 'EA09' 'EA99' 'EB99']\n",
      "False docID: 3881 prediction of  ED99  was: ['EH07' 'EC03' 'EB03' 'EC07' 'EC09']\n",
      "False docID: 3939 prediction of  ED99  was: ['EC05' 'EB99' 'ED07' 'EA03' 'ED01']\n",
      "False docID: 4043 prediction of  ED99  was: ['ED11' 'EA05' 'ED08' 'EE01' 'EE02']\n",
      "False docID: 4646 prediction of  ED99  was: ['EB02' 'EA08' 'EA07' 'EA09' 'ED06']\n",
      "False docID: 4725 prediction of  ED99  was: ['EE99' 'EE02' 'EA03' 'EC09' 'EG99']\n",
      "False docID: 4830 prediction of  ED99  was: ['EB01' 'ED10' 'EA99' 'EB99' 'EF99']\n",
      "False docID: 4918 prediction of  ED99  was: ['EE99' 'EI05' 'EA15' 'EE14' 'ED11']\n",
      "False docID: 4968 prediction of  ED99  was: ['EF05' 'EE05' 'ED03' 'EE11' 'ED05']\n",
      "False docID: 5035 prediction of  ED99  was: ['EF99' 'ED03' 'EF04' 'ED09' 'ED05']\n",
      "False docID: 5185 prediction of  ED99  was: ['EF99' 'EA02' 'EB03' 'EA09' 'ED05']\n",
      "False docID: 5206 prediction of  ED99  was: ['EA08' 'ED06' 'EB02' 'EF06' 'EI05']\n",
      "False docID: 5314 prediction of  ED99  was: ['EB05' 'EA07' 'EB06' 'ED01' 'ED06']\n",
      "False docID: 5393 prediction of  ED99  was: ['EF99' 'EE02' 'EF05' 'EE11' 'EE99']\n",
      "False docID: 5657 prediction of  ED99  was: ['EB03' 'ED05' 'EA07' 'EA08' 'ED06']\n",
      "False docID: 5827 prediction of  ED99  was: ['EA01' 'ED01' 'EA03' 'EA10' 'ED08']\n",
      "!Low precision :! #Correct: 22.0 #Tested: 50.0 #Train 342.0\n",
      "\t EA99 Acc.: 0.44 Correct: 22.0 Tested: 50.0 #Train 342.0\n",
      "\t EI02 Acc.: 0.95 Correct: 19.0 Tested: 20.0 #Train 256.0\n",
      "\t EI03 Acc.: 0.94495412844 Correct: 103.0 Tested: 109.0 #Train 865.0\n",
      "\t EI01 Acc.: 0.916666666667 Correct: 22.0 Tested: 24.0 #Train 217.0\n",
      "\t EI06 Acc.: 0.96 Correct: 24.0 Tested: 25.0 #Train 282.0\n",
      "\t EI07 Acc.: 0.666666666667 Correct: 4.0 Tested: 6.0 #Train 52.0\n",
      "\t EI04 Acc.: 0.946808510638 Correct: 89.0 Tested: 94.0 #Train 915.0\n",
      "\t EI05 Acc.: 0.857142857143 Correct: 36.0 Tested: 42.0 #Train 305.0\n",
      "\t EG08 Acc.: 0.615384615385 Correct: 8.0 Tested: 13.0 #Train 115.0\n",
      "\t EI08 Acc.: 0.666666666667 Correct: 4.0 Tested: 6.0 #Train 100.0\n",
      "\t EI09 Acc.: 0.970588235294 Correct: 33.0 Tested: 34.0 #Train 338.0\n",
      "\t EG09 Acc.: 0.916666666667 Correct: 11.0 Tested: 12.0 #Train 123.0\n",
      "\t EA08 Acc.: 0.81914893617 Correct: 77.0 Tested: 94.0 #Train 788.0\n",
      "\t EA09 Acc.: 0.967213114754 Correct: 177.0 Tested: 183.0 #Train 1618.0\n",
      "\t EA02 Acc.: 0.755319148936 Correct: 71.0 Tested: 94.0 #Train 878.0\n",
      "\t EA03 Acc.: 0.75 Correct: 48.0 Tested: 64.0 #Train 725.0\n",
      "\t EA01 Acc.: 0.75 Correct: 51.0 Tested: 68.0 #Train 524.0\n",
      "\t EA06 Acc.: 0.925531914894 Correct: 87.0 Tested: 94.0 #Train 755.0\n",
      "\t EA07 Acc.: 0.817391304348 Correct: 94.0 Tested: 115.0 #Train 1043.0\n",
      "\t EA04 Acc.: 0.826086956522 Correct: 57.0 Tested: 69.0 #Train 627.0\n",
      "\t EA05 Acc.: 0.93661971831 Correct: 133.0 Tested: 142.0 #Train 1311.0\n",
      "\t EC10 Acc.: 1.0 Correct: 2.0 Tested: 2.0 #Train 50.0\n",
      "\t EE99 Acc.: 0.730769230769 Correct: 57.0 Tested: 78.0 #Train 781.0\n",
      "\t EB08 Acc.: 0.571428571429 Correct: 8.0 Tested: 14.0 #Train 95.0\n",
      "\t EF99 Acc.: 0.714285714286 Correct: 55.0 Tested: 77.0 #Train 650.0\n",
      "\t EI11 Acc.: 0.912280701754 Correct: 52.0 Tested: 57.0 #Train 563.0\n",
      "\t EI10 Acc.: 1.0 Correct: 18.0 Tested: 18.0 #Train 124.0\n",
      "\t EI12 Acc.: 0.936170212766 Correct: 44.0 Tested: 47.0 #Train 497.0\n",
      "\t EA15 Acc.: 0.8 Correct: 12.0 Tested: 15.0 #Train 136.0\n",
      "\t EA14 Acc.: 0.823529411765 Correct: 14.0 Tested: 17.0 #Train 241.0\n",
      "\t EA11 Acc.: 0.975609756098 Correct: 40.0 Tested: 41.0 #Train 334.0\n",
      "\t EA10 Acc.: 0.945054945055 Correct: 86.0 Tested: 91.0 #Train 924.0\n",
      "\t EA13 Acc.: 1.0 Correct: 29.0 Tested: 29.0 #Train 183.0\n",
      "\t EA12 Acc.: 1.0 Correct: 16.0 Tested: 16.0 #Train 132.0\n",
      "\t EB99 Acc.: 0.604166666667 Correct: 29.0 Tested: 48.0 #Train 400.0\n",
      "\t EE08 Acc.: 0.935483870968 Correct: 29.0 Tested: 31.0 #Train 248.0\n",
      "\t EE09 Acc.: 0.868421052632 Correct: 66.0 Tested: 76.0 #Train 549.0\n",
      "\t EE06 Acc.: 0.883116883117 Correct: 68.0 Tested: 77.0 #Train 740.0\n",
      "\t EE07 Acc.: 0.939393939394 Correct: 31.0 Tested: 33.0 #Train 246.0\n",
      "\t EE04 Acc.: 0.9375 Correct: 30.0 Tested: 32.0 #Train 278.0\n",
      "\t EE05 Acc.: 0.794117647059 Correct: 27.0 Tested: 34.0 #Train 254.0\n",
      "\t EE02 Acc.: 0.945714285714 Correct: 331.0 Tested: 350.0 #Train 2798.0\n",
      "\t EE03 Acc.: 0.958333333333 Correct: 69.0 Tested: 72.0 #Train 757.0\n",
      "\t EE01 Acc.: 0.963855421687 Correct: 160.0 Tested: 166.0 #Train 1537.0\n",
      "\t EB01 Acc.: 0.881355932203 Correct: 156.0 Tested: 177.0 #Train 1353.0\n",
      "\t EB03 Acc.: 0.903614457831 Correct: 150.0 Tested: 166.0 #Train 1614.0\n",
      "\t EB02 Acc.: 0.900709219858 Correct: 127.0 Tested: 141.0 #Train 1181.0\n",
      "\t EB05 Acc.: 0.6875 Correct: 22.0 Tested: 32.0 #Train 278.0\n",
      "\t EB04 Acc.: 0.848484848485 Correct: 28.0 Tested: 33.0 #Train 229.0\n",
      "\t EB07 Acc.: 0.828571428571 Correct: 29.0 Tested: 35.0 #Train 316.0\n",
      "\t EB06 Acc.: 0.755102040816 Correct: 37.0 Tested: 49.0 #Train 479.0\n",
      "\t EE11 Acc.: 0.771428571429 Correct: 54.0 Tested: 70.0 #Train 647.0\n",
      "\t EE10 Acc.: 0.795918367347 Correct: 39.0 Tested: 49.0 #Train 501.0\n",
      "\t EE13 Acc.: 0.85 Correct: 17.0 Tested: 20.0 #Train 251.0\n",
      "\t EE12 Acc.: 0.95 Correct: 19.0 Tested: 20.0 #Train 218.0\n",
      "\t EI99 Acc.: 0.555555555556 Correct: 20.0 Tested: 36.0 #Train 294.0\n",
      "\t EE14 Acc.: 0.923076923077 Correct: 12.0 Tested: 13.0 #Train 143.0\n",
      "\t EC08 Acc.: 1.0 Correct: 8.0 Tested: 8.0 #Train 87.0\n",
      "\t EC09 Acc.: 0.946428571429 Correct: 53.0 Tested: 56.0 #Train 406.0\n",
      "\t EC01 Acc.: 0.868852459016 Correct: 53.0 Tested: 61.0 #Train 674.0\n",
      "\t EC02 Acc.: 0.908333333333 Correct: 109.0 Tested: 120.0 #Train 944.0\n",
      "\t EC03 Acc.: 0.772727272727 Correct: 34.0 Tested: 44.0 #Train 477.0\n",
      "\t EC04 Acc.: 1.0 Correct: 39.0 Tested: 39.0 #Train 381.0\n",
      "\t EC05 Acc.: 0.897435897436 Correct: 35.0 Tested: 39.0 #Train 424.0\n",
      "\t EC06 Acc.: 0.75 Correct: 15.0 Tested: 20.0 #Train 202.0\n",
      "\t EC07 Acc.: 0.972222222222 Correct: 35.0 Tested: 36.0 #Train 248.0\n",
      "\t EF05 Acc.: 0.88 Correct: 44.0 Tested: 50.0 #Train 481.0\n",
      "\t EF04 Acc.: 0.7 Correct: 21.0 Tested: 30.0 #Train 319.0\n",
      "\t EF06 Acc.: 0.952991452991 Correct: 223.0 Tested: 234.0 #Train 2220.0\n",
      "\t EF01 Acc.: 0.925925925926 Correct: 25.0 Tested: 27.0 #Train 252.0\n",
      "\t EF03 Acc.: 0.952380952381 Correct: 20.0 Tested: 21.0 #Train 194.0\n",
      "\t EF02 Acc.: 0.952380952381 Correct: 20.0 Tested: 21.0 #Train 293.0\n",
      "\t ED10 Acc.: 0.847826086957 Correct: 78.0 Tested: 92.0 #Train 816.0\n",
      "\t ED11 Acc.: 0.8 Correct: 24.0 Tested: 30.0 #Train 352.0\n",
      "\t EG04 Acc.: 0.897435897436 Correct: 35.0 Tested: 39.0 #Train 332.0\n",
      "\t EG05 Acc.: 0.823529411765 Correct: 14.0 Tested: 17.0 #Train 125.0\n",
      "\t EG06 Acc.: 1.0 Correct: 28.0 Tested: 28.0 #Train 191.0\n",
      "\t EG07 Acc.: 0.931034482759 Correct: 54.0 Tested: 58.0 #Train 546.0\n",
      "\t EG01 Acc.: 0.789473684211 Correct: 15.0 Tested: 19.0 #Train 95.0\n",
      "\t EG02 Acc.: 0.866666666667 Correct: 13.0 Tested: 15.0 #Train 157.0\n",
      "\t EG03 Acc.: 1.0 Correct: 20.0 Tested: 20.0 #Train 131.0\n",
      "\t ED07 Acc.: 0.72131147541 Correct: 44.0 Tested: 61.0 #Train 577.0\n",
      "\t ED06 Acc.: 0.890625 Correct: 57.0 Tested: 64.0 #Train 634.0\n",
      "\t ED05 Acc.: 0.7 Correct: 63.0 Tested: 90.0 #Train 892.0\n",
      "\t ED04 Acc.: 0.899441340782 Correct: 161.0 Tested: 179.0 #Train 1602.0\n",
      "\t ED03 Acc.: 0.91 Correct: 91.0 Tested: 100.0 #Train 785.0\n",
      "\t ED02 Acc.: 0.666666666667 Correct: 26.0 Tested: 39.0 #Train 353.0\n",
      "\t ED01 Acc.: 0.913461538462 Correct: 95.0 Tested: 104.0 #Train 908.0\n",
      "\t ED09 Acc.: 0.882352941176 Correct: 45.0 Tested: 51.0 #Train 470.0\n",
      "\t EG10 Acc.: 1.0 Correct: 20.0 Tested: 20.0 #Train 156.0\n",
      "\t EH10 Acc.: 0.653846153846 Correct: 17.0 Tested: 26.0 #Train 212.0\n",
      "\t EH11 Acc.: 0.75 Correct: 18.0 Tested: 24.0 #Train 208.0\n",
      "\t EH12 Acc.: 0.882352941176 Correct: 15.0 Tested: 17.0 #Train 121.0\n",
      "\t EH13 Acc.: 0.8125 Correct: 13.0 Tested: 16.0 #Train 141.0\n",
      "!Low precision :! #Correct: 2.0 #Tested: 8.0 #Train 93.0\n",
      "\t EH14 Acc.: 0.25 Correct: 2.0 Tested: 8.0 #Train 93.0\n",
      "\t EH15 Acc.: 0.666666666667 Correct: 4.0 Tested: 6.0 #Train 31.0\n",
      "\t EG99 Acc.: 0.925 Correct: 37.0 Tested: 40.0 #Train 378.0\n",
      "\t EC99 Acc.: 0.555555555556 Correct: 5.0 Tested: 9.0 #Train 94.0\n",
      "!Low precision :! #Correct: 31.0 #Tested: 64.0 #Train 600.0\n",
      "\t ED99 Acc.: 0.484375 Correct: 31.0 Tested: 64.0 #Train 600.0\n",
      "\t EC11 Acc.: 0.666666666667 Correct: 2.0 Tested: 3.0 #Train 27.0\n",
      "\t EH09 Acc.: 0.871794871795 Correct: 34.0 Tested: 39.0 #Train 279.0\n",
      "\t EH08 Acc.: 0.8 Correct: 12.0 Tested: 15.0 #Train 145.0\n",
      "\t EH03 Acc.: 0.916666666667 Correct: 22.0 Tested: 24.0 #Train 226.0\n",
      "\t EH02 Acc.: 0.922077922078 Correct: 71.0 Tested: 77.0 #Train 735.0\n",
      "\t EH01 Acc.: 0.938775510204 Correct: 46.0 Tested: 49.0 #Train 444.0\n",
      "\t EH07 Acc.: 0.882352941176 Correct: 45.0 Tested: 51.0 #Train 472.0\n",
      "\t EH06 Acc.: 0.884615384615 Correct: 23.0 Tested: 26.0 #Train 247.0\n",
      "\t EH05 Acc.: 1.0 Correct: 5.0 Tested: 5.0 #Train 67.0\n",
      "\t EH04 Acc.: 0.85 Correct: 17.0 Tested: 20.0 #Train 142.0\n",
      "\t EH99 Acc.: 0.538461538462 Correct: 7.0 Tested: 13.0 #Train 197.0\n",
      "\t ED08 Acc.: 0.795918367347 Correct: 39.0 Tested: 49.0 #Train 514.0\n",
      "Total Test Examples 6033 \n",
      "Micro Acc.(item level) 0.867727498757\n",
      "Macro Acc.(class level) 0.841049869509 \n",
      "\n",
      "\n",
      "Cumulative 0.872368639151\n"
     ]
    }
   ],
   "source": [
    "accumulated_fail_list = {}\n",
    "TRIAL_SIZE = 3\n",
    "RANDOM_STATE_START = 5\n",
    "cumulative_micro_avg = 0\n",
    "cumulative_class_score = {}\n",
    "CODE = 'ED99' #code you want to investigate, doesn't affect the result\n",
    "#try the code with different train/test splts\n",
    "for t,trial in enumerate(range(RANDOM_STATE_START,RANDOM_STATE_START + TRIAL_SIZE)):\n",
    "    print(\"Trial:\",t,\"R_s\",trial)\n",
    "    divide_data(trial)\n",
    "    print(\"Vectorizing: \",trial)\n",
    "    vectorize()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    fail_list = []\n",
    "    fail_list_for_code = []\n",
    "    feature_names = np.asarray(feature_names)\n",
    "    # Train SGD model\n",
    "    print(\"Learning: \",trial)\n",
    "    \n",
    "    #suggested by sklearn tutorial:http://scikit-learn.org/stable/modules/sgd.html#tips-on-practical-use\n",
    "    suggested_n_iter = np.ceil(10**6/len(data_train_data)) \n",
    "    \n",
    "    #DONT USE ELASTICNET as penalty, it will give lower accuracy\n",
    "    clf = SGDClassifier(loss='modified_huber', alpha=0.0001, n_iter=10, penalty='l2')\n",
    "    benchmark(clf)\n",
    "    for x in fail_list:\n",
    "        if not accumulated_fail_list.has_key(x):\n",
    "            accumulated_fail_list[x] = 0\n",
    "        accumulated_fail_list[x] +=1\n",
    "    #print(fail_list)\n",
    "    for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] == TRIAL_SIZE:\n",
    "            print(x,accumulated_fail_list[x])\n",
    "#print the average micro accuracy            \n",
    "print('Cumulative',cumulative_micro_avg/TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this block prints the statistics(info about each category)\n",
    "statistics = open('statistics_3rdtest.txt','w')\n",
    "statistics.write('\\t'.join(['CODE','ALL','TRAIN','TEST','CORRECT','correct%'])+'\\n')\n",
    "\n",
    "for x in count:\n",
    "    a_row = [x,count[x],count[x]-cumulative_class_score[x][1],cumulative_class_score[x][1],cumulative_class_score[x][0],cumulative_class_score[x][0]/cumulative_class_score[x][1]]#code,train,tested,correct\n",
    "    for i in range(len(a_row)):\n",
    "        a_row[i] = str(a_row[i])\n",
    "    statistics.write('\\t'.join(a_row)+'\\n')\n",
    "statistics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EH12 1\n",
      "EA99 1\n",
      "EH15 1\n",
      "ED99 1\n"
     ]
    }
   ],
   "source": [
    "#which categories failed most\n",
    "for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] >= TRIAL_SIZE -2:\n",
    "            print(x,accumulated_fail_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EA99 [20.0, 41.0] 372\n",
      "EH12 [4.0, 10.0] 106\n",
      "EH15 [2.0, 5.0] 25\n",
      "ED99 [14.0, 40.0] 582\n"
     ]
    }
   ],
   "source": [
    "#which categories failed most 2\n",
    "for x in cumulative_class_score:\n",
    "    if(x[0] == \"E\"):\n",
    "        if(cumulative_class_score[x][0]/cumulative_class_score[x][1]<0.5):\n",
    "            print(x,cumulative_class_score[x],count[x]*TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the index for specific code\n",
    "# EH14 is 95\n",
    "# EH15 is 96\n",
    "# EA99 is 15\n",
    "# ed99 is 48\n",
    "# ee00 is 63\n",
    "print(suggested_n_iter)\n",
    "CODE_INDEX = clf.classes_.tolist().index(CODE)\n",
    "CODE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517542185785 endoscopi\n",
      "0.554998145394 lamp\n",
      "0.551419272672 triangular\n",
      "0.563239502759 turnov\n",
      "0.608646924589 wearabl\n",
      "0.66730913174 \n",
      "0.519867299344 \n",
      "0.925674999351 \n",
      "0.602099061057 \n",
      "0.746020559369 \n",
      "0.79116022665 \n",
      "0.621038667741 \n",
      "0.520720374026 \n",
      "0.520453219473 \n",
      "0.596783766286 \n",
      "0.633231151025 \n",
      "0.608676919415 \n",
      "0.644928267792 \n",
      "0.656657027617 \n",
      "0.533554481677 \n",
      "0.559106759631 \n",
      "0.500680965876 \n",
      "0.562054476646 \n",
      "0.749688808711 \n",
      "0.586173454145 \n",
      "0.580687250659 \n",
      "0.563884064454 \n",
      "0.514010717075 \n",
      "0.618096097616 \n"
     ]
    }
   ],
   "source": [
    "#which words have high weight for CODE_INDEX\n",
    "white_list = []\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(clf.coef_[CODE_INDEX][i]>0.5):\n",
    "        print(clf.coef_[CODE_INDEX][i],x)\n",
    "        white_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = file(\"features.txt\",\"w\")\n",
    "\n",
    "for x in feature_names:\n",
    "    out.write(x.encode('utf-8','ignore')+\"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED99                       sunlight generation electricity carbon fiber electricity mat new regeneration energy                                                                                                                                                                                                                                                                                                                                                                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_test[fail_list_for_code[0]],data_test_data[fail_list_for_code[0]])\n",
    "fail_data = []\n",
    "for x in fail_list_for_code:\n",
    "    fail_data.append(data_test_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail size: 29\n",
      "                      sunlight generation electricity carbon fiber electricity mat new regeneration energy                                                                                                                                                                                                                                                                                                                                                                   \n",
      "\n",
      "                   educational program energy networking supporting export supporting small - size company                                                                                                                                                                                                                                     \n",
      "\n",
      "              micro ev battery controller power module                                                                                                                            \n",
      "\n",
      "                smart glasses augmented reality head mounted display wearable device optical system                                                                                                         \n",
      "\n",
      "           marine robot                                                                                                                                                                                                                                          \n",
      "\n",
      "    display blu lcd                                              \n",
      "\n",
      "                   high thermal mesh tech tension insert injection air cooled bm a lightweight bm a                                                                         \n",
      "\n",
      "               nano process nano patterning graph ene transfer surface control structure guiding polymer                                                                                                                                                                                                             \n",
      "\n",
      "            6 . car 7 . sensor 8 . antenna 9 . radar 1 0 . condition                                                                                                                                                                                                 \n",
      "\n",
      "                storybook picture - book interaction realize child                                                                                                                                                          \n",
      "\n",
      "                              patch type cardiac bio marker bio sensor highly sensitive sensor module dynamic noise reduction performance evaluation electrochemical system integration                                                                                                                                                                                                                            \n",
      "\n",
      "              printed electronics micro machining print master flexibility imprint                                                                                                                                                                                                    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      wide fire surveillance high reliability fire monitoring low cost thermal camera intelligent fire detection                                                                                                            \n",
      "\n",
      "                   d gps beacon g nss                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "           cctv energy saving ac cob led security light high efficiency                                                                                                                          \n",
      "\n",
      "                     guide a person who is visually imp a i app mobile bluetooth                                                                                                                                                                                                                                                                                                                                      \n",
      "\n",
      "                 electrode position electronic equipment impression of a pearl gray paints / pigment electrostatic painting                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "\n",
      "                         combined optical and analog sensor measurement equipment structure health monitoring fiber bragg grating sensor monitoring damage detection load history                                                                     \n",
      "\n",
      "                    lin interface alternator power control module mi com                                                                                                                                                                                                                  \n",
      "\n",
      "          spectrum relocation auction assignment                                                                                                            \n",
      "\n",
      "                        nice integrated system new industry for future life good service ict based field business expertise convergence education smart living creative converging female professional education research job career i interlink                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "\n",
      "                        functional safety automotive safety integrity level safety integrity level safety related system electrical elector nic control system                                                                                                                        \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  radar u av fm cw collision avoid image detect                                                                                                                                                                                                                                                                                                                                                     \n",
      "\n",
      "                           midterm r & d strategy first mover r & d strategy                                                                                                                                                  \n",
      "\n",
      "                     mobile x - ray image sensor design identity usability home diagnostic service                                                                                                                                                                                         \n",
      "\n",
      "                            traditional korean instrument metal percussion acoustical analysis sound synthesis toolkit softening beat impulse response subjective test                                                                                                                                                                                                                                                \n",
      "\n",
      "                 gas sensor i ot smart device sub miniature low power consumption                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "\n",
      "               nano process nano patterning graph ene transfer surface control structure guiding polymer                                                                                                                                                                                                            \n",
      "\n",
      "                  eco - friendly car emc ev low frequency evaluation method                                                                                                                                                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = vectorizer.transform(fail_data)\n",
    "v_array = v.toarray()\n",
    "important_word = []\n",
    "for i in range(200000):\n",
    "    important_word.append([])\n",
    "buffer = 200000*[0]\n",
    "print(\"Fail size:\",len(fail_data))\n",
    "for i,doc in enumerate(fail_data):\n",
    "    print(doc)\n",
    "    #print(v.toarray()[i])\n",
    "    #rev_list =  reversed(np.argsort(v.toarray()[i]))\n",
    "    for j in range(len(v_array[i])):\n",
    "        if(v_array[i][j]>0.0):\n",
    "     #       print(index,feature_names[index])\n",
    "            buffer[j] = 1\n",
    "        \n",
    "    for j in range(len(buffer)):\n",
    "        if buffer[j] > 0:\n",
    "            important_word[j].append(i)\n",
    "            buffer[j] = 0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 [1, 2, 4, 8, 9, 10, 11, 13, 18, 19, 20, 21, 22, 23, 25, 26, 28]  -0.0589689547829\n",
      "12 [0, 3, 5, 6, 7, 10, 14, 17, 20, 21, 24, 27]  -0.014681700471\n",
      "11 [1, 4, 11, 12, 15, 19, 20, 21, 23, 24, 26]  0.00160561546174\n",
      "12 [6, 7, 8, 10, 11, 12, 13, 16, 18, 26, 27, 28]  -0.0459541954862\n",
      "11 [4, 7, 8, 10, 12, 15, 17, 22, 24, 26, 27]  -0.0929137712641\n",
      "16 [1, 2, 4, 8, 9, 10, 11, 13, 14, 16, 18, 19, 22, 24, 25, 26]  0.204275988193\n",
      "15 [0, 5, 6, 7, 9, 10, 11, 16, 17, 18, 22, 24, 25, 27, 28]  -0.106692923436\n",
      "14 [0, 2, 4, 5, 6, 9, 11, 14, 15, 16, 18, 22, 24, 26]  -0.0150238899123\n",
      "16 [0, 1, 2, 3, 7, 8, 9, 13, 14, 16, 18, 20, 24, 25, 26, 27]  0.0356542569683\n"
     ]
    }
   ],
   "source": [
    "for i,count in enumerate(important_word):\n",
    "    if len(count) > 10:\n",
    "        print(len(count),count,feature_names[i],clf.coef_[63][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
