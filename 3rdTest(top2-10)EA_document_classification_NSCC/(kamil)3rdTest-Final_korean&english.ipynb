{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification of text documents using sparse features\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#\t\t  Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#\t\t  Mathieu Blondel <mathieu@mblondel.org>\n",
    "#\t\t  Lars Buitinck\n",
    "# Updated by: Kisti\n",
    "# Finalized by: Kamil Veli TORAMAN <kvtoraman@kaist.ac.kr>\n",
    "# 23 August 2017\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import nltk.stem\n",
    "from optparse import OptionParser\n",
    "import sys, copy\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def transform_label(clf, prob, topk):\n",
    "    rst_arr = np.empty( (len(prob), topk), dtype=object) \n",
    "    for i in range(len(prob)):\n",
    "        s_items = np.argsort(prob[i])[-topk:]\n",
    "\n",
    "        for j in range(len(s_items)):\n",
    "            rst_arr[i][j] = clf.classes_[s_items[j]]\n",
    "    return rst_arr\n",
    "\n",
    "def apk_per_class(actual, predicted, k=1):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items per each class\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : multi list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    class_score = {}\n",
    "    micro_correct = 0.0\n",
    "    length = 0\n",
    "    global cumulative_class_score\n",
    "    if len(actual) == len(predicted):\n",
    "\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] not in class_score:\n",
    "                class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "            if actual[i] not in cumulative_class_score:\n",
    "                cumulative_class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "             \n",
    "            well_classified = False\n",
    "            for pred in predicted[i]:\n",
    "                if actual[i] == pred:\n",
    "                    class_score[actual[i]][0] += 1.0\n",
    "                    micro_correct += 1.0\n",
    "                    well_classified = True\n",
    "                    \n",
    "            if(actual[i] == CODE and well_classified == False):\n",
    "                print(well_classified , \"docID:\",i,\"prediction of \",CODE,\" was:\",predicted[i])\n",
    "                fail_list_for_code.append(i)\n",
    "            class_score[actual[i]][1] += 1.0\n",
    "            length+=1\n",
    "\n",
    "    avg_acc = 0.0 \n",
    "    for cl in class_score.keys():\n",
    "        avg = class_score[cl][0]/class_score[cl][1]\n",
    "        if(avg<0.5 and count[cl]-class_score[cl][1] > class_score[cl][1]):\n",
    "            print(\"!Low precision :! #Correct:\", class_score[cl][0], \"#Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "            fail_list.append(cl)\n",
    "        print (\"\\t\", cl, \"Acc.:\", avg, \"Correct:\", class_score[cl][0], \"Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "        cumulative_class_score[cl][0] += class_score[cl][0]\n",
    "        cumulative_class_score[cl][1] += class_score[cl][1]\n",
    "        \n",
    "        avg_acc +=avg\n",
    "\n",
    "    print ('Total Test Examples', length, \"\\nMicro Acc.(item level)\", micro_correct/length)\n",
    "    global cumulative_micro_avg\n",
    "    cumulative_micro_avg += micro_correct/length\n",
    "    return avg_acc/len(class_score)\n",
    "\n",
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    pred = clf.predict(X_test)\t  \n",
    "    probs = clf.predict_proba(X_test)\n",
    "\n",
    "    #Right now, it only uses top-5\n",
    "    for topk in range(5, 6):\n",
    "        best_n_label = transform_label(clf, probs, topk)\n",
    "\n",
    "        test_time = time() - t0\n",
    "        print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "        pred = best_n_label\n",
    "        print (\"Top-\", topk)\n",
    "        print (\"Macro Acc.(class level)\", apk_per_class(y_test, best_n_label, topk), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NSCC\t dataset for categories:\n",
      "['EA99', 'EI02', 'EI03', 'EI01', 'EI06', 'EI07', 'EI04', 'EI05', 'EG08', 'EI08', 'EI09', 'EG09', 'EA08', 'EA09', 'EA02', 'EA03', 'EA01', 'EA06', 'EA07', 'EA04', 'EA05', 'EC10', 'EE99', 'EB08', 'EF99', 'EI11', 'EI10', 'EI12', 'EA15', 'EA14', 'EA11', 'EA10', 'EA13', 'EB99', 'EA12', 'EE08', 'EE09', 'EE06', 'EE07', 'EE04', 'EE05', 'EE02', 'EE03', 'EE01', 'EB01', 'EB03', 'EB02', 'EB05', 'EB04', 'EB07', 'EB06', 'EE11', 'EE10', 'EE13', 'EE12', 'EI99', 'EE14', 'EC08', 'EC09', 'EC01', 'EC02', 'EC03', 'EC04', 'EC05', 'EC06', 'EC07', 'EF05', 'EF04', 'EF06', 'EF01', 'EF03', 'EF02', 'ED10', 'ED11', 'EG04', 'EG05', 'EG06', 'EG07', 'EG01', 'EG02', 'EG03', 'ED07', 'ED06', 'ED05', 'ED04', 'ED03', 'ED02', 'ED01', 'ED09', 'ED08', 'EH10', 'EH11', 'EH12', 'EH13', 'EH14', 'EH15', 'EG99', 'EC99', 'ED99', 'EC11', 'EH09', 'EH08', 'EH03', 'EH02', 'EH01', 'EH07', 'EH06', 'EH05', 'EH04', 'EH99', 'EG10']\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################\n",
    "### Define train/test/code list files \n",
    "#################################################################\n",
    "code_list_fn = \"NSCC_sample_data_170309_Codelist.dat\"\n",
    "train_fn = \"rev_utf8_train_big.dat\"\n",
    "test_fn = \"test_5500_from_izip_all_kkma_1col.dat\"\n",
    "all_fn ='izip_kkma_all_3cols.dat'\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "categories =  [x for x in open(code_list_fn,'r').read().split('\\n') if len(x) > 0]\n",
    "\n",
    "print(\"Loading NSCC\t dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "print(len(categories))\n",
    "\n",
    "data_train = open(train_fn).readlines()\n",
    "data_test = open(test_fn).readlines()\n",
    "all_data = open(all_fn).readlines()\n",
    "\n",
    "data_train_data, data_test_data = [], []\n",
    "y_train, y_test = [], []\n",
    "all_x, all_y = [], []\n",
    "count = {}\n",
    "\n",
    "for cat in categories:\n",
    "    count[cat] = 0\n",
    "\n",
    "for line in all_data:\n",
    "    #Shape of training file:CODE + '\\t' + name + ' %% ' + kor_kywd + ' %% ' + goal + ' %% ' + abstract + ' %% ' + efct\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        #if document code is not E, ignore that\n",
    "        if(items[0][0] != 'E'): \n",
    "            continue\n",
    "        all_x.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        all_y.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print('ERROR IN READING')\n",
    "    \"\"\"\n",
    "for line in data_train:\n",
    "\titems = line.split('\\t')\n",
    "\tif len(items) == 2:\n",
    "\t\tdata_train_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "\t\ty_train.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "for line in data_test:\n",
    "\titems = line.split('\\t')\n",
    "\tif len(items) == 2:\n",
    "\t\tdata_test_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "\t\ty_test.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    \"\"\"\n",
    "\n",
    "#divides data to train&test with 9:1 ratio\n",
    "def divide_data(r_s):\n",
    "    global data_train_data,data_test_data,y_train,y_test\n",
    "    data_train_data,data_test_data,y_train,y_test = train_test_split(all_x,all_y,random_state =r_s, train_size = 0.9)\n",
    "    #trash_a,data_test_data,trash_b,y_test = train_test_split(all_x,all_y,random_state =1, train_size = 0.60)\n",
    "    print (len(data_train_data), len(data_test_data))\n",
    "    print('data loaded')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = 0\n",
    "X_train,X_test = 0,0\n",
    "#vectorize training data using tfidf vectorizer\n",
    "def vectorize():\n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "    t0 = time()\n",
    "    my_stop_words = [unicode(x.strip(), 'utf-8') for x in open('kor_stop_word.txt','r').read().split('\\n')]\n",
    "\n",
    "    #print (len(data_train_data))\n",
    "    global vectorizer,X_train,X_test\n",
    "    #vectorizer = StemmedTfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 200000,min_df=5)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 200000,min_df=5,ngram_range=(1,1))\n",
    "    X_train = vectorizer.fit_transform(data_train_data)\n",
    "\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "    \n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "    X_test = vectorizer.transform(data_test_data)\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 R_s 5\n",
      "54297 6033\n",
      "data loaded\n",
      "Vectorizing:  5\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 54297, n_features: 89815\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 6033, n_features: 89815\n",
      "Learning:  5\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=10, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 29.207s\n",
      "test time:  0.416s\n",
      "Top- 5\n",
      "False docID: 551 prediction of  ED99  was: ['EF99' 'EA07' 'EA02' 'EA09' 'ED05']\n",
      "False docID: 1415 prediction of  ED99  was: ['ED04' 'EB06' 'ED05' 'EB01' 'ED10']\n",
      "False docID: 1668 prediction of  ED99  was: ['EI03' 'EE99' 'EE07' 'EE11' 'EE02']\n",
      "False docID: 1883 prediction of  ED99  was: ['ED09' 'ED07' 'ED01' 'ED04' 'EA06']\n",
      "False docID: 1897 prediction of  ED99  was: ['EA09' 'EA08' 'ED05' 'EA10' 'ED03']\n",
      "False docID: 2212 prediction of  ED99  was: ['EE02' 'EE09' 'ED06' 'EE06' 'EE10']\n",
      "False docID: 2502 prediction of  ED99  was: ['EF04' 'EB06' 'EF06' 'EB01' 'ED04']\n",
      "False docID: 2598 prediction of  ED99  was: ['EF04' 'EB02' 'EF06' 'EB01' 'ED04']\n",
      "False docID: 2702 prediction of  ED99  was: ['EA08' 'EF99' 'EA07' 'EE02' 'EE09']\n",
      "False docID: 2755 prediction of  ED99  was: ['EF99' 'ED05' 'EB01' 'ED02' 'EA02']\n",
      "False docID: 2992 prediction of  ED99  was: ['EA03' 'EF06' 'ED08' 'EA01' 'EA10']\n",
      "False docID: 3197 prediction of  ED99  was: ['EF02' 'EI02' 'ED11' 'EE01' 'ED08']\n",
      "False docID: 3216 prediction of  ED99  was: ['EF99' 'EB99' 'EA04' 'EA02' 'EA09']\n",
      "False docID: 3294 prediction of  ED99  was: ['EF04' 'EA08' 'EA03' 'EE09' 'EA05']\n",
      "False docID: 3345 prediction of  ED99  was: ['ED06' 'EE11' 'ED10' 'EE02' 'ED01']\n",
      "False docID: 3927 prediction of  ED99  was: ['ED07' 'ED05' 'ED01' 'EE11' 'ED06']\n",
      "False docID: 4154 prediction of  ED99  was: ['EF04' 'ED03' 'EF05' 'EF06' 'ED09']\n",
      "False docID: 4827 prediction of  ED99  was: ['ED03' 'EF06' 'EA09' 'ED05' 'EF99']\n",
      "False docID: 5461 prediction of  ED99  was: ['EA09' 'EA99' 'EB99' 'ED10' 'EF99']\n",
      "False docID: 5695 prediction of  ED99  was: ['ED08' 'EE07' 'EE01' 'EE02' 'EE99']\n",
      "False docID: 5720 prediction of  ED99  was: ['EB03' 'ED04' 'EB06' 'EF06' 'EB01']\n",
      "False docID: 5954 prediction of  ED99  was: ['EE14' 'ED08' 'EE01' 'EE02' 'EE03']\n",
      "!Low precision :! #Correct: 14.0 #Tested: 35.0 #Train 357.0\n",
      "\t EA99 Acc.: 0.4 Correct: 14.0 Tested: 35.0 #Train 357.0\n",
      "\t EI02 Acc.: 0.857142857143 Correct: 18.0 Tested: 21.0 #Train 255.0\n",
      "\t EI03 Acc.: 0.9375 Correct: 90.0 Tested: 96.0 #Train 878.0\n",
      "\t EI01 Acc.: 0.964285714286 Correct: 27.0 Tested: 28.0 #Train 213.0\n",
      "\t EI06 Acc.: 0.978260869565 Correct: 45.0 Tested: 46.0 #Train 261.0\n",
      "\t EI07 Acc.: 0.833333333333 Correct: 5.0 Tested: 6.0 #Train 52.0\n",
      "\t EI04 Acc.: 0.981818181818 Correct: 108.0 Tested: 110.0 #Train 899.0\n",
      "\t EI05 Acc.: 1.0 Correct: 31.0 Tested: 31.0 #Train 316.0\n",
      "\t EG08 Acc.: 0.9 Correct: 9.0 Tested: 10.0 #Train 118.0\n",
      "\t EI08 Acc.: 0.789473684211 Correct: 15.0 Tested: 19.0 #Train 87.0\n",
      "\t EI09 Acc.: 0.964285714286 Correct: 27.0 Tested: 28.0 #Train 344.0\n",
      "\t EG09 Acc.: 0.944444444444 Correct: 17.0 Tested: 18.0 #Train 117.0\n",
      "\t EA08 Acc.: 0.773195876289 Correct: 75.0 Tested: 97.0 #Train 785.0\n",
      "\t EA09 Acc.: 0.960591133005 Correct: 195.0 Tested: 203.0 #Train 1598.0\n",
      "\t EA02 Acc.: 0.862745098039 Correct: 88.0 Tested: 102.0 #Train 870.0\n",
      "\t EA03 Acc.: 0.805194805195 Correct: 62.0 Tested: 77.0 #Train 712.0\n",
      "\t EA01 Acc.: 0.803278688525 Correct: 49.0 Tested: 61.0 #Train 531.0\n",
      "\t EA06 Acc.: 0.886363636364 Correct: 78.0 Tested: 88.0 #Train 761.0\n",
      "\t EA07 Acc.: 0.803571428571 Correct: 90.0 Tested: 112.0 #Train 1046.0\n",
      "\t EA04 Acc.: 0.92 Correct: 69.0 Tested: 75.0 #Train 621.0\n",
      "\t EA05 Acc.: 0.945578231293 Correct: 139.0 Tested: 147.0 #Train 1306.0\n",
      "\t EC10 Acc.: 0.714285714286 Correct: 5.0 Tested: 7.0 #Train 45.0\n",
      "\t EE99 Acc.: 0.741176470588 Correct: 63.0 Tested: 85.0 #Train 774.0\n",
      "\t EB08 Acc.: 0.75 Correct: 6.0 Tested: 8.0 #Train 101.0\n",
      "\t EF99 Acc.: 0.757142857143 Correct: 53.0 Tested: 70.0 #Train 657.0\n",
      "\t EI11 Acc.: 0.924528301887 Correct: 49.0 Tested: 53.0 #Train 567.0\n",
      "\t EI10 Acc.: 1.0 Correct: 12.0 Tested: 12.0 #Train 130.0\n",
      "\t EI12 Acc.: 0.944444444444 Correct: 51.0 Tested: 54.0 #Train 490.0\n",
      "\t EA15 Acc.: 0.842105263158 Correct: 16.0 Tested: 19.0 #Train 132.0\n",
      "\t EA14 Acc.: 0.727272727273 Correct: 16.0 Tested: 22.0 #Train 236.0\n",
      "\t EA11 Acc.: 0.853658536585 Correct: 35.0 Tested: 41.0 #Train 334.0\n",
      "\t EA10 Acc.: 0.969387755102 Correct: 95.0 Tested: 98.0 #Train 917.0\n",
      "\t EA13 Acc.: 0.944444444444 Correct: 17.0 Tested: 18.0 #Train 194.0\n",
      "!Low precision :! #Correct: 22.0 #Tested: 50.0 #Train 398.0\n",
      "\t EB99 Acc.: 0.44 Correct: 22.0 Tested: 50.0 #Train 398.0\n",
      "\t EA12 Acc.: 0.733333333333 Correct: 11.0 Tested: 15.0 #Train 133.0\n",
      "\t EE08 Acc.: 0.666666666667 Correct: 14.0 Tested: 21.0 #Train 258.0\n",
      "\t EE09 Acc.: 0.833333333333 Correct: 35.0 Tested: 42.0 #Train 583.0\n",
      "\t EE06 Acc.: 0.933333333333 Correct: 70.0 Tested: 75.0 #Train 742.0\n",
      "\t EE07 Acc.: 0.833333333333 Correct: 20.0 Tested: 24.0 #Train 255.0\n",
      "\t EE04 Acc.: 0.939393939394 Correct: 31.0 Tested: 33.0 #Train 277.0\n",
      "\t EE05 Acc.: 0.928571428571 Correct: 13.0 Tested: 14.0 #Train 274.0\n",
      "\t EE02 Acc.: 0.959247648903 Correct: 306.0 Tested: 319.0 #Train 2829.0\n",
      "\t EE03 Acc.: 0.973333333333 Correct: 73.0 Tested: 75.0 #Train 754.0\n",
      "\t EE01 Acc.: 0.912280701754 Correct: 156.0 Tested: 171.0 #Train 1532.0\n",
      "\t EB01 Acc.: 0.840277777778 Correct: 121.0 Tested: 144.0 #Train 1386.0\n",
      "\t EB03 Acc.: 0.917525773196 Correct: 178.0 Tested: 194.0 #Train 1586.0\n",
      "\t EB02 Acc.: 0.871212121212 Correct: 115.0 Tested: 132.0 #Train 1190.0\n",
      "\t EB05 Acc.: 0.666666666667 Correct: 20.0 Tested: 30.0 #Train 280.0\n",
      "\t EB04 Acc.: 0.823529411765 Correct: 28.0 Tested: 34.0 #Train 228.0\n",
      "\t EB07 Acc.: 0.787878787879 Correct: 26.0 Tested: 33.0 #Train 318.0\n",
      "\t EB06 Acc.: 0.745454545455 Correct: 41.0 Tested: 55.0 #Train 473.0\n",
      "\t EE11 Acc.: 0.833333333333 Correct: 65.0 Tested: 78.0 #Train 639.0\n",
      "\t EE10 Acc.: 0.813953488372 Correct: 35.0 Tested: 43.0 #Train 507.0\n",
      "\t EE13 Acc.: 0.7 Correct: 14.0 Tested: 20.0 #Train 251.0\n",
      "\t EE12 Acc.: 0.869565217391 Correct: 20.0 Tested: 23.0 #Train 215.0\n",
      "\t EI99 Acc.: 0.655172413793 Correct: 19.0 Tested: 29.0 #Train 301.0\n",
      "\t EE14 Acc.: 0.545454545455 Correct: 6.0 Tested: 11.0 #Train 145.0\n",
      "\t EC08 Acc.: 0.9 Correct: 9.0 Tested: 10.0 #Train 85.0\n",
      "\t EC09 Acc.: 0.941176470588 Correct: 48.0 Tested: 51.0 #Train 411.0\n",
      "\t EC01 Acc.: 0.943661971831 Correct: 67.0 Tested: 71.0 #Train 664.0\n",
      "\t EC02 Acc.: 0.88679245283 Correct: 94.0 Tested: 106.0 #Train 958.0\n",
      "\t EC03 Acc.: 0.85 Correct: 51.0 Tested: 60.0 #Train 461.0\n",
      "\t EC04 Acc.: 0.933333333333 Correct: 42.0 Tested: 45.0 #Train 375.0\n",
      "\t EC05 Acc.: 0.765957446809 Correct: 36.0 Tested: 47.0 #Train 416.0\n",
      "\t EC06 Acc.: 0.692307692308 Correct: 18.0 Tested: 26.0 #Train 196.0\n",
      "\t EC07 Acc.: 0.939393939394 Correct: 31.0 Tested: 33.0 #Train 251.0\n",
      "\t EF05 Acc.: 0.918032786885 Correct: 56.0 Tested: 61.0 #Train 470.0\n",
      "\t EF04 Acc.: 0.71875 Correct: 23.0 Tested: 32.0 #Train 317.0\n",
      "\t EF06 Acc.: 0.974468085106 Correct: 229.0 Tested: 235.0 #Train 2219.0\n",
      "\t EF01 Acc.: 0.869565217391 Correct: 20.0 Tested: 23.0 #Train 256.0\n",
      "\t EF03 Acc.: 0.785714285714 Correct: 11.0 Tested: 14.0 #Train 201.0\n",
      "\t EF02 Acc.: 0.821428571429 Correct: 23.0 Tested: 28.0 #Train 286.0\n",
      "\t ED10 Acc.: 0.876404494382 Correct: 78.0 Tested: 89.0 #Train 819.0\n",
      "\t ED11 Acc.: 0.805555555556 Correct: 29.0 Tested: 36.0 #Train 346.0\n",
      "\t EG04 Acc.: 0.810810810811 Correct: 30.0 Tested: 37.0 #Train 334.0\n",
      "\t EG05 Acc.: 0.882352941176 Correct: 15.0 Tested: 17.0 #Train 125.0\n",
      "\t EG06 Acc.: 1.0 Correct: 23.0 Tested: 23.0 #Train 196.0\n",
      "\t EG07 Acc.: 1.0 Correct: 63.0 Tested: 63.0 #Train 541.0\n",
      "\t EG01 Acc.: 1.0 Correct: 7.0 Tested: 7.0 #Train 107.0\n",
      "\t EG02 Acc.: 1.0 Correct: 21.0 Tested: 21.0 #Train 151.0\n",
      "\t EG03 Acc.: 0.875 Correct: 14.0 Tested: 16.0 #Train 135.0\n",
      "\t ED07 Acc.: 0.8 Correct: 52.0 Tested: 65.0 #Train 573.0\n",
      "\t ED06 Acc.: 0.853658536585 Correct: 70.0 Tested: 82.0 #Train 616.0\n",
      "\t ED05 Acc.: 0.735849056604 Correct: 78.0 Tested: 106.0 #Train 876.0\n",
      "\t ED04 Acc.: 0.938461538462 Correct: 183.0 Tested: 195.0 #Train 1586.0\n",
      "\t ED03 Acc.: 0.897959183673 Correct: 88.0 Tested: 98.0 #Train 787.0\n",
      "\t ED02 Acc.: 0.871794871795 Correct: 34.0 Tested: 39.0 #Train 353.0\n",
      "\t ED01 Acc.: 0.863157894737 Correct: 82.0 Tested: 95.0 #Train 917.0\n",
      "\t ED09 Acc.: 0.898305084746 Correct: 53.0 Tested: 59.0 #Train 462.0\n",
      "\t EG10 Acc.: 1.0 Correct: 17.0 Tested: 17.0 #Train 159.0\n",
      "\t EH10 Acc.: 0.875 Correct: 21.0 Tested: 24.0 #Train 214.0\n",
      "\t EH11 Acc.: 0.652173913043 Correct: 15.0 Tested: 23.0 #Train 209.0\n",
      "\t EH12 Acc.: 0.6 Correct: 9.0 Tested: 15.0 #Train 123.0\n",
      "\t EH13 Acc.: 0.833333333333 Correct: 10.0 Tested: 12.0 #Train 145.0\n",
      "\t EH14 Acc.: 0.625 Correct: 5.0 Tested: 8.0 #Train 93.0\n",
      "\t EH15 Acc.: 0.666666666667 Correct: 2.0 Tested: 3.0 #Train 34.0\n",
      "\t EG99 Acc.: 0.893617021277 Correct: 42.0 Tested: 47.0 #Train 371.0\n",
      "\t EC99 Acc.: 0.5 Correct: 5.0 Tested: 10.0 #Train 93.0\n",
      "\t ED99 Acc.: 0.592592592593 Correct: 32.0 Tested: 54.0 #Train 610.0\n",
      "\t EC11 Acc.: 1.0 Correct: 2.0 Tested: 2.0 #Train 28.0\n",
      "\t EH09 Acc.: 0.911764705882 Correct: 31.0 Tested: 34.0 #Train 284.0\n",
      "\t EH08 Acc.: 0.785714285714 Correct: 11.0 Tested: 14.0 #Train 146.0\n",
      "\t EH03 Acc.: 0.904761904762 Correct: 19.0 Tested: 21.0 #Train 229.0\n",
      "\t EH02 Acc.: 0.925925925926 Correct: 75.0 Tested: 81.0 #Train 731.0\n",
      "\t EH01 Acc.: 0.907407407407 Correct: 49.0 Tested: 54.0 #Train 439.0\n",
      "\t EH07 Acc.: 0.954545454545 Correct: 42.0 Tested: 44.0 #Train 479.0\n",
      "\t EH06 Acc.: 0.954545454545 Correct: 21.0 Tested: 22.0 #Train 251.0\n",
      "!Low precision :! #Correct: 2.0 #Tested: 5.0 #Train 67.0\n",
      "\t EH05 Acc.: 0.4 Correct: 2.0 Tested: 5.0 #Train 67.0\n",
      "\t EH04 Acc.: 0.9 Correct: 9.0 Tested: 10.0 #Train 152.0\n",
      "\t EH99 Acc.: 0.727272727273 Correct: 16.0 Tested: 22.0 #Train 188.0\n",
      "\t ED08 Acc.: 0.881355932203 Correct: 52.0 Tested: 59.0 #Train 504.0\n",
      "Total Test Examples 6033 \n",
      "Micro Acc.(item level) 0.874026189292\n",
      "Macro Acc.(class level) 0.840035413449 \n",
      "\n",
      "\n",
      "Trial: 1 R_s 6\n",
      "54297 6033\n",
      "data loaded\n",
      "Vectorizing:  6\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 54297, n_features: 89974\n",
      "Extracting features from the training data using a sparse vectorizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 6033, n_features: 89974\n",
      "Learning:  6\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=10, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 30.936s\n",
      "test time:  0.431s\n",
      "Top- 5\n",
      "False docID: 245 prediction of  ED99  was: ['EA07' 'EA09' 'ED01' 'EA10' 'ED06']\n",
      "False docID: 487 prediction of  ED99  was: ['EI11' 'EE09' 'EA14' 'EE02' 'EE13']\n",
      "False docID: 959 prediction of  ED99  was: ['EF04' 'EI09' 'EF03' 'EI03' 'EF06']\n",
      "False docID: 1188 prediction of  ED99  was: ['EE05' 'ED11' 'EE12' 'ED04' 'EA09']\n",
      "False docID: 1372 prediction of  ED99  was: ['EE04' 'EE02' 'EE01' 'EE06' 'ED11']\n",
      "False docID: 1375 prediction of  ED99  was: ['EA09' 'EI05' 'EE01' 'EE99' 'ED08']\n",
      "False docID: 1445 prediction of  ED99  was: ['EE03' 'ED01' 'EB01' 'EI11' 'EA14']\n",
      "False docID: 1708 prediction of  ED99  was: ['EE99' 'EB02' 'ED04' 'EE11' 'ED01']\n",
      "False docID: 2464 prediction of  ED99  was: ['ED04' 'ED05' 'ED01' 'ED06' 'ED03']\n",
      "False docID: 2684 prediction of  ED99  was: ['EE02' 'ED07' 'ED11' 'ED08' 'EA09']\n",
      "False docID: 2774 prediction of  ED99  was: ['EE02' 'EF99' 'EA04' 'EA02' 'EA09']\n",
      "False docID: 3124 prediction of  ED99  was: ['EE09' 'EE08' 'EE01' 'EE10' 'EE02']\n",
      "False docID: 3887 prediction of  ED99  was: ['EE14' 'EE06' 'EA11' 'ED05' 'ED01']\n",
      "False docID: 3998 prediction of  ED99  was: ['EE11' 'ED08' 'EE12' 'EE06' 'EE02']\n",
      "False docID: 4792 prediction of  ED99  was: ['EA05' 'EE14' 'ED11' 'ED09' 'EA15']\n",
      "False docID: 4927 prediction of  ED99  was: ['EF04' 'EE11' 'ED07' 'ED05' 'ED03']\n",
      "False docID: 5197 prediction of  ED99  was: ['EA02' 'ED02' 'EA05' 'EA08' 'ED05']\n",
      "False docID: 5556 prediction of  ED99  was: ['ED03' 'EA07' 'EF99' 'ED06' 'EF06']\n",
      "False docID: 5826 prediction of  ED99  was: ['EE02' 'ED05' 'EA03' 'EB02' 'EA09']\n",
      "False docID: 5911 prediction of  ED99  was: ['EE01' 'EA02' 'EI03' 'ED11' 'EA05']\n",
      "\t EA99 Acc.: 0.581395348837 Correct: 25.0 Tested: 43.0 #Train 349.0\n",
      "\t EI02 Acc.: 0.866666666667 Correct: 26.0 Tested: 30.0 #Train 246.0\n",
      "\t EI03 Acc.: 0.98 Correct: 98.0 Tested: 100.0 #Train 874.0\n",
      "\t EI01 Acc.: 1.0 Correct: 29.0 Tested: 29.0 #Train 212.0\n",
      "\t EI06 Acc.: 1.0 Correct: 19.0 Tested: 19.0 #Train 288.0\n",
      "\t EI07 Acc.: 1.0 Correct: 2.0 Tested: 2.0 #Train 56.0\n",
      "\t EI04 Acc.: 0.987654320988 Correct: 80.0 Tested: 81.0 #Train 928.0\n",
      "\t EI05 Acc.: 0.935483870968 Correct: 29.0 Tested: 31.0 #Train 316.0\n",
      "\t ED10 Acc.: 0.915789473684 Correct: 87.0 Tested: 95.0 #Train 813.0\n",
      "\t EI08 Acc.: 0.909090909091 Correct: 10.0 Tested: 11.0 #Train 95.0\n",
      "\t EI09 Acc.: 1.0 Correct: 38.0 Tested: 38.0 #Train 334.0\n",
      "\t ED11 Acc.: 0.864864864865 Correct: 32.0 Tested: 37.0 #Train 345.0\n",
      "\t EA08 Acc.: 0.831460674157 Correct: 74.0 Tested: 89.0 #Train 793.0\n",
      "\t EA09 Acc.: 0.960227272727 Correct: 169.0 Tested: 176.0 #Train 1625.0\n",
      "\t EA02 Acc.: 0.789473684211 Correct: 75.0 Tested: 95.0 #Train 877.0\n",
      "\t EA03 Acc.: 0.878048780488 Correct: 72.0 Tested: 82.0 #Train 707.0\n",
      "\t EA01 Acc.: 0.775 Correct: 31.0 Tested: 40.0 #Train 552.0\n",
      "\t EA06 Acc.: 0.872093023256 Correct: 75.0 Tested: 86.0 #Train 763.0\n",
      "\t EA07 Acc.: 0.782178217822 Correct: 79.0 Tested: 101.0 #Train 1057.0\n",
      "\t EA04 Acc.: 0.853333333333 Correct: 64.0 Tested: 75.0 #Train 621.0\n",
      "\t EA05 Acc.: 0.921052631579 Correct: 140.0 Tested: 152.0 #Train 1301.0\n",
      "\t EG07 Acc.: 0.963636363636 Correct: 53.0 Tested: 55.0 #Train 549.0\n",
      "\t EE99 Acc.: 0.719101123596 Correct: 64.0 Tested: 89.0 #Train 770.0\n",
      "\t EE10 Acc.: 0.759259259259 Correct: 41.0 Tested: 54.0 #Train 496.0\n",
      "\t EF99 Acc.: 0.661538461538 Correct: 43.0 Tested: 65.0 #Train 662.0\n",
      "\t EI11 Acc.: 0.861538461538 Correct: 56.0 Tested: 65.0 #Train 555.0\n",
      "\t EI10 Acc.: 1.0 Correct: 14.0 Tested: 14.0 #Train 128.0\n",
      "\t EI12 Acc.: 0.96 Correct: 48.0 Tested: 50.0 #Train 494.0\n",
      "\t EA15 Acc.: 0.714285714286 Correct: 10.0 Tested: 14.0 #Train 137.0\n",
      "\t EA14 Acc.: 0.789473684211 Correct: 30.0 Tested: 38.0 #Train 220.0\n",
      "\t EA11 Acc.: 0.970588235294 Correct: 33.0 Tested: 34.0 #Train 341.0\n",
      "\t EA10 Acc.: 0.974576271186 Correct: 115.0 Tested: 118.0 #Train 897.0\n",
      "\t EA13 Acc.: 0.95 Correct: 19.0 Tested: 20.0 #Train 192.0\n",
      "\t EA12 Acc.: 1.0 Correct: 13.0 Tested: 13.0 #Train 135.0\n",
      "\t EB99 Acc.: 0.531914893617 Correct: 25.0 Tested: 47.0 #Train 401.0\n",
      "\t EE08 Acc.: 0.724137931034 Correct: 21.0 Tested: 29.0 #Train 250.0\n",
      "\t EE09 Acc.: 0.871428571429 Correct: 61.0 Tested: 70.0 #Train 555.0\n",
      "\t EE06 Acc.: 0.925 Correct: 74.0 Tested: 80.0 #Train 737.0\n",
      "\t EE07 Acc.: 0.928571428571 Correct: 26.0 Tested: 28.0 #Train 251.0\n",
      "\t EE04 Acc.: 0.8 Correct: 32.0 Tested: 40.0 #Train 270.0\n",
      "\t EE05 Acc.: 0.714285714286 Correct: 20.0 Tested: 28.0 #Train 260.0\n",
      "\t EE02 Acc.: 0.948453608247 Correct: 276.0 Tested: 291.0 #Train 2857.0\n",
      "\t EE03 Acc.: 0.966666666667 Correct: 87.0 Tested: 90.0 #Train 739.0\n",
      "\t EE01 Acc.: 0.913580246914 Correct: 148.0 Tested: 162.0 #Train 1541.0\n",
      "\t EB01 Acc.: 0.850828729282 Correct: 154.0 Tested: 181.0 #Train 1349.0\n",
      "\t EB03 Acc.: 0.91061452514 Correct: 163.0 Tested: 179.0 #Train 1601.0\n",
      "\t EB02 Acc.: 0.918699186992 Correct: 113.0 Tested: 123.0 #Train 1199.0\n",
      "\t EB05 Acc.: 0.8 Correct: 20.0 Tested: 25.0 #Train 285.0\n",
      "\t EB04 Acc.: 0.64 Correct: 16.0 Tested: 25.0 #Train 237.0\n",
      "\t EB07 Acc.: 0.7 Correct: 21.0 Tested: 30.0 #Train 321.0\n",
      "\t EB06 Acc.: 0.754098360656 Correct: 46.0 Tested: 61.0 #Train 467.0\n",
      "\t EE11 Acc.: 0.739130434783 Correct: 51.0 Tested: 69.0 #Train 648.0\n",
      "\t EB08 Acc.: 0.909090909091 Correct: 10.0 Tested: 11.0 #Train 98.0\n",
      "\t EE13 Acc.: 0.655172413793 Correct: 19.0 Tested: 29.0 #Train 242.0\n",
      "\t EE12 Acc.: 0.967741935484 Correct: 30.0 Tested: 31.0 #Train 207.0\n",
      "\t EI99 Acc.: 0.826086956522 Correct: 19.0 Tested: 23.0 #Train 307.0\n",
      "\t EE14 Acc.: 0.714285714286 Correct: 10.0 Tested: 14.0 #Train 142.0\n",
      "\t EC08 Acc.: 0.928571428571 Correct: 13.0 Tested: 14.0 #Train 81.0\n",
      "\t EC09 Acc.: 0.92 Correct: 46.0 Tested: 50.0 #Train 412.0\n",
      "\t EC01 Acc.: 0.905882352941 Correct: 77.0 Tested: 85.0 #Train 650.0\n",
      "\t EC02 Acc.: 0.924528301887 Correct: 98.0 Tested: 106.0 #Train 958.0\n",
      "\t EC03 Acc.: 0.867924528302 Correct: 46.0 Tested: 53.0 #Train 468.0\n",
      "\t EC04 Acc.: 0.961538461538 Correct: 50.0 Tested: 52.0 #Train 368.0\n",
      "\t EC05 Acc.: 0.854166666667 Correct: 41.0 Tested: 48.0 #Train 415.0\n",
      "\t EC06 Acc.: 0.72 Correct: 18.0 Tested: 25.0 #Train 197.0\n",
      "\t EC07 Acc.: 0.909090909091 Correct: 30.0 Tested: 33.0 #Train 251.0\n",
      "\t EF05 Acc.: 0.842105263158 Correct: 48.0 Tested: 57.0 #Train 474.0\n",
      "\t EF04 Acc.: 0.757575757576 Correct: 25.0 Tested: 33.0 #Train 316.0\n",
      "\t EF06 Acc.: 0.962962962963 Correct: 234.0 Tested: 243.0 #Train 2211.0\n",
      "\t EF01 Acc.: 0.892857142857 Correct: 25.0 Tested: 28.0 #Train 251.0\n",
      "\t EF03 Acc.: 0.92 Correct: 23.0 Tested: 25.0 #Train 190.0\n",
      "\t EF02 Acc.: 0.92 Correct: 23.0 Tested: 25.0 #Train 289.0\n",
      "\t EG08 Acc.: 0.571428571429 Correct: 8.0 Tested: 14.0 #Train 114.0\n",
      "\t EG09 Acc.: 1.0 Correct: 17.0 Tested: 17.0 #Train 118.0\n",
      "\t EG04 Acc.: 0.880952380952 Correct: 37.0 Tested: 42.0 #Train 329.0\n",
      "\t EG05 Acc.: 1.0 Correct: 11.0 Tested: 11.0 #Train 131.0\n",
      "\t EG06 Acc.: 1.0 Correct: 22.0 Tested: 22.0 #Train 197.0\n",
      "\t EC10 Acc.: 0.75 Correct: 3.0 Tested: 4.0 #Train 48.0\n",
      "\t EG01 Acc.: 0.909090909091 Correct: 10.0 Tested: 11.0 #Train 103.0\n",
      "\t EG02 Acc.: 0.8 Correct: 12.0 Tested: 15.0 #Train 157.0\n",
      "\t EG03 Acc.: 0.8 Correct: 12.0 Tested: 15.0 #Train 136.0\n",
      "\t ED07 Acc.: 0.876923076923 Correct: 57.0 Tested: 65.0 #Train 573.0\n",
      "\t ED06 Acc.: 0.825396825397 Correct: 52.0 Tested: 63.0 #Train 635.0\n",
      "\t ED05 Acc.: 0.715789473684 Correct: 68.0 Tested: 95.0 #Train 887.0\n",
      "\t ED04 Acc.: 0.96174863388 Correct: 176.0 Tested: 183.0 #Train 1598.0\n",
      "\t ED03 Acc.: 0.901960784314 Correct: 92.0 Tested: 102.0 #Train 783.0\n",
      "\t ED02 Acc.: 0.816326530612 Correct: 40.0 Tested: 49.0 #Train 343.0\n",
      "\t ED01 Acc.: 0.898876404494 Correct: 80.0 Tested: 89.0 #Train 923.0\n",
      "\t ED09 Acc.: 0.911764705882 Correct: 62.0 Tested: 68.0 #Train 453.0\n",
      "\t EG10 Acc.: 1.0 Correct: 16.0 Tested: 16.0 #Train 160.0\n",
      "\t EH10 Acc.: 0.85 Correct: 17.0 Tested: 20.0 #Train 218.0\n",
      "\t EH11 Acc.: 0.8 Correct: 20.0 Tested: 25.0 #Train 207.0\n",
      "\t EH12 Acc.: 0.5 Correct: 8.0 Tested: 16.0 #Train 122.0\n",
      "\t EH13 Acc.: 0.692307692308 Correct: 9.0 Tested: 13.0 #Train 144.0\n",
      "!Low precision :! #Correct: 6.0 #Tested: 17.0 #Train 84.0\n",
      "\t EH14 Acc.: 0.352941176471 Correct: 6.0 Tested: 17.0 #Train 84.0\n",
      "!Low precision :! #Correct: 1.0 #Tested: 4.0 #Train 33.0\n",
      "\t EH15 Acc.: 0.25 Correct: 1.0 Tested: 4.0 #Train 33.0\n",
      "\t EG99 Acc.: 0.918918918919 Correct: 34.0 Tested: 37.0 #Train 381.0\n",
      "!Low precision :! #Correct: 3.0 #Tested: 7.0 #Train 96.0\n",
      "\t EC99 Acc.: 0.428571428571 Correct: 3.0 Tested: 7.0 #Train 96.0\n",
      "\t ED99 Acc.: 0.672131147541 Correct: 41.0 Tested: 61.0 #Train 603.0\n",
      "\t EC11 Acc.: 1.0 Correct: 1.0 Tested: 1.0 #Train 29.0\n",
      "\t EH09 Acc.: 0.974358974359 Correct: 38.0 Tested: 39.0 #Train 279.0\n",
      "\t EH08 Acc.: 0.769230769231 Correct: 10.0 Tested: 13.0 #Train 147.0\n",
      "\t EH03 Acc.: 0.96 Correct: 24.0 Tested: 25.0 #Train 225.0\n",
      "\t EH02 Acc.: 0.918918918919 Correct: 68.0 Tested: 74.0 #Train 738.0\n",
      "\t EH01 Acc.: 0.924528301887 Correct: 49.0 Tested: 53.0 #Train 440.0\n",
      "\t EH07 Acc.: 0.914893617021 Correct: 43.0 Tested: 47.0 #Train 476.0\n",
      "\t EH06 Acc.: 0.923076923077 Correct: 24.0 Tested: 26.0 #Train 247.0\n",
      "\t EH05 Acc.: 0.666666666667 Correct: 2.0 Tested: 3.0 #Train 69.0\n",
      "\t EH04 Acc.: 0.941176470588 Correct: 16.0 Tested: 17.0 #Train 145.0\n",
      "\t EH99 Acc.: 0.9 Correct: 18.0 Tested: 20.0 #Train 190.0\n",
      "\t ED08 Acc.: 0.86 Correct: 43.0 Tested: 50.0 #Train 513.0\n",
      "Total Test Examples 6033 \n",
      "Micro Acc.(item level) 0.875517984419\n",
      "Macro Acc.(class level) 0.845610648214 \n",
      "\n",
      "\n",
      "Trial: 2 R_s 7\n",
      "54297 6033\n",
      "data loaded\n",
      "Vectorizing:  7\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 54297, n_features: 90093\n",
      "Extracting features from the training data using a sparse vectorizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 6033, n_features: 90093\n",
      "Learning:  7\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=10, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 28.615s\n",
      "test time:  0.375s\n",
      "Top- 5\n",
      "False docID: 202 prediction of  ED99  was: ['ED06' 'EA08' 'EA07' 'EG07' 'ED01']\n",
      "False docID: 291 prediction of  ED99  was: ['EB03' 'EC09' 'EA03' 'ED09' 'EA09']\n",
      "False docID: 462 prediction of  ED99  was: ['EA05' 'EA08' 'EE03' 'ED07' 'ED08']\n",
      "False docID: 624 prediction of  ED99  was: ['EA99' 'EA02' 'ED10' 'EE99' 'EE02']\n",
      "False docID: 633 prediction of  ED99  was: ['EB03' 'ED02' 'EC05' 'ED01' 'EF06']\n",
      "False docID: 1950 prediction of  ED99  was: ['EA10' 'EE05' 'EE06' 'EE99' 'EE09']\n",
      "False docID: 2046 prediction of  ED99  was: ['ED09' 'EA02' 'EA03' 'ED05' 'ED03']\n",
      "False docID: 2237 prediction of  ED99  was: ['EI03' 'EE01' 'EA02' 'ED11' 'EA05']\n",
      "False docID: 2349 prediction of  ED99  was: ['EE04' 'EE99' 'EA01' 'EE06' 'ED04']\n",
      "False docID: 2574 prediction of  ED99  was: ['EE09' 'EA14' 'EI11' 'EE13' 'EE01']\n",
      "False docID: 2698 prediction of  ED99  was: ['EA03' 'ED02' 'EA01' 'EA05' 'ED07']\n",
      "False docID: 2700 prediction of  ED99  was: ['ED10' 'EA05' 'ED01' 'ED04' 'ED05']\n",
      "False docID: 2992 prediction of  ED99  was: ['EI03' 'EA01' 'ED10' 'EE01' 'ED08']\n",
      "False docID: 3070 prediction of  ED99  was: ['EC01' 'EA05' 'EB01' 'ED02' 'EA02']\n",
      "False docID: 3149 prediction of  ED99  was: ['EE99' 'EA05' 'EB99' 'EI11' 'EG99']\n",
      "False docID: 3491 prediction of  ED99  was: ['EA10' 'EA99' 'EE02' 'ED06' 'EA05']\n",
      "False docID: 3711 prediction of  ED99  was: ['EB99' 'EB01' 'EA99' 'EA09' 'EB02']\n",
      "False docID: 3881 prediction of  ED99  was: ['EC06' 'EC03' 'EB03' 'EC07' 'EC09']\n",
      "False docID: 3939 prediction of  ED99  was: ['ED07' 'EB02' 'ED04' 'EE11' 'ED01']\n",
      "False docID: 4043 prediction of  ED99  was: ['EE13' 'EA06' 'EE02' 'ED08' 'EE01']\n",
      "False docID: 4646 prediction of  ED99  was: ['EB02' 'EA09' 'EA07' 'EA08' 'ED06']\n",
      "False docID: 4725 prediction of  ED99  was: ['EA03' 'EC09' 'EE99' 'EA99' 'EE02']\n",
      "False docID: 4747 prediction of  ED99  was: ['EF04' 'EH02' 'ED06' 'ED03' 'EF06']\n",
      "False docID: 4830 prediction of  ED99  was: ['EA09' 'EA99' 'ED10' 'EB99' 'EF99']\n",
      "False docID: 4918 prediction of  ED99  was: ['EC11' 'EI05' 'EA15' 'EE14' 'ED11']\n",
      "False docID: 4968 prediction of  ED99  was: ['EE05' 'EF05' 'EE11' 'EA09' 'ED05']\n",
      "False docID: 5035 prediction of  ED99  was: ['EF99' 'ED03' 'ED05' 'EF04' 'ED09']\n",
      "False docID: 5185 prediction of  ED99  was: ['ED04' 'EA07' 'EA02' 'EA09' 'ED05']\n",
      "False docID: 5206 prediction of  ED99  was: ['ED04' 'EF06' 'EB02' 'ED06' 'EI05']\n",
      "False docID: 5314 prediction of  ED99  was: ['EA09' 'EA07' 'ED01' 'EA10' 'ED06']\n",
      "False docID: 5393 prediction of  ED99  was: ['EF05' 'EA02' 'EG99' 'EE11' 'EE99']\n",
      "False docID: 5657 prediction of  ED99  was: ['EA02' 'ED05' 'EA08' 'EA07' 'ED06']\n",
      "False docID: 5827 prediction of  ED99  was: ['EF06' 'EA03' 'EA01' 'ED08' 'EA10']\n",
      "!Low precision :! #Correct: 23.0 #Tested: 50.0 #Train 342.0\n",
      "\t EA99 Acc.: 0.46 Correct: 23.0 Tested: 50.0 #Train 342.0\n",
      "\t EI02 Acc.: 0.9 Correct: 18.0 Tested: 20.0 #Train 256.0\n",
      "\t EI03 Acc.: 0.954128440367 Correct: 104.0 Tested: 109.0 #Train 865.0\n",
      "\t EI01 Acc.: 0.958333333333 Correct: 23.0 Tested: 24.0 #Train 217.0\n",
      "\t EI06 Acc.: 0.96 Correct: 24.0 Tested: 25.0 #Train 282.0\n",
      "\t EI07 Acc.: 0.5 Correct: 3.0 Tested: 6.0 #Train 52.0\n",
      "\t EI04 Acc.: 0.957446808511 Correct: 90.0 Tested: 94.0 #Train 915.0\n",
      "\t EI05 Acc.: 0.928571428571 Correct: 39.0 Tested: 42.0 #Train 305.0\n",
      "\t EG08 Acc.: 0.615384615385 Correct: 8.0 Tested: 13.0 #Train 115.0\n",
      "\t EI08 Acc.: 0.833333333333 Correct: 5.0 Tested: 6.0 #Train 100.0\n",
      "\t EI09 Acc.: 1.0 Correct: 34.0 Tested: 34.0 #Train 338.0\n",
      "\t EG09 Acc.: 0.916666666667 Correct: 11.0 Tested: 12.0 #Train 123.0\n",
      "\t EA08 Acc.: 0.787234042553 Correct: 74.0 Tested: 94.0 #Train 788.0\n",
      "\t EA09 Acc.: 0.972677595628 Correct: 178.0 Tested: 183.0 #Train 1618.0\n",
      "\t EA02 Acc.: 0.808510638298 Correct: 76.0 Tested: 94.0 #Train 878.0\n",
      "\t EA03 Acc.: 0.78125 Correct: 50.0 Tested: 64.0 #Train 725.0\n",
      "\t EA01 Acc.: 0.735294117647 Correct: 50.0 Tested: 68.0 #Train 524.0\n",
      "\t EA06 Acc.: 0.914893617021 Correct: 86.0 Tested: 94.0 #Train 755.0\n",
      "\t EA07 Acc.: 0.808695652174 Correct: 93.0 Tested: 115.0 #Train 1043.0\n",
      "\t EA04 Acc.: 0.840579710145 Correct: 58.0 Tested: 69.0 #Train 627.0\n",
      "\t EA05 Acc.: 0.93661971831 Correct: 133.0 Tested: 142.0 #Train 1311.0\n",
      "\t EC10 Acc.: 1.0 Correct: 2.0 Tested: 2.0 #Train 50.0\n",
      "\t EE99 Acc.: 0.730769230769 Correct: 57.0 Tested: 78.0 #Train 781.0\n",
      "\t EB08 Acc.: 0.571428571429 Correct: 8.0 Tested: 14.0 #Train 95.0\n",
      "\t EF99 Acc.: 0.662337662338 Correct: 51.0 Tested: 77.0 #Train 650.0\n",
      "\t EI11 Acc.: 0.912280701754 Correct: 52.0 Tested: 57.0 #Train 563.0\n",
      "\t EI10 Acc.: 1.0 Correct: 18.0 Tested: 18.0 #Train 124.0\n",
      "\t EI12 Acc.: 0.936170212766 Correct: 44.0 Tested: 47.0 #Train 497.0\n",
      "\t EA15 Acc.: 0.8 Correct: 12.0 Tested: 15.0 #Train 136.0\n",
      "\t EA14 Acc.: 0.823529411765 Correct: 14.0 Tested: 17.0 #Train 241.0\n",
      "\t EA11 Acc.: 0.975609756098 Correct: 40.0 Tested: 41.0 #Train 334.0\n",
      "\t EA10 Acc.: 0.967032967033 Correct: 88.0 Tested: 91.0 #Train 924.0\n",
      "\t EA13 Acc.: 0.965517241379 Correct: 28.0 Tested: 29.0 #Train 183.0\n",
      "\t EA12 Acc.: 1.0 Correct: 16.0 Tested: 16.0 #Train 132.0\n",
      "\t EB99 Acc.: 0.583333333333 Correct: 28.0 Tested: 48.0 #Train 400.0\n",
      "\t EE08 Acc.: 0.903225806452 Correct: 28.0 Tested: 31.0 #Train 248.0\n",
      "\t EE09 Acc.: 0.868421052632 Correct: 66.0 Tested: 76.0 #Train 549.0\n",
      "\t EE06 Acc.: 0.87012987013 Correct: 67.0 Tested: 77.0 #Train 740.0\n",
      "\t EE07 Acc.: 0.969696969697 Correct: 32.0 Tested: 33.0 #Train 246.0\n",
      "\t EE04 Acc.: 0.96875 Correct: 31.0 Tested: 32.0 #Train 278.0\n",
      "\t EE05 Acc.: 0.794117647059 Correct: 27.0 Tested: 34.0 #Train 254.0\n",
      "\t EE02 Acc.: 0.934285714286 Correct: 327.0 Tested: 350.0 #Train 2798.0\n",
      "\t EE03 Acc.: 0.986111111111 Correct: 71.0 Tested: 72.0 #Train 757.0\n",
      "\t EE01 Acc.: 0.969879518072 Correct: 161.0 Tested: 166.0 #Train 1537.0\n",
      "\t EB01 Acc.: 0.898305084746 Correct: 159.0 Tested: 177.0 #Train 1353.0\n",
      "\t EB03 Acc.: 0.89156626506 Correct: 148.0 Tested: 166.0 #Train 1614.0\n",
      "\t EB02 Acc.: 0.90780141844 Correct: 128.0 Tested: 141.0 #Train 1181.0\n",
      "\t EB05 Acc.: 0.65625 Correct: 21.0 Tested: 32.0 #Train 278.0\n",
      "\t EB04 Acc.: 0.878787878788 Correct: 29.0 Tested: 33.0 #Train 229.0\n",
      "\t EB07 Acc.: 0.857142857143 Correct: 30.0 Tested: 35.0 #Train 316.0\n",
      "\t EB06 Acc.: 0.816326530612 Correct: 40.0 Tested: 49.0 #Train 479.0\n",
      "\t EE11 Acc.: 0.742857142857 Correct: 52.0 Tested: 70.0 #Train 647.0\n",
      "\t EE10 Acc.: 0.816326530612 Correct: 40.0 Tested: 49.0 #Train 501.0\n",
      "\t EE13 Acc.: 0.85 Correct: 17.0 Tested: 20.0 #Train 251.0\n",
      "\t EE12 Acc.: 1.0 Correct: 20.0 Tested: 20.0 #Train 218.0\n",
      "\t EI99 Acc.: 0.638888888889 Correct: 23.0 Tested: 36.0 #Train 294.0\n",
      "\t EE14 Acc.: 0.769230769231 Correct: 10.0 Tested: 13.0 #Train 143.0\n",
      "\t EC08 Acc.: 1.0 Correct: 8.0 Tested: 8.0 #Train 87.0\n",
      "\t EC09 Acc.: 0.946428571429 Correct: 53.0 Tested: 56.0 #Train 406.0\n",
      "\t EC01 Acc.: 0.868852459016 Correct: 53.0 Tested: 61.0 #Train 674.0\n",
      "\t EC02 Acc.: 0.883333333333 Correct: 106.0 Tested: 120.0 #Train 944.0\n",
      "\t EC03 Acc.: 0.772727272727 Correct: 34.0 Tested: 44.0 #Train 477.0\n",
      "\t EC04 Acc.: 1.0 Correct: 39.0 Tested: 39.0 #Train 381.0\n",
      "\t EC05 Acc.: 0.897435897436 Correct: 35.0 Tested: 39.0 #Train 424.0\n",
      "\t EC06 Acc.: 0.7 Correct: 14.0 Tested: 20.0 #Train 202.0\n",
      "\t EC07 Acc.: 0.972222222222 Correct: 35.0 Tested: 36.0 #Train 248.0\n",
      "\t EF05 Acc.: 0.88 Correct: 44.0 Tested: 50.0 #Train 481.0\n",
      "\t EF04 Acc.: 0.666666666667 Correct: 20.0 Tested: 30.0 #Train 319.0\n",
      "\t EF06 Acc.: 0.944444444444 Correct: 221.0 Tested: 234.0 #Train 2220.0\n",
      "\t EF01 Acc.: 0.888888888889 Correct: 24.0 Tested: 27.0 #Train 252.0\n",
      "\t EF03 Acc.: 0.904761904762 Correct: 19.0 Tested: 21.0 #Train 194.0\n",
      "\t EF02 Acc.: 0.952380952381 Correct: 20.0 Tested: 21.0 #Train 293.0\n",
      "\t ED10 Acc.: 0.858695652174 Correct: 79.0 Tested: 92.0 #Train 816.0\n",
      "\t ED11 Acc.: 0.833333333333 Correct: 25.0 Tested: 30.0 #Train 352.0\n",
      "\t EG04 Acc.: 0.846153846154 Correct: 33.0 Tested: 39.0 #Train 332.0\n",
      "\t EG05 Acc.: 0.882352941176 Correct: 15.0 Tested: 17.0 #Train 125.0\n",
      "\t EG06 Acc.: 1.0 Correct: 28.0 Tested: 28.0 #Train 191.0\n",
      "\t EG07 Acc.: 0.913793103448 Correct: 53.0 Tested: 58.0 #Train 546.0\n",
      "\t EG01 Acc.: 0.736842105263 Correct: 14.0 Tested: 19.0 #Train 95.0\n",
      "\t EG02 Acc.: 0.933333333333 Correct: 14.0 Tested: 15.0 #Train 157.0\n",
      "\t EG03 Acc.: 0.95 Correct: 19.0 Tested: 20.0 #Train 131.0\n",
      "\t ED07 Acc.: 0.72131147541 Correct: 44.0 Tested: 61.0 #Train 577.0\n",
      "\t ED06 Acc.: 0.90625 Correct: 58.0 Tested: 64.0 #Train 634.0\n",
      "\t ED05 Acc.: 0.622222222222 Correct: 56.0 Tested: 90.0 #Train 892.0\n",
      "\t ED04 Acc.: 0.91061452514 Correct: 163.0 Tested: 179.0 #Train 1602.0\n",
      "\t ED03 Acc.: 0.93 Correct: 93.0 Tested: 100.0 #Train 785.0\n",
      "\t ED02 Acc.: 0.641025641026 Correct: 25.0 Tested: 39.0 #Train 353.0\n",
      "\t ED01 Acc.: 0.903846153846 Correct: 94.0 Tested: 104.0 #Train 908.0\n",
      "\t ED09 Acc.: 0.843137254902 Correct: 43.0 Tested: 51.0 #Train 470.0\n",
      "\t EG10 Acc.: 1.0 Correct: 20.0 Tested: 20.0 #Train 156.0\n",
      "\t EH10 Acc.: 0.615384615385 Correct: 16.0 Tested: 26.0 #Train 212.0\n",
      "\t EH11 Acc.: 0.75 Correct: 18.0 Tested: 24.0 #Train 208.0\n",
      "\t EH12 Acc.: 0.764705882353 Correct: 13.0 Tested: 17.0 #Train 121.0\n",
      "\t EH13 Acc.: 0.8125 Correct: 13.0 Tested: 16.0 #Train 141.0\n",
      "!Low precision :! #Correct: 3.0 #Tested: 8.0 #Train 93.0\n",
      "\t EH14 Acc.: 0.375 Correct: 3.0 Tested: 8.0 #Train 93.0\n",
      "\t EH15 Acc.: 0.666666666667 Correct: 4.0 Tested: 6.0 #Train 31.0\n",
      "\t EG99 Acc.: 0.9 Correct: 36.0 Tested: 40.0 #Train 378.0\n",
      "\t EC99 Acc.: 0.555555555556 Correct: 5.0 Tested: 9.0 #Train 94.0\n",
      "!Low precision :! #Correct: 31.0 #Tested: 64.0 #Train 600.0\n",
      "\t ED99 Acc.: 0.484375 Correct: 31.0 Tested: 64.0 #Train 600.0\n",
      "\t EC11 Acc.: 0.666666666667 Correct: 2.0 Tested: 3.0 #Train 27.0\n",
      "\t EH09 Acc.: 0.871794871795 Correct: 34.0 Tested: 39.0 #Train 279.0\n",
      "\t EH08 Acc.: 0.8 Correct: 12.0 Tested: 15.0 #Train 145.0\n",
      "\t EH03 Acc.: 0.916666666667 Correct: 22.0 Tested: 24.0 #Train 226.0\n",
      "\t EH02 Acc.: 0.896103896104 Correct: 69.0 Tested: 77.0 #Train 735.0\n",
      "\t EH01 Acc.: 0.938775510204 Correct: 46.0 Tested: 49.0 #Train 444.0\n",
      "\t EH07 Acc.: 0.901960784314 Correct: 46.0 Tested: 51.0 #Train 472.0\n",
      "\t EH06 Acc.: 0.884615384615 Correct: 23.0 Tested: 26.0 #Train 247.0\n",
      "\t EH05 Acc.: 1.0 Correct: 5.0 Tested: 5.0 #Train 67.0\n",
      "\t EH04 Acc.: 0.85 Correct: 17.0 Tested: 20.0 #Train 142.0\n",
      "!Low precision :! #Correct: 6.0 #Tested: 13.0 #Train 197.0\n",
      "\t EH99 Acc.: 0.461538461538 Correct: 6.0 Tested: 13.0 #Train 197.0\n",
      "\t ED08 Acc.: 0.897959183673 Correct: 44.0 Tested: 49.0 #Train 514.0\n",
      "Total Test Examples 6033 \n",
      "Micro Acc.(item level) 0.8670644787\n",
      "Macro Acc.(class level) 0.83970318206 \n",
      "\n",
      "\n",
      "Cumulative 0.872202884137\n"
     ]
    }
   ],
   "source": [
    "accumulated_fail_list = {}\n",
    "TRIAL_SIZE = 3\n",
    "RANDOM_STATE_START = 5\n",
    "cumulative_micro_avg = 0\n",
    "cumulative_class_score = {}\n",
    "CODE = 'ED99' #code you want to investigate, doesn't affect the result\n",
    "#try the code with different train/test splts\n",
    "for t,trial in enumerate(range(RANDOM_STATE_START,RANDOM_STATE_START + TRIAL_SIZE)):\n",
    "    print(\"Trial:\",t,\"R_s\",trial)\n",
    "    divide_data(trial)\n",
    "    print(\"Vectorizing: \",trial)\n",
    "    vectorize()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    fail_list = []\n",
    "    fail_list_for_code = []\n",
    "    feature_names = np.asarray(feature_names)\n",
    "    # Train SGD model\n",
    "    print(\"Learning: \",trial)\n",
    "    \n",
    "    #suggested by sklearn tutorial:http://scikit-learn.org/stable/modules/sgd.html#tips-on-practical-use\n",
    "    suggested_n_iter = np.ceil(10**6/len(data_train_data)) \n",
    "    \n",
    "    #DONT USE ELASTICNET as penalty, it will give lower accuracy\n",
    "    clf = SGDClassifier(loss='modified_huber', alpha=0.0001, n_iter=10, penalty='l2')\n",
    "    benchmark(clf)\n",
    "    for x in fail_list:\n",
    "        if not accumulated_fail_list.has_key(x):\n",
    "            accumulated_fail_list[x] = 0\n",
    "        accumulated_fail_list[x] +=1\n",
    "    #print(fail_list)\n",
    "    for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] == TRIAL_SIZE:\n",
    "            print(x,accumulated_fail_list[x])\n",
    "#print the average micro accuracy            \n",
    "print('Cumulative',cumulative_micro_avg/TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this block prints the statistics(info about each category)\n",
    "statistics = open('statistics_3rdtest.txt','w')\n",
    "statistics.write('\\t'.join(['CODE','ALL','TRAIN','TEST','CORRECT','correct%'])+'\\n')\n",
    "\n",
    "for x in count:\n",
    "    a_row = [x,count[x],count[x]-cumulative_class_score[x][1],cumulative_class_score[x][1],cumulative_class_score[x][0],cumulative_class_score[x][0]/cumulative_class_score[x][1]]#code,train,tested,correct\n",
    "    for i in range(len(a_row)):\n",
    "        a_row[i] = str(a_row[i])\n",
    "    statistics.write('\\t'.join(a_row)+'\\n')\n",
    "statistics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EH12 1\n",
      "EA99 1\n",
      "EH15 1\n",
      "ED99 1\n"
     ]
    }
   ],
   "source": [
    "#which categories failed most\n",
    "for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] >= TRIAL_SIZE -2:\n",
    "            print(x,accumulated_fail_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EA99 [20.0, 41.0] 372\n",
      "EH12 [4.0, 10.0] 106\n",
      "EH15 [2.0, 5.0] 25\n",
      "ED99 [14.0, 40.0] 582\n"
     ]
    }
   ],
   "source": [
    "#which categories failed most 2\n",
    "for x in cumulative_class_score:\n",
    "    if(x[0] == \"E\"):\n",
    "        if(cumulative_class_score[x][0]/cumulative_class_score[x][1]<0.5):\n",
    "            print(x,cumulative_class_score[x],count[x]*TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the index for specific code\n",
    "# EH14 is 95\n",
    "# EH15 is 96\n",
    "# EA99 is 15\n",
    "# ed99 is 48\n",
    "# ee00 is 63\n",
    "print(suggested_n_iter)\n",
    "CODE_INDEX = clf.classes_.tolist().index(CODE)\n",
    "CODE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517542185785 endoscopi\n",
      "0.554998145394 lamp\n",
      "0.551419272672 triangular\n",
      "0.563239502759 turnov\n",
      "0.608646924589 wearabl\n",
      "0.66730913174 \n",
      "0.519867299344 \n",
      "0.925674999351 \n",
      "0.602099061057 \n",
      "0.746020559369 \n",
      "0.79116022665 \n",
      "0.621038667741 \n",
      "0.520720374026 \n",
      "0.520453219473 \n",
      "0.596783766286 \n",
      "0.633231151025 \n",
      "0.608676919415 \n",
      "0.644928267792 \n",
      "0.656657027617 \n",
      "0.533554481677 \n",
      "0.559106759631 \n",
      "0.500680965876 \n",
      "0.562054476646 \n",
      "0.749688808711 \n",
      "0.586173454145 \n",
      "0.580687250659 \n",
      "0.563884064454 \n",
      "0.514010717075 \n",
      "0.618096097616 \n"
     ]
    }
   ],
   "source": [
    "#which words have high weight for CODE_INDEX\n",
    "white_list = []\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(clf.coef_[CODE_INDEX][i]>0.5):\n",
    "        print(clf.coef_[CODE_INDEX][i],x)\n",
    "        white_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = file(\"features.txt\",\"w\")\n",
    "\n",
    "for x in feature_names:\n",
    "    out.write(x.encode('utf-8','ignore')+\"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED99                       sunlight generation electricity carbon fiber electricity mat new regeneration energy                                                                                                                                                                                                                                                                                                                                                                   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_test[fail_list_for_code[0]],data_test_data[fail_list_for_code[0]])\n",
    "fail_data = []\n",
    "for x in fail_list_for_code:\n",
    "    fail_data.append(data_test_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail size: 29\n",
      "                      sunlight generation electricity carbon fiber electricity mat new regeneration energy                                                                                                                                                                                                                                                                                                                                                                   \n",
      "\n",
      "                   educational program energy networking supporting export supporting small - size company                                                                                                                                                                                                                                     \n",
      "\n",
      "              micro ev battery controller power module                                                                                                                            \n",
      "\n",
      "                smart glasses augmented reality head mounted display wearable device optical system                                                                                                         \n",
      "\n",
      "           marine robot                                                                                                                                                                                                                                          \n",
      "\n",
      "    display blu lcd                                              \n",
      "\n",
      "                   high thermal mesh tech tension insert injection air cooled bm a lightweight bm a                                                                         \n",
      "\n",
      "               nano process nano patterning graph ene transfer surface control structure guiding polymer                                                                                                                                                                                                             \n",
      "\n",
      "            6 . car 7 . sensor 8 . antenna 9 . radar 1 0 . condition                                                                                                                                                                                                 \n",
      "\n",
      "                storybook picture - book interaction realize child                                                                                                                                                          \n",
      "\n",
      "                              patch type cardiac bio marker bio sensor highly sensitive sensor module dynamic noise reduction performance evaluation electrochemical system integration                                                                                                                                                                                                                            \n",
      "\n",
      "              printed electronics micro machining print master flexibility imprint                                                                                                                                                                                                    \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      wide fire surveillance high reliability fire monitoring low cost thermal camera intelligent fire detection                                                                                                            \n",
      "\n",
      "                   d gps beacon g nss                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "           cctv energy saving ac cob led security light high efficiency                                                                                                                          \n",
      "\n",
      "                     guide a person who is visually imp a i app mobile bluetooth                                                                                                                                                                                                                                                                                                                                      \n",
      "\n",
      "                 electrode position electronic equipment impression of a pearl gray paints / pigment electrostatic painting                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
      "\n",
      "                         combined optical and analog sensor measurement equipment structure health monitoring fiber bragg grating sensor monitoring damage detection load history                                                                     \n",
      "\n",
      "                    lin interface alternator power control module mi com                                                                                                                                                                                                                  \n",
      "\n",
      "          spectrum relocation auction assignment                                                                                                            \n",
      "\n",
      "                        nice integrated system new industry for future life good service ict based field business expertise convergence education smart living creative converging female professional education research job career i interlink                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      "\n",
      "                        functional safety automotive safety integrity level safety integrity level safety related system electrical elector nic control system                                                                                                                        \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  radar u av fm cw collision avoid image detect                                                                                                                                                                                                                                                                                                                                                     \n",
      "\n",
      "                           midterm r & d strategy first mover r & d strategy                                                                                                                                                  \n",
      "\n",
      "                     mobile x - ray image sensor design identity usability home diagnostic service                                                                                                                                                                                         \n",
      "\n",
      "                            traditional korean instrument metal percussion acoustical analysis sound synthesis toolkit softening beat impulse response subjective test                                                                                                                                                                                                                                                \n",
      "\n",
      "                 gas sensor i ot smart device sub miniature low power consumption                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "\n",
      "               nano process nano patterning graph ene transfer surface control structure guiding polymer                                                                                                                                                                                                            \n",
      "\n",
      "                  eco - friendly car emc ev low frequency evaluation method                                                                                                                                                              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = vectorizer.transform(fail_data)\n",
    "v_array = v.toarray()\n",
    "important_word = []\n",
    "for i in range(200000):\n",
    "    important_word.append([])\n",
    "buffer = 200000*[0]\n",
    "print(\"Fail size:\",len(fail_data))\n",
    "for i,doc in enumerate(fail_data):\n",
    "    print(doc)\n",
    "    #print(v.toarray()[i])\n",
    "    #rev_list =  reversed(np.argsort(v.toarray()[i]))\n",
    "    for j in range(len(v_array[i])):\n",
    "        if(v_array[i][j]>0.0):\n",
    "     #       print(index,feature_names[index])\n",
    "            buffer[j] = 1\n",
    "        \n",
    "    for j in range(len(buffer)):\n",
    "        if buffer[j] > 0:\n",
    "            important_word[j].append(i)\n",
    "            buffer[j] = 0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 [1, 2, 4, 8, 9, 10, 11, 13, 18, 19, 20, 21, 22, 23, 25, 26, 28]  -0.0589689547829\n",
      "12 [0, 3, 5, 6, 7, 10, 14, 17, 20, 21, 24, 27]  -0.014681700471\n",
      "11 [1, 4, 11, 12, 15, 19, 20, 21, 23, 24, 26]  0.00160561546174\n",
      "12 [6, 7, 8, 10, 11, 12, 13, 16, 18, 26, 27, 28]  -0.0459541954862\n",
      "11 [4, 7, 8, 10, 12, 15, 17, 22, 24, 26, 27]  -0.0929137712641\n",
      "16 [1, 2, 4, 8, 9, 10, 11, 13, 14, 16, 18, 19, 22, 24, 25, 26]  0.204275988193\n",
      "15 [0, 5, 6, 7, 9, 10, 11, 16, 17, 18, 22, 24, 25, 27, 28]  -0.106692923436\n",
      "14 [0, 2, 4, 5, 6, 9, 11, 14, 15, 16, 18, 22, 24, 26]  -0.0150238899123\n",
      "16 [0, 1, 2, 3, 7, 8, 9, 13, 14, 16, 18, 20, 24, 25, 26, 27]  0.0356542569683\n"
     ]
    }
   ],
   "source": [
    "for i,count in enumerate(important_word):\n",
    "    if len(count) > 10:\n",
    "        print(len(count),count,feature_names[i],clf.coef_[63][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
