{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classification of text documents using sparse features\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#\t\t  Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#\t\t  Mathieu Blondel <mathieu@mblondel.org>\n",
    "#\t\t  Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import nltk.stem\n",
    "from optparse import OptionParser\n",
    "import sys, copy\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def transform_label(clf, prob, topk):\n",
    "    rst_arr = np.empty( (len(prob), topk), dtype=object) \n",
    "    for i in range(len(prob)):\n",
    "        s_items = np.argsort(prob[i])[-topk:]\n",
    "\n",
    "        for j in range(len(s_items)):\n",
    "            rst_arr[i][j] = clf.classes_[s_items[j]]\n",
    "\n",
    "\n",
    "    return rst_arr\n",
    "\n",
    "def apk_per_class(actual, predicted, k=1):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items per each class\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : multi list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    class_score = {}\n",
    "    micro_correct = 0.0\n",
    "    length = 0\n",
    "    global e_correct,e_tested\n",
    "    global cumulative_class_score\n",
    "    e_correct = 0\n",
    "    e_tested = 0\n",
    "    if len(actual) == len(predicted):\t\t\n",
    "\n",
    "        for\ti in range(len(actual)):\n",
    "            if actual[i] not in class_score:\n",
    "                class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "            if actual[i] not in cumulative_class_score:\n",
    "                cumulative_class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "             \n",
    "            well_classified = False\n",
    "            if(guess[i] is not \"\"):\n",
    "                predicted[i][0] = guess[i]    \n",
    "            for pred in predicted[i]:\n",
    "\n",
    "                if actual[i] == pred:\n",
    "                    class_score[actual[i]][0] += 1.0\n",
    "                    micro_correct += 1.0\n",
    "                    well_classified = True\n",
    "                    \n",
    "            if(type(actual[i]) is list):\n",
    "                print(\"!! actual[\",i,\"] is \",actual[i])\n",
    "            if(actual[i] == CODE and well_classified == False):\n",
    "                print(well_classified , \"docID:\",i,\"prediction of \",CODE,\" was:\",predicted[i])\n",
    "                fail_list_for_code.append(i)\n",
    "            class_score[actual[i]][1] += 1.0\n",
    "            length+=1\n",
    "\n",
    "    avg_acc = 0.0 \n",
    "    for cl in class_score.keys():\n",
    "        avg = class_score[cl][0]/class_score[cl][1]\n",
    "        if(avg<0.5 and count[cl]-class_score[cl][1] > class_score[cl][1]):\n",
    "            print(\"!Low precision :! #Correct:\", class_score[cl][0], \"#Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "            fail_list.append(cl)\n",
    "        print (\"\\t\", cl, \"Acc.:\", avg, \"Correct:\", class_score[cl][0], \"Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "        if cl[0] =='E':\n",
    "            e_correct += class_score[cl][0]\n",
    "            e_tested += class_score[cl][1]\n",
    "        cumulative_class_score[cl][0] += class_score[cl][0]\n",
    "        cumulative_class_score[cl][1] += class_score[cl][1]\n",
    "        \n",
    "        avg_acc +=avg\n",
    "\n",
    "    print ('Total Test Examples', length, \"\\nMicro Acc.(item level)\", micro_correct/length)\n",
    "    print('Average of E',e_correct/e_tested)\n",
    "    global cumulative_micro_avg\n",
    "    cumulative_micro_avg += micro_correct/length\n",
    "    return avg_acc/len(class_score)\n",
    "\n",
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    # Top 1 \n",
    "    pred = clf.predict(X_test)\t  \n",
    "    probs = clf.predict_proba(X_test)\n",
    "\n",
    "    for topk in range(5, 6):\n",
    "        best_n_label = transform_label(clf, probs, topk)\n",
    "\n",
    "        test_time = time() - t0\n",
    "        print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "        pred = best_n_label\n",
    "        print (\"Top-\", topk)\n",
    "        print (\"Macro Acc.(class level)\", apk_per_class(y_test, best_n_label, topk), \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NSCC\t dataset for categories:\n",
      "['EA99', 'EI02', 'EI03', 'EI01', 'EI06', 'EI07', 'EI04', 'EI05', 'EG08', 'EI08', 'EI09', 'EG09', 'EA08', 'EA09', 'EA02', 'EA03', 'EA01', 'EA06', 'EA07', 'EA04', 'EA05', 'EC10', 'EE99', 'EB08', 'EF99', 'EI11', 'EI10', 'EI12', 'EA15', 'EA14', 'EA11', 'EA10', 'EA13', 'EB99', 'EA12', 'EE08', 'EE09', 'EE06', 'EE07', 'EE04', 'EE05', 'EE02', 'EE03', 'EE01', 'EB01', 'EB03', 'EB02', 'EB05', 'EB04', 'EB07', 'EB06', 'EE11', 'EE10', 'EE13', 'EE12', 'EI99', 'EE14', 'EC08', 'EC09', 'EC01', 'EC02', 'EC03', 'EC04', 'EC05', 'EC06', 'EC07', 'EF05', 'EF04', 'EF06', 'EF01', 'EF03', 'EF02', 'ED10', 'ED11', 'EG04', 'EG05', 'EG06', 'EG07', 'EG01', 'EG02', 'EG03', 'ED07', 'ED06', 'ED05', 'ED04', 'ED03', 'ED02', 'ED01', 'ED09', 'ED08', 'EH10', 'EH11', 'EH12', 'EH13', 'EH14', 'EH15', 'EG99', 'EC99', 'ED99', 'EC11', 'EH09', 'EH08', 'EH03', 'EH02', 'EH01', 'EH07', 'EH06', 'EH05', 'EH04', 'EH99', 'EG10']\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################################\n",
    "### Define train/test/code list files \n",
    "#################################################################\n",
    "#code_list_fn = \"./data/KSSC_sample_data_170206_Codelist.dat\"\n",
    "#train_fn = \"./data/KSSC_sample_data_170206_Train.dat\"\n",
    "#test_fn = \"./data/KSSC_sample_data_170206_Test.dat\"\n",
    "\n",
    "code_list_fn = \"NSCC_sample_data_170309_Codelist.dat\"\n",
    "train_fn = \"rev_utf8_train_big.dat\"\n",
    "test_fn = \"test_5500_from_izip_all_kkma_1col.dat\"\n",
    "ENCODING = 'utf-8'\n",
    "\n",
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "categories =  [x for x in open(code_list_fn,'r').read().split('\\n') if len(x) > 0]\n",
    "\n",
    "print(\"Loading NSCC\t dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "print(len(categories))\n",
    "\n",
    "data_train = open(train_fn).readlines()\n",
    "data_test = open(test_fn).readlines()\n",
    "#all_data = open('rev_reserved_data_all.dat').readlines()\n",
    "all_data = open('kkma_koreanonly_withsentencebreaker_3col.dat').readlines()\n",
    "data_train_data, data_test_data = [], []\n",
    "y_train, y_test = [], []\n",
    "all_x, all_y = [], []\n",
    "count = {}\n",
    "for cat in categories:\n",
    "    count[cat] = 0\n",
    "\n",
    "for line in all_data:\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        if(items[0][0] != 'E'):\n",
    "            continue\n",
    "        all_x.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        all_y.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print('ERROR IN READING')\n",
    "    \"\"\"\n",
    "for line in data_train:\n",
    "\titems = line.split('\\t')\n",
    "\tif len(items) == 2:\n",
    "\t\tdata_train_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "\t\ty_train.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "for line in data_test:\n",
    "\titems = line.split('\\t')\n",
    "\tif len(items) == 2:\n",
    "\t\tdata_test_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "\t\ty_test.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    \"\"\"\n",
    "guess = 10000*[\"\"]\n",
    "target_names = categories #data_train.target_names\n",
    "def divide_data(r_s):\n",
    "    global data_train_data,data_test_data,y_train,y_test\n",
    "    data_train_data,data_test_data,y_train,y_test = train_test_split(all_x,all_y,random_state =r_s, train_size = 0.9)\n",
    "    #trash_a,data_test_data,trash_b,y_test = train_test_split(all_x,all_y,random_state =1, train_size = 0.60)\n",
    "    print (len(data_train_data), len(data_test_data))\n",
    "    print('data loaded')\n",
    "    # order of labels in `target_names` can be different from `categories`\n",
    "    list_for_ed99 = [u'관련',u\"구조\",u\"구축\",u\"성능\",u\"센서\",u\"시장\",u\"제작\",u\"제품\",u\"효과\",u\"냉장고\",u\"라이브러리\",u\"레이져\",u\"업소\",u\"연주\",u\"전력 \",u\"송수신기\",u\"전자 \",u\"주요 \",u\"채용\",u\"품목\"]\n",
    "    for i,line in enumerate(data_test_data):\n",
    "        count_for_ed99 = 0\n",
    "        for word in list_for_ed99:\n",
    "            if(word in line):\n",
    "                count_for_ed99 += 1\n",
    "        if count_for_ed99>len(list_for_ed99)*0.4:\n",
    "            #print(\"ED99 guess for \",i)\n",
    "            #guess[i] = 'ED99'\n",
    "            pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Word Embedding (Word Embedding, Topic Embedding, Topic-Event Embedding) Features\n",
    "t0 = 0\n",
    "vectorizer = 0\n",
    "X_train,X_test = 0,0\n",
    "def vectorize():\n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "    t0 = time()\n",
    "    my_stop_words = [unicode(x.strip(), 'utf-8') for x in open('kor_stop_word.txt','r').read().split('\\n')]\n",
    "\n",
    "    #print (len(data_train_data))\n",
    "    global vectorizer,X_train,X_test\n",
    "    #vectorizer = StemmedTfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 200000,min_df=5)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 200000,min_df=5,ngram_range=(1,1))\n",
    "    X_train = vectorizer.fit_transform(data_train_data)\n",
    "\n",
    "    #duration = time() - t0\n",
    "\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "    print()\n",
    "\n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "\n",
    "    X_test = vectorizer.transform(data_test_data)\n",
    "    #duration = time() - t0\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 R_s 5\n",
      "54297 6033\n",
      "data loaded\n",
      "Vectorizing:  5\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 54297, n_features: 200000\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 6033, n_features: 200000\n",
      "Learning:  5\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='modified_huber', n_iter=2, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 5.204s\n",
      "test time:  0.508s\n",
      "Top- 5\n",
      "False docID: 533 prediction of  ED99  was: ['EE10' 'EA05' 'EA04' 'EE99' 'ED07']\n",
      "False docID: 551 prediction of  ED99  was: ['ED08' 'EA07' 'ED04' 'ED02' 'ED05']\n",
      "False docID: 973 prediction of  ED99  was: ['EG07' 'EE01' 'EB03' 'EA06' 'ED01']\n",
      "False docID: 1180 prediction of  ED99  was: ['ED04' 'EA09' 'ED05' 'ED06' 'EC07']\n",
      "False docID: 1415 prediction of  ED99  was: ['EB02' 'EE02' 'EE99' 'EB03' 'EB01']\n",
      "False docID: 1668 prediction of  ED99  was: ['EC09' 'EE07' 'EE99' 'EE11' 'EE02']\n",
      "False docID: 1883 prediction of  ED99  was: ['ED01' 'EB03' 'EA06' 'EC04' 'ED04']\n",
      "False docID: 1897 prediction of  ED99  was: ['ED05' 'EE02' 'ED03' 'ED06' 'EA09']\n",
      "False docID: 1958 prediction of  ED99  was: ['EA03' 'EG99' 'EA04' 'EB07' 'EA09']\n",
      "False docID: 2212 prediction of  ED99  was: ['EE09' 'EE10' 'EE06' 'ED06' 'EE02']\n",
      "False docID: 2502 prediction of  ED99  was: ['EB01' 'EB07' 'ED06' 'EB02' 'ED04']\n",
      "False docID: 2598 prediction of  ED99  was: ['EE99' 'EB01' 'ED06' 'ED04' 'EB02']\n",
      "False docID: 2702 prediction of  ED99  was: ['EC08' 'ED01' 'EA07' 'EE02' 'EE09']\n",
      "False docID: 2755 prediction of  ED99  was: ['EA05' 'EG99' 'ED10' 'EA02' 'ED02']\n",
      "False docID: 2992 prediction of  ED99  was: ['ED07' 'EA10' 'EE11' 'ED08' 'EA03']\n",
      "False docID: 3197 prediction of  ED99  was: ['EA05' 'ED11' 'EE01' 'EH02' 'ED08']\n",
      "False docID: 3216 prediction of  ED99  was: ['EA02' 'EE02' 'EB06' 'EA04' 'EA09']\n",
      "False docID: 3294 prediction of  ED99  was: ['EA03' 'EE99' 'EE02' 'EE09' 'EA05']\n",
      "False docID: 3345 prediction of  ED99  was: ['EA06' 'EE10' 'EE11' 'ED01' 'EE02']\n",
      "False docID: 4154 prediction of  ED99  was: ['EF04' 'ED03' 'ED05' 'ED09' 'EF06']\n",
      "False docID: 4827 prediction of  ED99  was: ['EF01' 'ED05' 'EF05' 'EA07' 'EF99']\n",
      "False docID: 5461 prediction of  ED99  was: ['EC01' 'EA03' 'EA99' 'EB99' 'EF99']\n",
      "False docID: 5750 prediction of  ED99  was: ['EE03' 'EE10' 'EE02' 'EE09' 'EE99']\n",
      "False docID: 5954 prediction of  ED99  was: ['EE07' 'EE01' 'EE14' 'EE02' 'EE03']\n",
      "!Low precision :! #Correct: 13.0 #Tested: 35.0 #Train 357.0\n",
      "\t EA99 Acc.: 0.371428571429 Correct: 13.0 Tested: 35.0 #Train 357.0\n",
      "\t EI02 Acc.: 0.761904761905 Correct: 16.0 Tested: 21.0 #Train 255.0\n",
      "\t EI03 Acc.: 0.947916666667 Correct: 91.0 Tested: 96.0 #Train 878.0\n",
      "\t EI01 Acc.: 0.857142857143 Correct: 24.0 Tested: 28.0 #Train 213.0\n",
      "\t EI06 Acc.: 0.869565217391 Correct: 40.0 Tested: 46.0 #Train 261.0\n",
      "\t EI07 Acc.: 0.833333333333 Correct: 5.0 Tested: 6.0 #Train 52.0\n",
      "\t EI04 Acc.: 0.963636363636 Correct: 106.0 Tested: 110.0 #Train 899.0\n",
      "\t EI05 Acc.: 0.967741935484 Correct: 30.0 Tested: 31.0 #Train 316.0\n",
      "\t EG08 Acc.: 0.9 Correct: 9.0 Tested: 10.0 #Train 118.0\n",
      "\t EI08 Acc.: 0.789473684211 Correct: 15.0 Tested: 19.0 #Train 87.0\n",
      "\t EI09 Acc.: 0.857142857143 Correct: 24.0 Tested: 28.0 #Train 344.0\n",
      "\t EG09 Acc.: 0.944444444444 Correct: 17.0 Tested: 18.0 #Train 117.0\n",
      "\t EA08 Acc.: 0.701030927835 Correct: 68.0 Tested: 97.0 #Train 785.0\n",
      "\t EA09 Acc.: 0.945812807882 Correct: 192.0 Tested: 203.0 #Train 1598.0\n",
      "\t EA02 Acc.: 0.78431372549 Correct: 80.0 Tested: 102.0 #Train 870.0\n",
      "\t EA03 Acc.: 0.831168831169 Correct: 64.0 Tested: 77.0 #Train 712.0\n",
      "\t EA01 Acc.: 0.770491803279 Correct: 47.0 Tested: 61.0 #Train 531.0\n",
      "\t EA06 Acc.: 0.818181818182 Correct: 72.0 Tested: 88.0 #Train 761.0\n",
      "\t EA07 Acc.: 0.758928571429 Correct: 85.0 Tested: 112.0 #Train 1046.0\n",
      "\t EA04 Acc.: 0.853333333333 Correct: 64.0 Tested: 75.0 #Train 621.0\n",
      "\t EA05 Acc.: 0.904761904762 Correct: 133.0 Tested: 147.0 #Train 1306.0\n",
      "\t EC10 Acc.: 0.714285714286 Correct: 5.0 Tested: 7.0 #Train 45.0\n",
      "\t EE99 Acc.: 0.752941176471 Correct: 64.0 Tested: 85.0 #Train 774.0\n",
      "\t EB08 Acc.: 0.75 Correct: 6.0 Tested: 8.0 #Train 101.0\n",
      "\t EF99 Acc.: 0.742857142857 Correct: 52.0 Tested: 70.0 #Train 657.0\n",
      "\t EI11 Acc.: 0.943396226415 Correct: 50.0 Tested: 53.0 #Train 567.0\n",
      "\t EI10 Acc.: 1.0 Correct: 12.0 Tested: 12.0 #Train 130.0\n",
      "\t EI12 Acc.: 0.907407407407 Correct: 49.0 Tested: 54.0 #Train 490.0\n",
      "\t EA15 Acc.: 0.526315789474 Correct: 10.0 Tested: 19.0 #Train 132.0\n",
      "\t EA14 Acc.: 0.727272727273 Correct: 16.0 Tested: 22.0 #Train 236.0\n",
      "\t EA11 Acc.: 0.80487804878 Correct: 33.0 Tested: 41.0 #Train 334.0\n",
      "\t EA10 Acc.: 0.918367346939 Correct: 90.0 Tested: 98.0 #Train 917.0\n",
      "\t EA13 Acc.: 0.944444444444 Correct: 17.0 Tested: 18.0 #Train 194.0\n",
      "!Low precision :! #Correct: 20.0 #Tested: 50.0 #Train 398.0\n",
      "\t EB99 Acc.: 0.4 Correct: 20.0 Tested: 50.0 #Train 398.0\n",
      "\t EA12 Acc.: 0.733333333333 Correct: 11.0 Tested: 15.0 #Train 133.0\n",
      "\t EE08 Acc.: 0.571428571429 Correct: 12.0 Tested: 21.0 #Train 258.0\n",
      "\t EE09 Acc.: 0.809523809524 Correct: 34.0 Tested: 42.0 #Train 583.0\n",
      "\t EE06 Acc.: 0.906666666667 Correct: 68.0 Tested: 75.0 #Train 742.0\n",
      "\t EE07 Acc.: 0.75 Correct: 18.0 Tested: 24.0 #Train 255.0\n",
      "\t EE04 Acc.: 0.757575757576 Correct: 25.0 Tested: 33.0 #Train 277.0\n",
      "\t EE05 Acc.: 0.785714285714 Correct: 11.0 Tested: 14.0 #Train 274.0\n",
      "\t EE02 Acc.: 0.974921630094 Correct: 311.0 Tested: 319.0 #Train 2829.0\n",
      "\t EE03 Acc.: 0.96 Correct: 72.0 Tested: 75.0 #Train 754.0\n",
      "\t EE01 Acc.: 0.93567251462 Correct: 160.0 Tested: 171.0 #Train 1532.0\n",
      "\t EB01 Acc.: 0.819444444444 Correct: 118.0 Tested: 144.0 #Train 1386.0\n",
      "\t EB03 Acc.: 0.855670103093 Correct: 166.0 Tested: 194.0 #Train 1586.0\n",
      "\t EB02 Acc.: 0.833333333333 Correct: 110.0 Tested: 132.0 #Train 1190.0\n",
      "\t EB05 Acc.: 0.633333333333 Correct: 19.0 Tested: 30.0 #Train 280.0\n",
      "\t EB04 Acc.: 0.735294117647 Correct: 25.0 Tested: 34.0 #Train 228.0\n",
      "\t EB07 Acc.: 0.909090909091 Correct: 30.0 Tested: 33.0 #Train 318.0\n",
      "\t EB06 Acc.: 0.636363636364 Correct: 35.0 Tested: 55.0 #Train 473.0\n",
      "\t EE11 Acc.: 0.782051282051 Correct: 61.0 Tested: 78.0 #Train 639.0\n",
      "\t EE10 Acc.: 0.744186046512 Correct: 32.0 Tested: 43.0 #Train 507.0\n",
      "\t EE13 Acc.: 0.7 Correct: 14.0 Tested: 20.0 #Train 251.0\n",
      "\t EE12 Acc.: 0.782608695652 Correct: 18.0 Tested: 23.0 #Train 215.0\n",
      "\t EI99 Acc.: 0.655172413793 Correct: 19.0 Tested: 29.0 #Train 301.0\n",
      "\t EE14 Acc.: 0.545454545455 Correct: 6.0 Tested: 11.0 #Train 145.0\n",
      "\t EC08 Acc.: 0.7 Correct: 7.0 Tested: 10.0 #Train 85.0\n",
      "\t EC09 Acc.: 0.921568627451 Correct: 47.0 Tested: 51.0 #Train 411.0\n",
      "\t EC01 Acc.: 0.915492957746 Correct: 65.0 Tested: 71.0 #Train 664.0\n",
      "\t EC02 Acc.: 0.88679245283 Correct: 94.0 Tested: 106.0 #Train 958.0\n",
      "\t EC03 Acc.: 0.666666666667 Correct: 40.0 Tested: 60.0 #Train 461.0\n",
      "\t EC04 Acc.: 0.933333333333 Correct: 42.0 Tested: 45.0 #Train 375.0\n",
      "\t EC05 Acc.: 0.63829787234 Correct: 30.0 Tested: 47.0 #Train 416.0\n",
      "!Low precision :! #Correct: 11.0 #Tested: 26.0 #Train 196.0\n",
      "\t EC06 Acc.: 0.423076923077 Correct: 11.0 Tested: 26.0 #Train 196.0\n",
      "\t EC07 Acc.: 0.878787878788 Correct: 29.0 Tested: 33.0 #Train 251.0\n",
      "\t EF05 Acc.: 0.901639344262 Correct: 55.0 Tested: 61.0 #Train 470.0\n",
      "\t EF04 Acc.: 0.78125 Correct: 25.0 Tested: 32.0 #Train 317.0\n",
      "\t EF06 Acc.: 0.944680851064 Correct: 222.0 Tested: 235.0 #Train 2219.0\n",
      "\t EF01 Acc.: 0.826086956522 Correct: 19.0 Tested: 23.0 #Train 256.0\n",
      "\t EF03 Acc.: 0.785714285714 Correct: 11.0 Tested: 14.0 #Train 201.0\n",
      "\t EF02 Acc.: 0.785714285714 Correct: 22.0 Tested: 28.0 #Train 286.0\n",
      "\t ED10 Acc.: 0.775280898876 Correct: 69.0 Tested: 89.0 #Train 819.0\n",
      "\t ED11 Acc.: 0.638888888889 Correct: 23.0 Tested: 36.0 #Train 346.0\n",
      "\t EG04 Acc.: 0.891891891892 Correct: 33.0 Tested: 37.0 #Train 334.0\n",
      "\t EG05 Acc.: 0.764705882353 Correct: 13.0 Tested: 17.0 #Train 125.0\n",
      "\t EG06 Acc.: 0.95652173913 Correct: 22.0 Tested: 23.0 #Train 196.0\n",
      "\t EG07 Acc.: 1.0 Correct: 63.0 Tested: 63.0 #Train 541.0\n",
      "\t EG01 Acc.: 1.0 Correct: 7.0 Tested: 7.0 #Train 107.0\n",
      "\t EG02 Acc.: 0.809523809524 Correct: 17.0 Tested: 21.0 #Train 151.0\n",
      "\t EG03 Acc.: 0.875 Correct: 14.0 Tested: 16.0 #Train 135.0\n",
      "\t ED07 Acc.: 0.753846153846 Correct: 49.0 Tested: 65.0 #Train 573.0\n",
      "\t ED06 Acc.: 0.743902439024 Correct: 61.0 Tested: 82.0 #Train 616.0\n",
      "\t ED05 Acc.: 0.660377358491 Correct: 70.0 Tested: 106.0 #Train 876.0\n",
      "\t ED04 Acc.: 0.933333333333 Correct: 182.0 Tested: 195.0 #Train 1586.0\n",
      "\t ED03 Acc.: 0.80612244898 Correct: 79.0 Tested: 98.0 #Train 787.0\n",
      "\t ED02 Acc.: 0.769230769231 Correct: 30.0 Tested: 39.0 #Train 353.0\n",
      "\t ED01 Acc.: 0.894736842105 Correct: 85.0 Tested: 95.0 #Train 917.0\n",
      "\t ED09 Acc.: 0.898305084746 Correct: 53.0 Tested: 59.0 #Train 462.0\n",
      "\t EG10 Acc.: 0.941176470588 Correct: 16.0 Tested: 17.0 #Train 159.0\n",
      "\t EH10 Acc.: 0.791666666667 Correct: 19.0 Tested: 24.0 #Train 214.0\n",
      "\t EH11 Acc.: 0.565217391304 Correct: 13.0 Tested: 23.0 #Train 209.0\n",
      "\t EH12 Acc.: 0.666666666667 Correct: 10.0 Tested: 15.0 #Train 123.0\n",
      "\t EH13 Acc.: 0.666666666667 Correct: 8.0 Tested: 12.0 #Train 145.0\n",
      "\t EH14 Acc.: 0.5 Correct: 4.0 Tested: 8.0 #Train 93.0\n",
      "\t EH15 Acc.: 1.0 Correct: 3.0 Tested: 3.0 #Train 34.0\n",
      "\t EG99 Acc.: 0.808510638298 Correct: 38.0 Tested: 47.0 #Train 371.0\n",
      "\t EC99 Acc.: 0.5 Correct: 5.0 Tested: 10.0 #Train 93.0\n",
      "\t ED99 Acc.: 0.555555555556 Correct: 30.0 Tested: 54.0 #Train 610.0\n",
      "\t EC11 Acc.: 0.5 Correct: 1.0 Tested: 2.0 #Train 28.0\n",
      "\t EH09 Acc.: 0.852941176471 Correct: 29.0 Tested: 34.0 #Train 284.0\n",
      "\t EH08 Acc.: 0.785714285714 Correct: 11.0 Tested: 14.0 #Train 146.0\n",
      "\t EH03 Acc.: 0.809523809524 Correct: 17.0 Tested: 21.0 #Train 229.0\n",
      "\t EH02 Acc.: 0.913580246914 Correct: 74.0 Tested: 81.0 #Train 731.0\n",
      "\t EH01 Acc.: 0.907407407407 Correct: 49.0 Tested: 54.0 #Train 439.0\n",
      "\t EH07 Acc.: 0.886363636364 Correct: 39.0 Tested: 44.0 #Train 479.0\n",
      "\t EH06 Acc.: 0.954545454545 Correct: 21.0 Tested: 22.0 #Train 251.0\n",
      "!Low precision :! #Correct: 2.0 #Tested: 5.0 #Train 67.0\n",
      "\t EH05 Acc.: 0.4 Correct: 2.0 Tested: 5.0 #Train 67.0\n",
      "\t EH04 Acc.: 0.6 Correct: 6.0 Tested: 10.0 #Train 152.0\n",
      "\t EH99 Acc.: 0.636363636364 Correct: 14.0 Tested: 22.0 #Train 188.0\n",
      "\t ED08 Acc.: 0.813559322034 Correct: 48.0 Tested: 59.0 #Train 504.0\n",
      "Total Test Examples 6033 \n",
      "Micro Acc.(item level) 0.835405271009\n",
      "Average of E 0.835405271009\n",
      "Macro Acc.(class level) 0.789162061957 \n",
      "\n",
      "\n",
      "EA99 1\n",
      "EH05 1\n",
      "EC06 1\n",
      "EB99 1\n",
      "Cumulative 0.835405271009\n"
     ]
    }
   ],
   "source": [
    "accumulated_fail_list = {}\n",
    "TRIAL_SIZE = 1\n",
    "RANDOM_STATE_START = 5\n",
    "cumulative_micro_avg = 0\n",
    "e_correct = 0\n",
    "e_tested = 0\n",
    "cumulative_class_score = {}\n",
    "CODE = 'ED99'\n",
    "for t,trial in enumerate(range(RANDOM_STATE_START,RANDOM_STATE_START + TRIAL_SIZE)):\n",
    "    print(\"Trial:\",t,\"R_s\",trial)\n",
    "    divide_data(trial)\n",
    "    print(\"Vectorizing: \",trial)\n",
    "    vectorize()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    fail_list = []\n",
    "    fail_list_for_code = []\n",
    "    feature_names = np.asarray(feature_names)\n",
    "    # Train SGD model\n",
    "    print(\"Learning: \",trial)\n",
    "    \n",
    "    suggested_n_iter = np.ceil(10**6/len(data_train_data))\n",
    "    #print(sug)\n",
    "    #DONT USE ELASTICNET as penalty, it will give lower\n",
    "    clf = SGDClassifier(loss='modified_huber', alpha=0.0001, n_iter=2, penalty='l2')\n",
    "    benchmark(clf)\n",
    "    for x in fail_list:\n",
    "        if not accumulated_fail_list.has_key(x):\n",
    "            accumulated_fail_list[x] = 0\n",
    "        accumulated_fail_list[x] +=1\n",
    "    #print(fail_list)\n",
    "    for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] == TRIAL_SIZE:\n",
    "            print(x,accumulated_fail_list[x])\n",
    "print('Cumulative',cumulative_micro_avg/TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statistics = open('statistics_3rdtest.txt','w')\n",
    "statistics.write('\\t'.join(['CODE','ALL','TRAIN','TEST','CORRECT','correct%'])+'\\n')\n",
    "\n",
    "for x in count:\n",
    "    a_row = [x,count[x],count[x]-cumulative_class_score[x][1],cumulative_class_score[x][1],cumulative_class_score[x][0],cumulative_class_score[x][0]/cumulative_class_score[x][1]]#code,train,tested,correct\n",
    "    for i in range(len(a_row)):\n",
    "        a_row[i] = str(a_row[i])\n",
    "    statistics.write('\\t'.join(a_row)+'\\n')\n",
    "statistics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EH12 1\n",
      "EA99 1\n",
      "EH15 1\n",
      "ED99 1\n"
     ]
    }
   ],
   "source": [
    "for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] >= TRIAL_SIZE -2:\n",
    "            print(x,accumulated_fail_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EA99 [20.0, 41.0] 372\n",
      "EH12 [4.0, 10.0] 106\n",
      "EH15 [2.0, 5.0] 25\n",
      "ED99 [14.0, 40.0] 582\n"
     ]
    }
   ],
   "source": [
    "for x in cumulative_class_score:\n",
    "    if(x[0] == \"E\"):\n",
    "        if(cumulative_class_score[x][0]/cumulative_class_score[x][1]<0.5):\n",
    "            print(x,cumulative_class_score[x],count[x]*TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EH14 is 95\n",
    "# EH15 is 96\n",
    "# EA99 is 15\n",
    "# ed99 is 48\n",
    "# ee00 is 63\n",
    "print(suggested_n_iter)\n",
    "CODE_INDEX = clf.classes_.tolist().index(CODE)\n",
    "CODE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517542185785 endoscopi\n",
      "0.554998145394 lamp\n",
      "0.551419272672 triangular\n",
      "0.563239502759 turnov\n",
      "0.608646924589 wearabl\n",
      "0.66730913174 공급기\n",
      "0.519867299344 광시야\n",
      "0.925674999351 리졸버\n",
      "0.602099061057 산업원천기술개발\n",
      "0.746020559369 수송시스템산업핵심\n",
      "0.79116022665 시설보수\n",
      "0.621038667741 시스템반도체\n",
      "0.520720374026 실무\n",
      "0.520453219473 연주\n",
      "0.596783766286 유연인쇄전자\n",
      "0.633231151025 융복합시스템\n",
      "0.608676919415 인포\n",
      "0.644928267792 전기설비\n",
      "0.656657027617 전자정보디바이스\n",
      "0.533554481677 전자파\n",
      "0.559106759631 주름패턴\n",
      "0.500680965876 지벡계수\n",
      "0.562054476646 지역산업\n",
      "0.749688808711 창의인재양성\n",
      "0.586173454145 채용\n",
      "0.580687250659 충청권\n",
      "0.563884064454 포트\n",
      "0.514010717075 품목\n",
      "0.618096097616 학연산\n"
     ]
    }
   ],
   "source": [
    "white_list = []\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(clf.coef_[CODE_INDEX][i]>0.5):\n",
    "        print(clf.coef_[CODE_INDEX][i],x)\n",
    "        white_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = file(\"features.txt\",\"w\")\n",
    "\n",
    "for x in feature_names:\n",
    "    out.write(x.encode('utf-8','ignore')+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ED99 태양 광전지판 이용 탄소 섬유 온 열매트 전용 난방 시스템 기술 개발 태양광 발전 전기 탄소 섬유 전기 매트 재생 에너지  sunlight generation electricity carbon fiber electricity mat new regeneration energy 태양 전지판 이용 가정 난방 탄소 섬유 전 기온 열매트 전용 난방 시스템 개발 태양 광전지판 인버터 사용 태양 광전지판 발생 전기 축전 전류 사용 난방 시스템 개발 전기 온 열매트 난방 온도 최고 이상 발생 안전 지속 난방 가능 시스템 개발 태양 전용 탄소 섬유 전 기온 열매트 설계 개발 축전지 전력 저장 한도 난방 설계 매트 최고 난방 온도 이상 매트 난방 유지 온도 태양 전지판 전력 발생량 이상 최대 출력 동작 전압 최대 출력 동작 전류 축전지 지속 시간 탄소 섬유 매트 전자파 이하 태양광 집열 전지판 용도 규격 개발 집광판 이용 이상 용량 태양열 전지판 직열 어레이 구성 열매트 인 최고 온도 이상 유지 용도 크기 규격 설계 개발 아파트 베란다 설치 집광판 규격 개발 규격 적정 전기 용량 데이터 확보 아파트 베란다 길이 축전지 시스템 개발 축전 전기 저장 장치 설치 인버트 장치 설치 방법 개발 전기 전환 장치 개발 태양광 전기 일반 전기 교체 사용 전기 전환 장치 개발 전기 난방 배선 시스템 개발 비상등 배선 방법 연결 코드 설치 방법 개발 아파트 구조 일반 주택 구조 실내 전기 배선 설치 설계 방법 태양 광 전기 전용 탄소 섬유 온 열매트 개발 전기 온열매트 개발 사용 가능 매트 개발 원적외선 발생 은나노 섬유 황토 코팅 원단 개발 온도 조절기 개발 겸용 태양 광 전기 온열매트 온도 조절기 개발 온도 조절 장치 조절기 제품 디자인 개발 시 작품 제작 기술 개발 효과 아파트 주택 전기 사용량 누진 적용 전력 사용 가정 전기 요금 부과 태양 광전기 일부 사용 전기 요금 절감 효과 예 월 전기 사용량 설비 기준 주택 경우 월 전기 요금 부과 태양광 설치 부담 절감 월 전기 사용량 설비 기준 주택 태양광 설치 절감 효과 아파트 전용 면적 경우 도시가스 개별 난방 시스템 적용 월 난방비 겨울철 부과 태양 전기 이용 인 온열매트 온도 난방 유지 난방비 약 절감 파악 대구광역시 아파트 가구 기준 가구 난방 기준 때 월 절감 가구 간 절감 대구시 전체 아파트 기준 간 에너지 절감비 절감 효과 발생 전국 절감 효과 추가 원자력 발전소 건설 비용 절감 당사 개발 무전자파 원적외선 발생 탄소 섬유 발 열매트 공급 사용자 건강 효과 지구 환경 보호 정책 이산화탄소 배출 의무 감축 교토 의정서 동참 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_test[fail_list_for_code[0]],data_test_data[fail_list_for_code[0]])\n",
    "fail_data = []\n",
    "for x in fail_list_for_code:\n",
    "    fail_data.append(data_test_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail size: 29\n",
      "태양 광전지판 이용 탄소 섬유 온 열매트 전용 난방 시스템 기술 개발 태양광 발전 전기 탄소 섬유 전기 매트 재생 에너지  sunlight generation electricity carbon fiber electricity mat new regeneration energy 태양 전지판 이용 가정 난방 탄소 섬유 전 기온 열매트 전용 난방 시스템 개발 태양 광전지판 인버터 사용 태양 광전지판 발생 전기 축전 전류 사용 난방 시스템 개발 전기 온 열매트 난방 온도 최고 이상 발생 안전 지속 난방 가능 시스템 개발 태양 전용 탄소 섬유 전 기온 열매트 설계 개발 축전지 전력 저장 한도 난방 설계 매트 최고 난방 온도 이상 매트 난방 유지 온도 태양 전지판 전력 발생량 이상 최대 출력 동작 전압 최대 출력 동작 전류 축전지 지속 시간 탄소 섬유 매트 전자파 이하 태양광 집열 전지판 용도 규격 개발 집광판 이용 이상 용량 태양열 전지판 직열 어레이 구성 열매트 인 최고 온도 이상 유지 용도 크기 규격 설계 개발 아파트 베란다 설치 집광판 규격 개발 규격 적정 전기 용량 데이터 확보 아파트 베란다 길이 축전지 시스템 개발 축전 전기 저장 장치 설치 인버트 장치 설치 방법 개발 전기 전환 장치 개발 태양광 전기 일반 전기 교체 사용 전기 전환 장치 개발 전기 난방 배선 시스템 개발 비상등 배선 방법 연결 코드 설치 방법 개발 아파트 구조 일반 주택 구조 실내 전기 배선 설치 설계 방법 태양 광 전기 전용 탄소 섬유 온 열매트 개발 전기 온열매트 개발 사용 가능 매트 개발 원적외선 발생 은나노 섬유 황토 코팅 원단 개발 온도 조절기 개발 겸용 태양 광 전기 온열매트 온도 조절기 개발 온도 조절 장치 조절기 제품 디자인 개발 시 작품 제작 기술 개발 효과 아파트 주택 전기 사용량 누진 적용 전력 사용 가정 전기 요금 부과 태양 광전기 일부 사용 전기 요금 절감 효과 예 월 전기 사용량 설비 기준 주택 경우 월 전기 요금 부과 태양광 설치 부담 절감 월 전기 사용량 설비 기준 주택 태양광 설치 절감 효과 아파트 전용 면적 경우 도시가스 개별 난방 시스템 적용 월 난방비 겨울철 부과 태양 전기 이용 인 온열매트 온도 난방 유지 난방비 약 절감 파악 대구광역시 아파트 가구 기준 가구 난방 기준 때 월 절감 가구 간 절감 대구시 전체 아파트 기준 간 에너지 절감비 절감 효과 발생 전국 절감 효과 추가 원자력 발전소 건설 비용 절감 당사 개발 무전자파 원적외선 발생 탄소 섬유 발 열매트 공급 사용자 건강 효과 지구 환경 보호 정책 이산화탄소 배출 의무 감축 교토 의정서 동참 \n",
      "\n",
      "수출 연계 인력 교류 사업 맞춤 프로그램 수출 촉진 사업 확산 에너지 스마트그리드 전력 신재생 에너지 인 네트워크  educational program energy networking supporting export supporting small - size company 외국인 교육 초청 경쟁 목표 외국인 교육 소속 국가 수 목표 교육 수료 인원 목표 외국인 교육 한국 수요 기업 만족도 목표 이상 에너지 산업 수출 기여 목표 수요 기업 수출 진행 상황 주기 추적 성과 관리 실시 수요 맞춤 프로그램 개발 운영 비중 사전 수요 조사 만족도 설문 조사 차수 맞춤 프로그램 제공 공무원 정책 제도 기업인 실증 운영 현황 구분 관심 주제 프로그램 제공 연수 외국 공무원 대상 연수 교육 추진 수요 기업 의견 수렴 반영 교류회 세미나 외국 공무원 전용 프로그램 신설 적용 이론 연계 현장 방문 프로그램 효율 향상 만족도 설문 조사 결과 반영 현장 방문지 선정 중소기업 수출 도움 기업 대상 세미나 진행 인 네트워크 생성 유지 강화 비중 신규 해외 진출 지원 기업 유관 기관 네트워크 활용 해외 에너지 관련 공무원 기업인 유관 기관 글로벌 에너지 협력 센터 외교 부 참여 외국인 교육 교류회 수요 기업 방문 한국 문화 체험 홈페이지 지속 네트워크 유지 강화 장 마련 사업 운영 효율 제고 사업 운영 경험 활용 지속 모니터링 효율 사업 운영 사업 참여자 주관 참여 협력 기관 수요 기업 정보 공유 주기 의견 수렴 협력 체계 구축 강화 한국 수요 기업 비용 효율 수출 유발 효과 기대 우수 국내 기술 실증 운영 현황 정보 제공 외국인 교육 소속 국가 정책 제도 프로젝트 정보 수집 정보 교류 확대 지속 사업 운영 수출 달성 네트워크 유지 강화 가능 에너지 산업 수출 활성 시장 활 개척 \n",
      "\n",
      "소형 전기 자동차 파워 모듈 개발 소형 전기 자동차 전지 콘트롤러 파워 모듈  micro ev battery controller power module 기술 개발 목표 급 소형 전기 자동차 파워 모듈 개발 전기 이륜차 포함 인 마이크로 전기 자동차 적용 전지 모터 컨트롤러 개발 기술 개발 내용 방법 전기 이륜차 마이크로 전기 자동차 차세대 적용 목적 전지팩 연결 모터 컨트롤러 전지팩 용량 대비 무게 기존 제품 대비 이하 교체 기존 급 차별 급 전지 스마트 배터리 관리 시스템 장착 개별 셀 제어 가능 니즈 방전 충전량 제어 펌웨어 포함 연결 구현 모터 컨트롤러 적용 급 경량 전지 기술 개발 예상효 기대 효과 시장 창출 일자리 창출 효과 관련 기술 기반 향후 고속 전기 자동차 하이브리드 자동차 다양 영역 진출 기대 수입 대체 효과 기존 수입 의존 가솔린 이륜차 시장 국산 마이크로 전환 기대 산업 발전 영향 관련 기술 기반 다양 용량 전지 영역 진출 기대 \n",
      "\n",
      "안경 스마트 글래스 알파 글래스 개발 스마트 글래스 증강 현실 헤드 마운트 디스플레이 웨어러블디바이스 광학  smart glasses augmented reality head mounted display wearable device optical system 안경 스마트 글래스 알파 글래스 개발 자체 개발 광학 기술 분리 모듈식 광학 세계 최고 수준 화면 크기 다양 응용 개발 가능 안드로이드 개발자버전 기준 젤리빈 패션스마트 기기 다양 커스터마이징 가능 디자인 분리 광학 모듈 기술 개발 종래 광학 구조 부분 분리 구조 광학 디스플레이부 조절부 결합부 설계 확장 부피 세계 최고 수준 안드로이드 기반 시스템 다양 응용 개발 가능 안드로이드 탑재 효과 개발 개발 패션아이템 안경 일반 안경 선글라스 외관 일상생활 사용 개인 커스터마이징 디자인 가능 종래 기술 공간 안 광학소자 렌즈 거울 일체 구조 부피 안경 모양 구현 개발 기술 안경 공간 분리 배치 구조 공간 광학소자 제약 부피 안경 모양 가능 \n",
      "\n",
      "수중 로봇 연구실 미래 발전 전략 기획 연구 수중 로봇  marine robot 수중 로봇 연구실 비전 발전 전략 로드맵 수립 수중 로봇 기술 연구 동향 분석 미래 전망 구현 핵심 원천 기술 도출 우선순위 수립 수중 로봇 기술 체계 확보 수중 로봇 기술 핵심 원천 기술 장기 로드맵 확보 수중 로봇 연구실 내외부 현황 분석 수중 로봇 기술 전문가 연구 결과 직무 분석 선박 해양 플랜트 연구소 국내 수중 로봇 기술 분석 수행 수중 로봇 국내외 연구 기관 현황 분석 해외 선진국 연구 동향 분석 해외 센서 부품 수중 로봇 시스템 제품 서비스 시장 분석 미래 전망 선진국 확보 개발 핵심 원천 기술 국내 수중 로봇 관련 기관 기술 수준 분석 수행 연구소 내외 협력 방안 도출 전문가 초청 세미나 수중 로봇 기술 전문가 의견 반영 향후 협력 방안 모색 비전 발전 전략 수립 전문가 의견 수렴 수중 로봇 핵심 원천 기술 도출 중요 공공 경제 근거 우선순위 도출 수중 로봇 핵심 원천 기술 확보 미래 발전 전략 기획 수중 로봇 핵심 원천 기술 분야 로드맵 마일스톤 작성 수중 로봇 기술 미래 발전 전략 기획 연구 체계 점진 핵심 원천 기술 확보 수중 로봇 기술 전문가 브레인스토밍 설문 조사 공청회 의견 수렴 수중 로봇 기술 장기 비전 수립 핵심 원천 기술 도출 수중 로봇 핵심 원천 기술 확보 전략 수립 장기 기술 로드맵 작성 체계 수중 로봇 핵심 원천 기술 확보 수중 로봇 핵심 원천 기술 개발 산학연 협력 체계 구축 체계 수중 로봇 기술 확보 수중 로봇 기술 선진국 위상 확보 관련 시장 진입 \n",
      "\n",
      " 드라이버 보드  display blu lcd 개발 사업 개발 사업 금형 제작 소형 금형 제작 시제품 제작 소형 제작 소형 제작 제작 제작 제작 설계 기술력 향상 효율 광학 구조 개발 제조 공정 기술력 향상 응용 제품 적용 공공 장소 제품군 응용 제품군 제품군 의료 기기 제품군 내수 수출 경쟁력 강화 \n",
      "\n",
      "고방열 직물 적용 공랭식 경량 개발 고방열 메쉬 장력 유지 이중 사출 공랭식 배터리 모듈 경량 배터리 모듈  high thermal mesh tech tension insert injection air cooled bm a lightweight bm a 배터리 모듈 사용 알루미늄 커버 타입 공랭식 냉각 시스템 경량 냉각 성능 실현 고방열 적용 공랭식 경량 개발 이차 전지 사용 알루미늄 커버 고방열 기술 적용 이차 전지 개발 다양 컨셉 설계 구조 냉각 성능 유동 해석 진행 양산 확보 이중 사출 성형 공법 개발 적용 제품 제작 신뢰 확보 후 고객 차 적용 제안 적용 알루미늄 셀커버 대체 형태 소형 경량 우수 냉각 성능 개발 국내 환경 자동차 기술 발전 기여 \n",
      "\n",
      "소재 소프트소자 공정 기술 나노 공정 나노 패터닝 전사 계면 제어 구조 유 폴리머  nano process nano patterning graph ene transfer surface control structure guiding polymer 소프트 기판 소재 방식 전사 공정 기반 분자 조립 공정 결합 하이브리드 대면 패터닝 공정 개발 소재 계면 특성 제어 이종 소재 적층 물질 신소자 적용 개념 공정 기술 개발 소재 결점 대면 전사 기술 소재 대면 전사 기법 개발 전사 가능 나노선 제조 공정 개발 리소그래피 자기 조립 결합 유도 자기 조립 정렬 활성 나노선 배열 제조 전사 가능 나노선 제조 나노 스케일 조립 대면 패터닝 기술 결합 유도 자기 조립 구현 기판 전사 가능 정렬 나노선 구현 소재 기판 접착 적층 제어 기술 이종 소재 소프트 기판 접착력 제어 적층 공정 개발 소재 계면 접착 에너지 증대 기술 방법 소프트 기판 위 대면 패터닝 구현 패터닝 공정 화학 물리 제어 기술 이종 소재 소재 포함 소자 제작 공정 응용 기술 소재 성장 박리 전사 접합 기술 개발 박막 소자 응용 필수 선행 연구 투명 신축 소자 적용 세부 전계 효과 트랜지스터 다양 종류 센서 응용 가능 대면적 전사 가능 그래핀 나노 스케일 패터닝 기술 소프트 일렉트로닉스 적용 나노 패턴 그래핀 전기 광학 특성 극대 소자 구현 가능 기대 그래핀 물질 대면 나노 스케일 패터닝 응용 기대 물질 합성 전기 성능 조절 기술 이용 투명 소자 제작 기여 미래 소프트 전자소자 개발 목표 부품 소재 원천 기술 연구 분야 획기적 기술 도약 예상 \n",
      "\n",
      "지능 자동차 센서 안테나 개발 자동차 센서 안테나 레이더 기상 조건  6 . car 7 . sensor 8 . antenna 9 . radar 1 0 . condition 과제 차량 레이더 요구 센서 안테나 개발 목표 차량 레이더 센서 지능 교통 시스템 구현 필수 기술 기상 조건 운전자 주의 발생 가능 사고 미연 방지 목적 개발 차량 안전 운행 시스템 센서 적합 성능 요구 안테나 개발 연구 목적 차량 레이더 요구 센서 안테나 개발 센서 용도 다양 안테나 개발 필요 안테나 중요 규격 사용 주파수 이득 방사 패턴 용도 규격 부합 안테나 개발 중요 개발 과정 안테나 성능 확인 반사 챔버실 사용 필요 전자파기술원 밀리미터 챔버 중 대 챔버 이용 차량 센서 사용 가능 다양 안테나 개발 도움 기대 주관 기관 전자파 기술원 이용 장비 밀리미터 챔버 중 대 챔버 활용 분야 차량 센서 안테나 이득 방사 패턴 시험 과제 성능 가격 차량 레이더 센서 상용 성공 수행 국내 경제 산업 기여 현재 레이더 센서 개발 기술 외국 기업 중심 개발 외국 고급 차량 국한 적용 실정 국내 미래 지능 자동차 관련 레이더 센서 관심 고조 과제 성능 차량 레이더 센서 국내 기술 생산 기술 개발 향후 고급 차량 차량 안전 운행 관심 일반 운전자 보급 국내 가격 경쟁력 레이더 센서 구현 기술 확보 국내 시장 창출 해외 시장 진출 레이더 센서 수입 의존 국내 공급 수입 대체 효과 기대 \n",
      "\n",
      "프로젝션 맵핑 기술 활용 아동 그림책 실감 미디어 장치 동화책 그림책 인터랙션 실감 미디어 아동  storybook picture - book interaction realize child 자동 사업비 조정 개발 기간 변경 하드웨어 장치 공간 맞춤 다면 영상 실감 시각 효과 구현 그림책 서사 개연 인터랙티브 입력 장치 오감 활용 감각 체험 출력 장치 콘텐츠 유아 서사 작품 완성 과정 창조 사고 가능 프로젝션 맵핑 그림책 콘텐츠 영상 제작 자료 수집 유아 흥미 그림책 저작 수집 확보 콘텐츠 기획 유아 행동 발달 인터랙션 동작 기획 반응 값 설정 유아 그림책 흥미 입출력 장치 개발 콘텐츠 서사 개연 입출력 장치 예 브래멘 음악대 그림책 드럼 악기 이야기 전개 액션 진행 아기 돼지 형제 그림책 늑대 입김 강도 초가집 목재 집 최신 기술 트랜드 이용 프로젝션 맵핑 프로그래밍 피지컬 컴퓨팅 제품 개발 계획 향후 종 출판책 연계 프로모션 비즈니스 모델 개발 양산 판로 확보 계획 빛 그림책 종이 책 흥미 실감 미디어 제품 종이 책 출판 시장 연계 출판 프로모션 체험 미디어 장치 시장 개척 시장 전국 어린이 관련 공공 기관 연계 프로그램 설치 단계 지속 그림책 콘텐츠 유료 업그레이드 지원 \n",
      "\n",
      "순환 급성 기능 장애 예방 인체 부착 센서 모듈 개발 임상 성능 평가 부착 심근 표지자 바이오 센서 감도 센서 모듈 동적 잡음 성능 평가 전기 화학 시스템 집적  patch type cardiac bio marker bio sensor highly sensitive sensor module dynamic noise reduction performance evaluation electrochemical system integration 결합 부착 센서 모듈 개발 무선 송수신 시험 임상 적용 시험 시스템 성능 최적 목표 단계 센서 모듈 제작 시스템 개념 설계 감도 신호 감지 회로 개발 센서 데이터 처리 분석 저장 전송 기술 개발 단계 부착 센서 모듈 구현 임상 적용 시험 시스템 성능 최적 포함 센서 모듈 구현 감도 신호 감지 회로 구현 연구 기술 집적 소형 초저 전력 감도 심근 표지자 측정법 성능 점검 다기관 공동 연구 임상 평가 시스템 기술 연구 센서 연구 연구 부착 센서 모듈 구현 연구 임상 적용 시험 시스템 성능 최적 연구 감도 신호 감지 구동 제어 기술 연구 급성 기능 장애 유발 인자 감지 기술 연구 전기 화학 신호 증폭 기술 연구 동적 잡음 제거 알고리즘 연구 센서 구동 제어 기술 연구 센서 데이터 처리 분석 저장 전송 기술 연구 센서 데이터 처리 분석 저장 전송 알고리즘 구현 기술 연구 센서 전기 화학 측정 기술 연구 집적 구현 연구 하드웨어 플랫폼 구조 연구 센서 데이터 신호 처리 기술 연구 소형 제어 집적 기술 연구 심근 표지자 측정 시스템 성능 점검 임상 평가 가이드라인 실험실 성능 시험 다기관 공동 연구 임상 평가 시험 고령 사회 대비 보건 의료 관련 기반 기술 확보 고령 인구 적극 사회생활 참여 유도 경제 활동 참가 증대 고령 사회 대비 의료 진단 시장 휴대 생체 진단 기술 우위 확보 하드웨어 소프트웨어 인프라 기술 육성 전문가 양성 \n",
      "\n",
      "기술 이용 전자 인쇄 마스터 개발 인쇄 전자 기술 마이크로머시닝 인쇄 마스터 임프린트  printed electronics micro machining print master flexibility imprint 종래 반도체 디스플레이 태양 전지 정통 반도체 공정 성능 중심 전자 소자 기술 개발 주 최근 인쇄 전자 공정 기술 대면 저가 환경 연속 장점 바탕 박막 태양전지 스마트 태그 필름 배터리 박막 조명 디스플레이 터치 패널 응용 시장 창출 라이프 스타일 변화 대응 인쇄 기술 그라비아 옵셋 프렉소 옵셋 리버스 옵셋 방식 코팅 수행 국내 인쇄 기술 역량 세계 우수 인프라 구축 인쇄 기술 중요 인쇄 마스터 기술 선폭 요구 연구 인쇄 기술 관련 업계 절대 필요 인쇄 마스터 마이크로머시닝 기술 이용 마스터 기술 개발 목적 전자 인쇄 마스터 기술 개발 기술 요소 공정 제조 요소 공정 기술 장비명 각종 당사 기술 요소 공정 이용 마스터 개발 기술 역량 확보 고가 반도체 공정 장비 당사 기업 인프라 구축 실정 연구 장비 공동 활용 지원 사업 기술 개발 절대 필수 불가결 연구 장비 보유 기관 협력 기술 개발 사업 기술 개발 도모 기대 직접 전자 인쇄 종사 국내 기관 기업 요구 기술 결과물 정밀 인쇄 마스터 요구 마이크로 나노레벨 전자 인쇄 마스터 제작 개발 가능 전자 인쇄 기술 인프라 구축 장비 설비 관련 중소 중견 기업 사업부 창출 기대 개발 인쇄 전자 기술 마스터 소모 제품 인쇄 장비 위치 중요 부품 개발 부가 가치 기대 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열화 카메라 이용 지능 화재 감시 시스템 개발 광범위 화재 감시 신뢰 화재 상황 모니터링 비용 열화 카메라 지능 화재 감시  wide fire surveillance high reliability fire monitoring low cost thermal camera intelligent fire detection 기존 화재 감지 시스템 연기 감지기 감지기 불꽃 감지기 한계 점 극복 문제점 해결 열화 카메라 이용 정확 신속 대응 가능 지능 화재 감시 시스템 개발 원거리 발생 화재 초기 감지 기술 개발 사각 지역 회전 방식 화재 감시 기반 파노라마 화재 감시 기술 개발 알람 화재 감지 정확 향상 기술 개발 중저 화질 영상 고가 화질 영상 카메라 유사 성능 발휘 중저가 임베디드 시스템 구축 카메라 이하 기존 화재 감지기 대체 지역 상대 개수 열화상 센서 모니터링 가능 화재 가능 공장 공공시설 적용 신속 정확 화재 대응 예방 원거리 발생 화재 감지 화재 초기 진압 가능 화재 감지 시스템 수출 지 재산 기술료 징수 이익 창출 \n",
      "\n",
      "소형 선박 위치 향상 안전 정보 문자 서비스 장치 개발 위성 항법 지피에스 컨수신기 소형 선박 보정 정보  d gps beacon g nss 시스템 통합 보정 정보 연산 처리부 소형 설계 개발 신호 처리 알고리즘 개발 통합 수신기 상세 설계 검증 시제 개발 해양 안전 경보기 상세 설계 검증 시제 개발 통합 수신기 디자인 목업 개발 해양 안전 경보기 디자인 목업 개발 시스템 통합 보정 정보 연산 처리부 상용모듈 개발 안테나부 부 수신부 모듈 개발 중파 획득 위성 항법 보정 신호 처리 알고리즘 안정 통합 수신기 시제품 개발 해양 안전 경보기 시제품 개발 통합 수신기 금형 기구 개발 해양 안전 경보기 금형 기구 개발 앱 연동 소프트웨어 개발 종합 시험 평가 장비 인증 개발 시스템 통합 보정 정보 연산 처리부 소형 시제품 설계 규격 통합 단말기 시스템 구성 소형 설계 중파 보정 정보 신호 처리 알고리즘 개발 보정 정보 서비스 처리부 프로토콜 개발 통합 수신기 모델링 검증 내부 배치 통합 환경 수신 규격 설계 개발 처리부 통합 간섭 설계 개발 중파 안테나 통합 설계 개발 통합 처리부 수신기 검증 개발 해양 안전 경보기 상세 설계 검증 시제 개발 통합 수신기 해양 환경 운용 디자인 개발 해양 안전경 부기 해양 환경 운용 디자인 개발 앱 서비스 연동 소프트웨어 구현 시스템 통합 보정 정보 연산 처리부 상용모듈 개발 통합 수신부 보정 정보 연산 처리부 데이터 운용 처리 프로토콜 검증 안테나부 부 수신부 모듈 개발 안테나부 통합 운용 환경 간섭 검증 중파 획득 위성 항법 보정 신호 처리 알고리즘 안정 보정 정보 연산 결과 성능 검증 통합 수신기 시제품 개발 처리 처리부 통합 시제 개발 검증 해양 안전 경보기 시제품 개발 유선 무선 신호 처리 통합 시제 개발 검증 통합 수신기 금형 기구 개발 해양 안전 경보기 금형 기구 개발 앱 연동 소프트웨어 개발 종합 시험 평가 인증 개발 해양 내륙 포함 국토 지리 위치 정보 서비스 이용 국가 관련 단체 수입 대체 효과 단말기 공급 예산 절감 신뢰도 측위 산업 기반 조성 국가 경제 기여 세계 최초 기준국 운영 향후 해외 단말기 보급 기반 확보 국제 인증 추가 추진 단말기 기술 기반 확보 레저 단말기 세계 이용 추가 개발 해외 시장 개척 선진국 주도 측량 측지 장비 국산 수입 대체 효과 부가 응용 기술 확대 선진국 측위 기준점 민간 주 산업 육성 기반 마련 국가 예산 개발 위성 항법 기반 기술 상용 \n",
      "\n",
      "융합 보안등 보안 카메라 에너지 절감 교류 씨오비 보안등 효율  cctv energy saving ac cob led security light high efficiency 광 효율 효율 개발 성형 기술 개발 반구 성형 기술 개발 이용 다단 성형 기술 개발 이내 개발 보호 회로 개발 개발 배열 최적 회로 설계 방열 특성 조명 효율 극대 회로 설계 연색 향상 물리 특성 향상 실험 성형 기술 설계 개발 최소 회로 설계 실장 가능 소형 배열 최적 설계 개선 회로 개발 실외 보호 회로 개발 입력 전원 효과 최적 설계 구조 개선 회로 설계 반구 성형 기술 개발 점 특성 실험 자연 반구 성형 조건 확립 반구 높이 최대 경화 조건 확립 이용 다단 성형 기술 개발 층수 변화 예측 시뮬레이션 기법 사출 기법 평가 선도 기업 효율 정도 과제 개발 목표 우리나라 세계 최고 기술력 세계 시장 리드 세계 최초 제품 해외 수출 활성 에너지 절감 \n",
      "\n",
      "스마트 앱세서리 이용 시각 장애인 전시관 박물관 보행 방향 유도 도슨트 기기 개발 전시 안내 시각 장애인 앱세사리 모바일 블루투스  guide a person who is visually imp a i app mobile bluetooth 사회 발전 양극 심화 소외 수 시각 장애인 전시 문화 체험 소외 시 장애인 차별 금지법 국가 지자체 장애인 문화 예술 시설 이용 예술 활동 적극 참여 필요 시책 강구 명시 장애인 문화 욕구 권리 정책 지원 배려 비 장애인 지원 배려 수준 사회 현실 박물관 전시관 시각 장애인 시도 진행 실질 부족 상태 전시물 설명 오디오 서비스 번호 입력 수동 방식 전시물 근처 시각 장애인 방향 고려 자동 안내 방식 음파 서비스 시각 장애인 배려 이동 동선 방향 방향 유도 장치 필요 방향 유도 장치 스마트폰 연계 자동 안내 도슨트 앱세서리 활용 시각 장애인 전시관 박물관 안전 편리 이동 전시물 설명 문화생활 방식 감지거리 유동 신호 동시 인식 간섭 문제점 방식 전파 혼용 거리 정확 방향 부재 문제점 해결 필요 공공 문화 기관 시각 장애인 편 서비스 증진 방안 마련 동시 문화 할동 참여 만족도 증가 실질 도움 서비스 구축 목적 스마트 앱세서리 이용 시각 장애인 전시관 박물관 보행 방향 유도 도슨트 기기 개발 제안 시스템 주요 기능 다음 적외선 송신 장치 복수 방향 신호 체계 탑재 시각 장애인 진행 방향 전 우 좌 우 방향 센서 신호 분석 방향 진행 전시물 목표 지점 유도 송신 장치 개발 적외선 방향 수신 신호 분석 스마트폰 위치 신호 전송 부착 앱세사리 개발 수신 신호 왜곡 중복 인식 보정 알고리즘 개발 전력 제어 기술 개발 배터리 효율 사용 배터리 로우 기술 개발 시각 장애인 점자 버튼 수신 위치 정보 매핑 도슨트 솔루션 개발 위치 정보 수신 해당 전시물 정보 자동 진동 음성 안내 메시지 서비스 시각 장애인 동선 위치 정보 파악 후 다음 이동 위치 정보 서비스 음성 안내 시각 장애인 적합 전시물 상세 설명 이동 방향 동선 설명 주변 편의 시설 설명 시각 장애인 응급 사항 경보 안내 음성 메시지 서비스 출입구 피난 시설 안내 서비스 사업 송신 장치 당사 기 설치 박물관 전시관 추가 적용 후 주요 국공립 사립 박물관 미술관 확대 적용 스마트폰 부착 앱세서리 한국 시각 장애인연합회 제품 홍보 공급 발전 방향 지방 자치 단체 지하철 도시 공공 장소 안내 시스템 구축 협의 \n",
      "\n",
      "펄감 표현 전자 기기 기능 전착 기술 개발 전착 전자 기기 펄감 도료 안료 찬착 도장  electrode position electronic equipment impression of a pearl gray paints / pigment electrostatic painting 다양 텍스쳐 형성 기술 가공 소재 선정 이론 메카니즘 기 보유 코팅 기술 개발 특성 노하우 접목 소재 개발 텍스쳐 소재 도료 최적 펄 효과 개발 텍스쳐 소재 표면 처리 기술 펄감 구현 기술 다양 칼라 구현 도료 안료 배합 기술 밀도 펄 효과 전착 코팅막 형성 전착 기술 시험 배합 도료 안료 물성 개발 반복 배합 설계 최적 사양 도출 종래 펄감 초과 다양 표면 형성 반사 펄 효과 구현 효과 패턴 다양 개발 표면 형성 조건 설정 텍스쳐링 방법 표면 분석휘 분석 펄 효과 수준 공정 조건 설정 전착 도막 시험 평가 시편 제작 물 시험 측정 텍스쳐 안료 적용 시제품 제작 기술 적용 시제품 제작 텍스쳐링 장비 제작 제품 펄 효과 성능 내식 경도 밀착 외관 제품 우수 확보 시험 성능 평가 결과 분석 공정 라인 최적 설계 기술 적용 부품 양산 제조 공정 설비 라인 전용 추진 기술 개발 분말 사용 소재 표면 물리 형성 밀착 펄감 우수 전착 도장 기술 개발 다양 피도물 색상 구현 광범위 제품 적용 가능 시각 차세대 도장 기술 개발 전착 도장 도장 방법 소재 형상 구애 균일 도장 가능 피도물 접착 우수 도막 형성 도료 손실 장점 자동차 전기 전자 제품 도장 광범위 사용 제품 내구 기능 수요 중가 펄감 가미 다양 색상 구현 요구 실정 연유 과제 개발 내용 다음 전착 코팅 제조 코팅 방법 개발 원료 전착액 시간 변화 분석 반응 시효 고찰 원료 도료 공정 기술 확보 전착 코팅제 인가 전압 온도 최적 분석 전착 코팅 기계 화학 방법 전처리 공정 분석 시험 샌드블라스팅 기계 연마 사포 전착 코팅 방법 선정 코팅 대상품 종류 형태 코팅 두께 시험 코팅 법 선정 전착 코팅제 시험 평가 시편 제작 물 시험 측정 코팅 조성물 배합 비 최적 공정 조건 설정 개선 코팅 증착 시간 도포 라인 이송 속도 건조 열처리 코팅 분석 공정 조건 설정 전착 코팅 전처리 적용 시제품 제작 개발 전착 코팅 기술 적용 제품 설계 형성 장비 제작 도료 안료 적용 표면 처리 방법 개발 시제품 최적 설계 전착 기술 개발 시제품 표면 형상 코팅 특성 조 의존 개발 도료 시제품 적용 검사 최적 코팅 설계 디자인 부각 환경 안료 적용 다양 컬러 구현 기술 개발 코팅제 적용 시제품 시험 성능 평가 코팅 공정 라인 최적 본기술 적용 코팅 표면 코팅막 내후성 시험 항온 항습 테스트 제품 도막 펄감 내열 광택 유지 내식 경도 제품 우수 확보 코팅 경도 힘 반복 미쓰비시 연필 내열 시간 측정 시험 성능 평가 결과 분석 공정 최적 설계 코팅제 적용 모바일 자동차 부품 양산 코팅 제조 공정 설비 라인 전용 추진 시험 작업 조건 방법 양산 실용 설비 작업 조건 변경 품질 성능 확보 관리 설정 공정 별설비 프로세스 설정 양산 개시 사업 추진 철저 개발 공정 분석 분석 장비 활용 극대 활용 방안 모바일 기기 자동차 전자 기기 부품 전자 기기 외장재 적용 휴대폰 노트북 캠코더 디지털 카메라 케이스 저장 장치 부품 광 픽업 헤드 프레임 레저 스포츠 용품 인라인 스케이트프레임 안경테 낚시 릴 자전거 프레임 골프 헤드 항공기 부품 제트 엔진 기어 박스 헬리콥터 회전축 보호 캡 기타 강도 경량 상품 활용 가능 파급 효과 기술 측면 펄감 표현 전자 기기 기능 전착 개발 제조 공법 국산 기술 개발 완성 펄감 표현 전자 기기 기능 전착 기술 접목 다양 부품 생산 가능 펄감 표현 전자 기기 기능 전착 내구 향상 기술 개발 모바일 기기 자동차 부품 전자 기기 수명 장기 촉진 사업 확보 기술 모바일 기기 자동차 부품 전자 기기 부품 적용 해당 제품 성능 향상 기여 경제 측면 펄감 표현 전자 기기 기능 전착 부가 가치 창출 매출 증대 효과 자동차 부품 전자 기기 부품 성능 내구 향상 부가 가치 제품 생산 기반 마련 품질 펄감 표현 전자 기기 기능 전착 기술 보유 시장 확대 촉진 펄감 표현 전자 기기 기능 전착 제조 공법 국산 개발 수입 대체 수출 효과 \n",
      "\n",
      "항공기 복합재 구조물 건전 감시 통합 계측 시스템 개발 광 아날로그 복합 계측 장비 구조 건전 모니터링 광섬유 격자 센서 손상 감지 하중 이력  combined optical and analog sensor measurement equipment structure health monitoring fiber bragg grating sensor monitoring damage detection load history 탑재 지상 분석 장비 상세 설계 구현 센서 부착 기술 표준 개발 선정 센서 장착 방안 마련 운용 시험 알고리즘 검토 시제 제작 통합 계측 시스템 상세 설계 구현 탑재 장비 시제 제작 지상 장비 시제 제작 센서 부착 표준 개발 선정 장착 방안 마련 탑재 지상 분석 장비 상세 설계 구현 센서 부착 기술 표준 개발 선정 센서 장착 방안 마련 운용 시험 알고리즘 검토 시제 제작 \n",
      "\n",
      "유럽 시장 공략 인터페이스 기반 차량 발전기 전력 제어 모듈 개발 통신 인터페이스 교류 발전기 전력 제어 모듈 마이컴  lin interface alternator power control module mi com 개발 대상 인터페이스 기반 차량 발전기 전력 제어 모듈 개발 적용 최적 알고리즘 설계 발전 전력 제어 모듈 회로 설계 개발 설계 발전 전력 제어 모듈 시제품 설계 제작 시제품 성능 평가 신뢰 평가 고객 승인 시제품 제출 조기 사업 맞춤식 고객 대응 유럽 시장 전략 아이템 기술 개발 구체 주관 기관 제논 전장 전력 제어 모듈 회로 설계 알고리즘 개발 전북자동차기술원 알고리즘 검증 수행 제품 기판 기구부 설계 전력 제어 모듈 시제품 제작 성능 시험 수행 후 문제점 보완 목표 기술 관련 특허 신청 지 재산 등록 시장 우회 진입 후 제조사 소량 생산 아이템 이원 추진 참여 기관 전북자동차기술원 설계 알고리즘 기반 성능 검증 수행 개발 지원 시제품 발열량 분포 분석 전력 제어 모듈 성능 평가 참여 기관 전북대학교 인터페이스 개발 개발품 인터페이스 확장 기술 지원 목표 기술 제품 이후 당사 영업망 고객 인프라 해외 제조사 공급 타진 확보 판로 촉진 아이템 고객 확대 유럽 시장 적극 공략 시장 창출 프리미엄 시장 진입 진입 장벽 당사 인지도 시장 대응 조기 매출 실현 제품 적용 이력 품질 안정 바탕 시장 진출 목표 고객 목표 고객 해외 시장 개척 유럽 시장 중심 시장 개척 매출 목표액 과제 종료 후 달성 고용 창출 신규 연구 인력 생산 인력 고용 창출 수입 대체 전량 수입 의존 부품 수입 대체 효과 기대 \n",
      "\n",
      "주파수 자원 개발 기반 구축 주파수 배치 경매 할당  spectrum relocation auction assignment 기존 주파수 배치 대역 정비 개발 실행 기반 구축 주파수 자원 효율 이용 목표 차세대 주파수 자원 확보 발굴 안정 전파 자원 관리 전파 산업 활성 주파수 수요 증가 대비 적기 주파수 공급 주파수 배치 대역 정비 방안 마련 전파 서비스 고도 급증 무선 기기 주파수 신규 분배 국제 기준 기술 기준 개정 관련 산업 활성 주파수 이용 효율 증대 주파수 대역 개발 주파수 자원 이용 최적 방안 구현 신규 서비스 도입 주파수 자원 적기 공급 가능 기반 마련 한국 경매 실행 사업자 선정 효율 공정 극대 방송 통신 서비스 시장 경쟁 활성 국내 산업 면허 주파수 수요 고려 효율 정책 추진 관련 산업 이용자 편익 증진 \n",
      "\n",
      "여성 산업 융합 인재 양성 사업 통합 시스템 현장 실무 전문가 교육 연구 취창업 연계 스마트 리빙 미래 생활 중심 산업 기반 융  nice integrated system new industry for future life good service ict based field business expertise convergence education smart living creative converging female professional education research job career i interlink 산업 구조 변화 인력 수요 공급 균형 대응 산업 수요 기반 교육 모델 개발 학문 융합 산학 협력 강화 연구 교육 취 창업 시스템 구축 창조 경제 여성 선도 인력 양성 다학제 인프라 구축 융합 교육 모델 개발 산업 분야 사회 요구 다학제 단과 대학 설립 학사 구조 개편 교과목 개발 사업 기간 이후 지속 가능 융합 교육 모델 정립 기반 산업 친화 융합 분야 공동 연구 개발 스마트 리빙 미래 생활 분야 현장 요구 반영 기반 스마트 웨어러블즈 스마트 엔터테인먼트 스마트 헬스 케어 분야 융 복합 공동 연구 개발 기술 개발 직업군 창출 현장 맞춤 융합 인재 양성 취 창업 지원 학사 제도 개편 장학 제도 신설 여성 산업 유망 분야 산학 연계 현장 학습 발굴 프로그램 개발 현장 맞춤 융합 인재 양성 사업 여성 특유 감성 역량 극대 미래 생활 중심 산업 적극 적용 산업 수요 기반 교육 연구 취 창업 통합 모델 선도 제시 교육 연구 취 창업 유기 연계 시너지 효과 극대 최적 모델 인재 양성 통합 시스템 개발 구축 인프라 구축 산업 융합 대학 신설 사업 참여 학과 중심 운영 위원회 교육 위원회 산학 협력 위원회 구성 대학 기업 관 컨소시엄 구성 스마트리빙 연구 센터 설립 운영 산학연 네트워크 조성 융합 지식 기반 교육 강화 산업 융합 분야 인재 양성 목표 참여 학과 교육 과정 혁신 변화 융합 기초 의사소통 창의 교과목 산업 수요 맞춤 융합 전공자기 설계 트랙 교육 과정 학부 연구 역량 강화 운영 현장 실습 프로그램 개발 운영 산학 협력 공동 연구 개발 미래 수요 부응 생활 중심 산업 분야 스마트 웨어 러블즈 스마트 엔터테인먼트 스마트 헬스 케어 분야 선정 성공 연구 개발 인력 양성 산업 수요 창출 관련 융복합 인재 배출 산업 분야 취 창업 지원 학생 취 창업 지원 대학 유관 기관 협조 체제 보완 도전 학기 코업 학기 취 창업 학사 제도 개편 운영 융합 취 창업 관련 장학 제도 신설 학생 지원 강화 산업 수요 분석 진로 코칭 시스템 개발 취 창업 지원 프로그램 개발 운영 교육 연구 취 창업 연계 융합 기반 교육 과정 스마트 리빙 산업 연구 사업 연계 강화 학부 연구 산학 협력 취 창업 지원 시스템 협력 체제 강화 교육 연구 성과 산학 협력 취 창업 연계 평가 개선 인재 양성 시스템 지속 운영 미래 사회 수요 반영 산업 융합 인재 양성 체제 모델 제시 기업 요구 부합 인력 수급 창의 연구 성과 사업 기술 이전 창업 경제 가치 창출 기술 적용 저변 확대 산업 활성 인간 생활 지원 관련 산업 도입 산업 창출 혁신 \n",
      "\n",
      "자동차 전기 전자 제어 장치 부품 기능 안전 표준 기반 조성 기능 안전 기능 안전 자동차 안전무결 수준 안전무결 수준 안전 관련 시스템  functional safety automotive safety integrity level safety integrity level safety related system electrical elector nic control system 국제 표준 회의 개최 국내 위상 강화 국내 기업 지속 기능 안전 대응 역량 향상 환경 구축 국제 표준 회의 개최 기능 안전 환경 구축 기능 안전 기업 지원 홈페이지 구축 운영 시스템 개발 가이드라인 배포 국내 자동차 기업 지원 기업 애로 기술 기능 안전 위험 분석 안전 구조 분석 리스크 평가 시스템 안전 기반 설계 중심 기업 지원 사업 수행 기반 자동차 전장 개발 체계 기능 안전 평가 수행 공인 평가서 발급 기반 자동차 시험 수행 가이드라인 준수 여부 관련 표준 이용 분석 싸이클 매트릭 정형 평가 지표 활용 제어 흐름 분석 데이터 흐름 분석 수행 시험 커버리지 정형 지표 사용 국제 표준 회의 개최 국내 위상 강화 국내 기업 지속 기능 안전 대응 역량 향상 환경 구축 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상용 소형 광학 레이더 기반 충돌 회피 시스템 개발 레이다 무인기 연속 주파 충돌 회피 영상 처리  radar u av fm cw collision avoid image detect 과제 최종 목표 사용 가능 소형 주파수 모듈레이션 연속파 방식 레이더 활용 충돌 방지 정보 제공 광학식 카메라 모듈 장착 추가 정보 제공 과제 개발 하드웨어 다음 밴드 안테나 방식 주파 레이더 송수신기 증폭기 회로 고속 회로 고속 회로 신호 처리 처리부 레이더 제어 데이터 처리 연산 레이더 검출 연산 외부 인터페이스 제공 충돌 회피 관련 소프트웨어 카메라 영상 정보 추출 레이더 센서 기반 전처리 장애물 탐지 모듈 소프트웨어 개발 레이더 센서 기반 파형 설계 발생 장애물 탐지 검증 소프트웨어 개발 광학 센서 기반 장애물 탐지 모듈 과제 사용 카메라 시스템 라즈베리파이 카메라 시스템 카메라 장착 일체 카메라 무게 급 해상도 제공 레이더 센서 기반 장애물 탐지 모듈 개발 설치 레이더 하드웨어 무게 소비 전력 고려 일반 사용 방식 펄스파 도플러 레이더 방식 주파수 모듈레이션 연속파 레이더 방식 안테나본 과제 소출력 전파 사용 마이크로스트립 패치 안테나 적용 예정 송출부 수신부 레이더 다음 시간 선 스윕 삼각파 변조 송신 장애물 반사 수신 신호 송신 신호 곱 주파수 차주 파수 차주 파수 거리 수신 신호 처리부 레이더 수신 처리부 수신부 수신 신호 최종 해석 모듈 수신부 송출 신호 수신 신호 모듈레이션 신호 최종 출력 신호 고속 디지털 신호 주파수 성분 추출 주파수 성분 추출 기법 사용 고속 처리 신호 처리부 인터페이스 과제 개발 목표 모듈 방식 레이더 일반 시스템 구매 조립 사용 범용 통신 인터페이스 제공 검토 방식 일반 시리얼 인터페이스 버스 방식 범용 인터페이스 제공 예정 전처리 모듈 입력 신호 디지털 데이터 저장 요구 시작 끝 시점 지정 제어 신호 변환 상호 동기 과정 데이터 저장 장애물 탐지 모듈 전 처리 모듈 전달 데이터 장애물 거리 산출 모듈 수신 값 이용 측정 송신 시점 수신 시점 사이 시간 차이 환산 거리 값 산출 역할 수행 장애물 탐지 테스트 설계 파형 구성 경우 무인기 작동 상태 테스트 개발 소형 충돌 회피 시스템 현재 유사 제품 상황 광학 레이더 동시 활용 가능 하이브리드 구성 유일 제품 충돌 회피 시스템 소형 모듈 제작 사용자 구매 가능 상용 제품 모듈 이식 커스터마이징 특장점 국내 대비 해외 소형 사용자 소형 활용 기하급수 증가 주요 판매 시장 해외 집중 개발 후 이후 해외 매출 국내 매출 예측 \n",
      "\n",
      "수요 기반 기술 기획 체계 구축 전략 수립 기관 발전 전략 기획 융합 기술 전략 연구 개발 포트폴리오 융합 기술 태스크 성과 목표 체계 창조 경제  midterm r & d strategy first mover r & d strategy 포트폴리오 분석 주요 수탁 수요 기반 기획 체계 구축 미래 유망 전기 기술 발굴 포트폴리오 분석 대상 기본 방향 설정 포트폴리오 분석 대상 데이터 정의 방법 연구 관련 데이터 수집 가공 포트폴리오 분석 기관 전략 수립 반영 정부 요구 대응 전기 연 차별 기획 체계 구축 사회 산업 수요 기반 개방 기획 관련 국내외 사례 분석 벤치마킹 차별 기획 방법 개발 패밀리 기업 활용 수요 기반 기술 기획 체계 마련 개방 선정 체계 도입 외부 전문가 참여 검토 시행 사회 기술 분석 기관 임무 기술 분야 산업 동향 분석 대형 창출 탑 과제 기획 프로세스 개선 정부 정책 대응 융합 기술 개발 활성 기술 융합 분석 전기 연 주관 대 융합 과제 주제 발굴 발굴 주제 기획 결과 전문가 검토 체계 구축 미래 성장 동력 창출 유망 기술 후보군 파악 기술 융복합 동향 파악 미래 전기 산업 시나리오 확보 대외 협력 개방 연구 체계 구축 \n",
      "\n",
      "현장 진단 서비스 시장 공략 디자인 기술 개발 이동 엑스 선 영상 센서 디자인 아이덴티티 사용 적합 가정 진단 서비스  mobile x - ray image sensor design identity usability home diagnostic service 인체 타깃 시장 공략 제품 디자인 기술 개발 진단 시 제품 이동 휴대 검토 휴대 디자인 요소 손잡이 유무 제작 방식 패킹 시 구성품 효율 배치 휴대 시 외부 환경 파손 방지 보호 시 내진동 최소 파손 방지 구조 반영 방수 테스트 효율 디자인 사용자 파손 대비 패턴 사용 사용자 행동 진단 시 효율 움직임 배려 제품 사용 사용자 행동반경 최소 효율 사용 제공 디자인 설계 기구 설계 시뮬레이션 샘플 제작 검수 신뢰 인증 안정 시험 평가 무선 엑스 선 영상 센서 기술 개발 내진동 방수 충격 방지 기구 안정 확보 판로 확보 마케팅 공통 진동 방수 충격 방지 기구 안정 확보 외형 디자인 개발 디자인 개발 시각 전략 구축 전략 수립 적용 사용 평가 피드백 의료진 사용 검증 수요 기업 외부 전문가 평가 강도 경량 소재 채용 기구 설계 기술 접목 디자인 기술력 확보 세분 시장 개발 역량 강화 방수 방진 낙하 충격 내구 강화 품질 신뢰 노하우 축적 과제 국산 브랜드 이미지 제고 효과 국산품 경쟁력 상승 효과 기대 고객 지향 시스템 증가 수요 충족 활성 도모 국산 의료 기기 전체 질 향상 기여 제품 완성도 측면 디자인 기술 글로벌 경쟁력 확보 \n",
      "\n",
      "국악 금속 타악기 연구 음향 분석 툴 킷 음 합성 알고리듬 개발 국악기 금속 타악기 음향 분석 음 합성 툴 킷 소프닝 맥놀이 임펄스 응답 청취 테스트  traditional korean instrument metal percussion acoustical analysis sound synthesis toolkit softening beat impulse response subjective test 연구 국악 금속 타악기 세부 음향 데이터 취득 분석 음향 분석 알고리듬 툴 킷 개발 금속 타악기 주요 특성 규명 후 주요 성분 시간 주파수 영역 파라미터 구성 이용 금속 타악기 음 합성 알고리듬 개발 연구 세부 다음 연구 분야 진행 악기 음향 데이터 취득 대상 악기 징 꽹과리 의 단위음 타법 연주음 녹취 전문가 악기 종류 음악 특성 자료 취득 대상 악기 임펄스 응답 녹음 분석 데이터 가공 편집 음향 분석 툴 킷 개발 타악기 음색 중요 성분 추출 피크 트래킹 시간 피크 감쇄 동시 고려 피크 트래킹 감쇄 측정 알고리듬 개발 국악 금속 타악기 특징 소프닝 맥놀이 검출 알고리듬 개발 시간 규명 타악기 선형 해석 기존 알고리듬 개선 알고리듬 통합 형태 음향 분석 툴 킷 구성 음 합성 알고리듬 개발 음향 분석 툴 킷 이용 정보 바탕 시간 주파수 영역 파라미터 구성 선형 성분 가산 합성 선형 부분 취득 순간 주파수 파라미터 이용 프레임 단위 개선 스펙트럼 모델링 적용 전문가 관련 학회 회원 청취 테스트 평가 피드백 연구 결과물 국제 저명 학술지 학술 대회 논문 발표 연구 결과 홍보 세계 관련 분야 전문가 제언 향후 연구 계획 모색 국악 금속 타악기 원천 기술 확보 악기음 모델링 단위음 연주음 녹음 환경 개선 악기 음색 변화 가상 악기 개발 가능 각종 멀티미디어 산업 방송 소비 콘텐츠 활용 예술 작품 제작 전문가 전문 마켓 시장 전통 문화 소스 진출 시장 형성 기여 전통 자원 산업 문화 보급 효과 극대 기여 국내 콘텐츠 제작 환경 제공 문화 콘텐츠 제작 활성 기여 \n",
      "\n",
      "스마트 기기 이용 가스 누출 검지 기술 가스 센서 사물 인터넷 스마트 디바이스 소형 소비 전력  gas sensor i ot smart device sub miniature low power consumption 주관 기관 와이즈산전 차원 판상 물질 대면 성장 공정 개발 성장 금속 물질 성장 급 적외선 소자 개발 일산화탄소 메탄 밴드 패스 필터 설계 개발 일산화탄소 메탄 감지 가스 센서 개발 모듈 개발 신호 증폭 필터링 온도 보상 통신회 구현 개발 데이터베이스 구축 적외선 가스 센서 시 작품 개발 참여 기관 한국전자통신 연구원 기술 이용 광원 소형 소모 전력 히터 설계 가스 센서 신호 처리 설계 가스 센서 제어 모듈 개별 시험 회로 개발 주관 기관 와이즈산전 급 적외선 소자 개발 소자 시험 필요 측정 장치 개발 차원 판상 물질 열전 물질 대면 성장 공정 개발 계열 물질 성장 계열 물질 성장 금속 성장 물질 열전 상수 향상 전기 전도 제어 급 적외선 소자 공정 개발 급 적외선 소자 공정 개발 일산화탄소 메탄 밴드 패스 필터 설계 개발 적외선 밴드 패스 필터 소재 개발 필터 특성 평가 센서 구동 모듈 개발 이용 신호 증폭 필터링 온도 보상 통신회 구현 이전 신호 필터링 온도 보상 데이터베이스 구축 구축 데이터베이스 바탕 설계 협조 가스 센서 시 작품 개발 기존 벌크 광도파로 개발 적외선 소자 히터 구성 벌크 특성 평가 마이크로 가스 센서 구상 설계 참여 기관 한국전자통신연구 원가 기술 이용 광원 소형 소모 전력 히터 설계 시뮬레이션 히터 형상 온도 예측 실리콘 공정 활용 히터 설계 가스 센서 신호 처리 설계 신호 처리 요구 사항 수집 규격 설정 신호 처리 종류 결정 신호 처리 포트 수 결정 신호 처리 설계 다 가스 센서 제어 모듈 개별 시험 회로 개발 제어부 마이크로 프로세서 하드웨어 구현 전력 무선 통신 하드웨어 구현 전원 관리 기능 외부 전원 이용 이차 전지 충전 하드웨어 구현 기능 성능 시험 개별 회로 기능 시험 개발 디버깅 환경 구축 가스 센서 인터페이스 구현 기능 성능 검증 작성 시험 기술 측면 부품 소재 적외선 센서 관련 기술 대외 의존도 최소 센서 시스템 전반 기술 확보 경쟁력 보유 패턴 인식 알고리즘 관리 기술 확보 최적 관리 가능 스마트폰 어플리케이션 기술 다양 관리 가능 관련 기술 전문가 양성 경제 산업 측면 수입 대체 수출 증가 국가 경쟁력 높임 센서 산업 수출 유망 부품 선진국 주도 산업 발전 단계 첨단 기술 집약 산업 핵심 부품 기술력 융합 완성 제품 기능 성능 좌우 절대 선진국 주도 산업 센서 산업 첨단 지식 산업 기술 집약 부가 가치 산업 고용 창출 효과 첨단 지식 산업 센서 산업 가치 향상 산업 산업 적용 융합 기존 가치 획기적 증대 산업 센서 산업 차세대 성장 산업 자동차 전자 로봇 산업 핵심 부품 차세대 성장 산업 전후방 효과 뿌리 산업 시장 요구 사업 창출 활성 일자리 창출 에너지 절감 에너지 위기 극복 화재 인명 재산 피해 감소 사회 측면 보안 안전 강화 사회 문제 해결 웰빙 편리 추구 인간 욕구 만족 삶 질 향상 실내 유해 가스 제거 실내 환경 개선 건강 환경 제공 고령 사회 관리 문제 해결 \n",
      "\n",
      "소재 소프트소자 공정 기술 나노 공정 나노 패터닝 전사 계면 제어 구조 유 폴리머  nano process nano patterning graph ene transfer surface control structure guiding polymer 소프트 기판 소재 방식 전사 공정 기반 분자 조립 공정 결합 하이브리드 대면 패터닝 공정 개발 소재 계면 특성 제어 이종 소재 적층 물질 신소자 적용 개념 공정 기술 개발 소재 대면 고속 전사 기술 전사 정밀도 전사 특성 평가 기술 전사 기판 소재 접착 제어 기술 대면 전사 가능 복합 나노 구조 그래핀 제조 공정 개발 유도 자기 조립 계층 복합 나노 구조 합성 대면 전사 가능 복합 나노 패턴 제조 계층 조립 복합 나노 패턴 구현 규칙 나노 기공 복합 정렬 나노 리본 패턴 구현 복합 나노 패턴 소자 전사 구현 나노 구조 사용 실현 방식 분자 조립 방식 하이브리드 패터닝 소자 제작 응용 공정 기술 소프트 기판상 이하 패턴 대면 패터닝 방법 개발 개념 소자 공정 적용 기술 소재 성장 박리 전사 접합 기술 개발 박막 소자 응용 필수 선행 연구 투명 신축 소자 적용 세부 전계 효과 트랜지스터 다양 종류 센서 응용 가능 대면적 전사 가능 그래핀 나노 스케일 패터닝 기술 소프트 일렉트로닉스 적용 나노 패턴 그래핀 전기 광학 특성 극대 소자 구현 가능 기대 그래핀 물질 대면 나노 스케일 패터닝 응용 기대 물질 합성 전기 성능 조절 기술 이용 투명 소자 제작 기여 미래 소프트 전자소자 개발 목표 부품 소재 원천 기술 연구 분야 획기적 기술 도약 예상 \n",
      "\n",
      "환경 차 부품 대역 장치 개발 평가 방법 표준 환경 차 전자파 적합 전기차 저주파 평가 방법  eco - friendly car emc ev low frequency evaluation method 환경 자동차 고전압 부품 인버터 대역 측정 방법 승인 투표 채택 국제 표준 종 범위 측정 가능 평가 장치 국산 개발 국제 표준 개정 국제 표준 활동 회의 환경 차 부품 이하 대역 전자파 시험 방법 표준 관련 동향 기술 세미나 개최 환경 차 부품 이하 대역 전자파 시험 측정 표준 보급 확산 국내 중소 제조사 기술 지도 환경 자동차 고전압 부품 인버터 이하 측정 방법 채택 시 작품 제작 성능 평가 국제 표준 회의 참가 독일 프랑크 프루트 환경 자동차 부품 평가 표준 관련 동향 정보 제공 환경 자동차 부품 시험 평가 취약 분야 성능 개선 기술 지원 환경 자동차 고전압 부품 인버터 대역 측정 방법 승인 투표 채택 국제 표준 종 범위 측정 가능 평가 장치 국산 개발 국제 표준 개정 국제 표준 활동 회의 환경 차 부품 이하 대역 전자파 시험 방법 표준 관련 동향 기술 세미나 개최 환경 차 부품 이하 대역 전자파 시험 측정 표준 보급 확산 국내 중소 제조사 기술 지도 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = vectorizer.transform(fail_data)\n",
    "v_array = v.toarray()\n",
    "important_word = []\n",
    "for i in range(200000):\n",
    "    important_word.append([])\n",
    "buffer = 200000*[0]\n",
    "print(\"Fail size:\",len(fail_data))\n",
    "for i,doc in enumerate(fail_data):\n",
    "    print(doc)\n",
    "    #print(v.toarray()[i])\n",
    "    #rev_list =  reversed(np.argsort(v.toarray()[i]))\n",
    "    for j in range(len(v_array[i])):\n",
    "        if(v_array[i][j]>0.0):\n",
    "     #       print(index,feature_names[index])\n",
    "            buffer[j] = 1\n",
    "        \n",
    "    for j in range(len(buffer)):\n",
    "        if buffer[j] > 0:\n",
    "            important_word[j].append(i)\n",
    "            buffer[j] = 0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 [1, 2, 4, 8, 9, 10, 11, 13, 18, 19, 20, 21, 22, 23, 25, 26, 28] 관련 -0.0589689547829\n",
      "12 [0, 3, 5, 6, 7, 10, 14, 17, 20, 21, 24, 27] 구조 -0.014681700471\n",
      "11 [1, 4, 11, 12, 15, 19, 20, 21, 23, 24, 26] 구축 0.00160561546174\n",
      "12 [6, 7, 8, 10, 11, 12, 13, 16, 18, 26, 27, 28] 성능 -0.0459541954862\n",
      "11 [4, 7, 8, 10, 12, 15, 17, 22, 24, 26, 27] 센서 -0.0929137712641\n",
      "16 [1, 2, 4, 8, 9, 10, 11, 13, 14, 16, 18, 19, 22, 24, 25, 26] 시장 0.204275988193\n",
      "15 [0, 5, 6, 7, 9, 10, 11, 16, 17, 18, 22, 24, 25, 27, 28] 제작 -0.106692923436\n",
      "14 [0, 2, 4, 5, 6, 9, 11, 14, 15, 16, 18, 22, 24, 26] 제품 -0.0150238899123\n",
      "16 [0, 1, 2, 3, 7, 8, 9, 13, 14, 16, 18, 20, 24, 25, 26, 27] 효과 0.0356542569683\n"
     ]
    }
   ],
   "source": [
    "for i,count in enumerate(important_word):\n",
    "    if len(count) > 10:\n",
    "        print(len(count),count,feature_names[i],clf.coef_[63][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (\n",
    "        english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
