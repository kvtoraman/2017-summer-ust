{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of text documents using sparse features\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import nltk.stem\n",
    "from optparse import OptionParser\n",
    "import sys, copy\n",
    "from time import time\n",
    "from random import randint\n",
    "#import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk_per_class(clf, actual, predicted, k=5):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items per each class\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : multi list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    class_score = {}\n",
    "    micro_correct = 0.0\n",
    "    length = 0\n",
    "    global ee_correct,ee_tested\n",
    "    global cumulative_class_score\n",
    "    ee_correct = 0\n",
    "    ee_tested = 0\n",
    "    if len(actual) == len(predicted):\t\t\n",
    "\n",
    "        for\ti in range(len(actual)):\n",
    "            if actual[i] not in class_score:\n",
    "                class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "            if actual[i] not in cumulative_class_score:\n",
    "                cumulative_class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "                \n",
    "            well_classified = False\n",
    "            if(guess[i] is not \"\"):\n",
    "                predicted[i][0] = guess[i]    \n",
    "            for pred in predicted[i]:\n",
    "                if actual[i] in pred:\n",
    "                    #if(randint(0, 500) == 50):\n",
    "                    #\tprint(\"act: -\" , actual[i], \"-pred:\", pred,\":\")\n",
    "                    class_score[actual[i]][0] += 1.0\n",
    "                    micro_correct += 1.0\n",
    "                    well_classified = True\n",
    "            if(type(actual[i]) is list):\n",
    "                print(\"!! actual[\",i,\"] is \",actual[i])\n",
    "            if(actual[i] == CODE):\n",
    "                print(well_classified , \"docID:\",i,\"prediction of \",CODE,\" was:\",predicted[i])\n",
    "                fail_list_for_code.append(i)\n",
    "                #print(test_dtm[i].toarray()[0])\n",
    "                #for j,word_rat in enumerate(test_dtm[i].toarray()[0]):\n",
    "                #\tif(word_rat>0.2):\n",
    "                #\t\tprint(word_rat)\n",
    "            class_score[actual[i]][1] += 1.0\n",
    "            length+=1\n",
    "\n",
    "    avg_acc = 0.0\n",
    "    \n",
    "    for cl in class_score.keys():\n",
    "        avg = class_score[cl][0]/class_score[cl][1]\n",
    "        if(avg<0.6 and count[cl]-class_score[cl][1] > class_score[cl][1]):\n",
    "            print(\"!Low precision :! #Correct:\", class_score[cl][0], \"#Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "            fail_list.append(cl)\n",
    "        print (\"\\t\", cl, \"Acc.:\", avg, \"Correct:\", class_score[cl][0], \"Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "        if cl[0] =='E':\n",
    "            ee_correct += class_score[cl][0]\n",
    "            ee_tested += class_score[cl][1]\n",
    "        avg_acc +=avg\n",
    "        cumulative_class_score[cl][0] += class_score[cl][0]\n",
    "        cumulative_class_score[cl][1] += class_score[cl][1]\n",
    "        \n",
    "\n",
    "    print ('Total Test Examples', length, \"\\nMicro Acc.(item level)\", micro_correct/length)\n",
    "    print('Average of EE',ee_correct/ee_tested) \n",
    "    global cumulative_micro_avg\n",
    "    cumulative_micro_avg += micro_correct/length\n",
    "    return avg_acc/len(class_score)\n",
    "\n",
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    # Top 1 \n",
    "    pred = clf.predict(X_test)    \n",
    "    probs = clf.predict_proba(X_test)\n",
    "\n",
    "    for topk in range(5,6):\n",
    "        best_n_label = transform_label(clf, probs, topk)\n",
    "\n",
    "        test_time = time() - t0\n",
    "        print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "        pred = best_n_label\n",
    "        print (\"Top-\", topk)\n",
    "        print (\"Macro Acc.(class level)\", apk_per_class(clf, y_test, best_n_label, topk), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_label(clf, prob, topk):\n",
    "    global target_names\n",
    "\n",
    "    rst_arr = np.empty( (len(prob), topk), dtype=object) \n",
    "    for i in range(len(prob)):\n",
    "        s_items = np.argsort(prob[i])[-topk:]\n",
    "\n",
    "        for j in range(len(s_items)):\n",
    "            rst_arr[i][j] = clf.classes_[s_items[j]]\n",
    "\n",
    "\n",
    "    return rst_arr\n",
    "def apk(actual, predicted, k=5):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : multi list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    if len(actual) == len(predicted):\n",
    "        for\ti in range(len(actual)):\n",
    "            for pred in predicted[i]:\n",
    "                if actual[i] in pred:\n",
    "                    score += 1\n",
    "\n",
    "            if not actual:\n",
    "                return 0.0\n",
    "\n",
    "    return score / len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NSCC  dataset for categories:\n",
      "['ED10', 'ED11', 'EI02', 'EI03', 'EI06', 'EI07', 'EI05', 'EI08', 'EH06', 'EF99', 'EB01', 'EA09', 'EE11', 'EE10', 'EE13', 'EE12', 'EI99', 'EE14', 'EA04', 'EA05', 'ED07', 'ED06', 'ED05', 'ED04', 'ED03', 'ED01', 'EE99', 'ED08', 'EA02', 'EH10', 'EI11', 'EI12', 'EA14', 'EA11', 'EA10', 'EA13', 'EA07', 'EF05', 'EF06', 'ED99', 'EE08', 'EE09', 'EE06', 'EE07', 'EE04', 'EE05', 'EE02', 'EE03', 'EE01', 'SB99', 'ND07', 'OA04', 'LC06', 'SI04', 'SH07']\n",
      "Category size 55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "CODE = \"LC04\"\n",
    "categories =  [x for x in open('KSCC_sample_data_170206_Codelist.dat','r').read().split('\\n') if len(x) > 0]\n",
    "\t\n",
    "remove = ()\n",
    "\n",
    "print(\"Loading NSCC  dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "print(\"Category size\",len(categories))\n",
    "target_names = categories #data_train.target_names\n",
    "\t\n",
    "#data_train = open('KSSC_sample_data_170206_Train.dat').readlines()\n",
    "#data_test = open('KSSC_sample_data_170206_Test.dat').readlines()\n",
    "data_train = open('rev_utf8_train.dat').readlines()\n",
    "#all_data = open('rev_reserved_new_data_all.dat').readlines()\n",
    "all_data = open('kkma_koreanonly_withsentencebreaker_2cols.dat').readlines()\n",
    "#data_test = open('rev_utf8_test.dat').readlines()\n",
    "data_test = open(\"rev_utf8_test.dat\").readlines()\n",
    "ENCODING = 'utf-8'\n",
    "data_train_data, data_test_data = [], []\n",
    "y_train, y_test = [], []\n",
    "all_x = []\n",
    "count = {}\n",
    "all_y = []\n",
    "\n",
    "#read all data    \n",
    "for i,line in enumerate(all_data):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        if items[0][0:2] != 'EE':\n",
    "            continue\n",
    "        items[1] = items[1].split('%%') #name + ' %% ' + kor_kywd + ' %% ' + goal + ' %% ' + abstract + ' %% ' + efct\n",
    "        occur_many_times = \"\"\n",
    "        occur_many_times += items[1][0]*1 + \" \"\n",
    "        occur_many_times += items[1][1]*1 + \" \"\n",
    "        items[1] =occur_many_times + ' '.join(items[1][2:])\n",
    "        all_x.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        #if(items[0] == CODE):\n",
    "        #    print(line)\n",
    "        all_y.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in trai n\",i,len(items))\n",
    "\"\"\"      \n",
    "for i,line in enumerate(data_train):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        data_train_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        y_train.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in train\",i,len(items))\n",
    "for i,line in enumerate(data_test):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        data_test_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        y_test.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in test\",i,len(items))\n",
    "\"\"\"\n",
    "\n",
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guess = 80000*[\"\"]\n",
    "#divides data to train&test with 9:1 ratio\n",
    "def divide_data(rs):    \n",
    "    global data_train_data,data_test_data,y_train,y_test,guess\n",
    "    data_train_data,data_test_data,y_train,y_test = train_test_split(all_x,all_y,random_state =rs, train_size = 0.9)\n",
    "    print (len(data_train_data), len(data_test_data))\n",
    "    print('data loaded')\n",
    "    guess = 80000*[\"\"]\n",
    "    #data_train_data,data_test_data = data_test_data,data_train_data\n",
    "    #y_test,y_train=y_train,y_test\n",
    "    #data_train_data = data_test_data\n",
    "    #y_train = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add Word Embedding (Word Embedding, Topic Embedding, Topic-Event Embedding) Features\n",
    "vectorizer,X_test,X_train = 0,0,0\n",
    "def vectorize():\n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "    my_stop_words = [np.unicode(x.strip(), 'utf-8','ignore') for x in open('kor_stop_word.txt', 'r').read().split('\\n')]\n",
    "    global vectorizer,X_test,X_train\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 100000,\n",
    "                                 min_df=3,ngram_range=(1,1))\n",
    "    #vectorizer = StemmedTfidfVectorizer(stop_words=my_stop_words,max_df=0.5,max_features = 50000,min_df=3)    \n",
    "    X_train = vectorizer.fit_transform(data_train_data)\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "    print(\"Extracting features from the test data using the same vectorizer\")\n",
    "    X_test = vectorizer.transform(data_test_data)\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "    # mapping from integer feature name to original token string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 R_s 5\n",
      "8832 982\n",
      "data loaded\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 8832, n_features: 25473\n",
      "Extracting features from the test data using the same vectorizer\n",
      "n_samples: 982, n_features: 25473\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 3.668s\n",
      "test time:  0.016s\n",
      "Top- 5\n",
      "True docID: 22 prediction of  EE14  was: ['EE01' 'EE11' 'EE14' 'EE99' 'EE02']\n",
      "False docID: 33 prediction of  EE14  was: ['EE04' 'EE99' 'EE01' 'EE09' 'EE06']\n",
      "False docID: 104 prediction of  EE14  was: ['EE02' 'EE08' 'EE10' 'EE09' 'EE03']\n",
      "False docID: 228 prediction of  EE14  was: ['EE13' 'EE06' 'EE99' 'EE04' 'EE09']\n",
      "True docID: 263 prediction of  EE14  was: ['EE11' 'EE99' 'EE14' 'EE01' 'EE02']\n",
      "False docID: 272 prediction of  EE14  was: ['EE11' 'EE99' 'EE09' 'EE02' 'EE01']\n",
      "False docID: 281 prediction of  EE14  was: ['EE06' 'EE99' 'EE10' 'EE01' 'EE02']\n",
      "True docID: 304 prediction of  EE14  was: ['EE14' 'EE10' 'EE02' 'EE01' 'EE03']\n",
      "False docID: 525 prediction of  EE14  was: ['EE10' 'EE09' 'EE02' 'EE11' 'EE06']\n",
      "True docID: 547 prediction of  EE14  was: ['EE04' 'EE14' 'EE05' 'EE11' 'EE06']\n",
      "True docID: 556 prediction of  EE14  was: ['EE10' 'EE01' 'EE14' 'EE99' 'EE02']\n",
      "False docID: 681 prediction of  EE14  was: ['EE06' 'EE01' 'EE99' 'EE02' 'EE11']\n",
      "True docID: 822 prediction of  EE14  was: ['EE03' 'EE11' 'EE02' 'EE14' 'EE99']\n",
      "True docID: 915 prediction of  EE14  was: ['EE14' 'EE09' 'EE01' 'EE02' 'EE99']\n",
      "\t EE05 Acc.: 0.842105263158 Correct: 16.0 Tested: 19.0 #Train 241.0\n",
      "\t EE13 Acc.: 0.8 Correct: 16.0 Tested: 20.0 #Train 184.0\n",
      "\t EE99 Acc.: 0.881578947368 Correct: 67.0 Tested: 76.0 #Train 708.0\n",
      "\t EE07 Acc.: 0.95 Correct: 19.0 Tested: 20.0 #Train 227.0\n",
      "!Low precision :! #Correct: 7.0 #Tested: 14.0 #Train 115.0\n",
      "\t EE14 Acc.: 0.5 Correct: 7.0 Tested: 14.0 #Train 115.0\n",
      "\t EE11 Acc.: 0.887096774194 Correct: 55.0 Tested: 62.0 #Train 578.0\n",
      "\t EE08 Acc.: 0.875 Correct: 21.0 Tested: 24.0 #Train 208.0\n",
      "\t EE09 Acc.: 0.981818181818 Correct: 54.0 Tested: 55.0 #Train 506.0\n",
      "\t EE06 Acc.: 0.960526315789 Correct: 73.0 Tested: 76.0 #Train 650.0\n",
      "\t EE10 Acc.: 0.895833333333 Correct: 43.0 Tested: 48.0 #Train 439.0\n",
      "\t EE04 Acc.: 0.92 Correct: 23.0 Tested: 25.0 #Train 242.0\n",
      "\t EE12 Acc.: 0.90625 Correct: 29.0 Tested: 32.0 #Train 177.0\n",
      "\t EE02 Acc.: 1.0 Correct: 290.0 Tested: 290.0 #Train 2580.0\n",
      "\t EE03 Acc.: 0.924050632911 Correct: 73.0 Tested: 79.0 #Train 671.0\n",
      "\t EE01 Acc.: 0.971830985915 Correct: 138.0 Tested: 142.0 #Train 1306.0\n",
      "Total Test Examples 982 \n",
      "Micro Acc.(item level) 0.940936863544\n",
      "Average of EE 0.940936863544\n",
      "Macro Acc.(class level) 0.886406028966 \n",
      "\n",
      "\n",
      "Trial: 1 R_s 6\n",
      "8832 982\n",
      "data loaded\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 8832, n_features: 25411\n",
      "Extracting features from the test data using the same vectorizer\n",
      "n_samples: 982, n_features: 25411\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 3.639s\n",
      "test time:  0.016s\n",
      "Top- 5\n",
      "False docID: 82 prediction of  EE14  was: ['EE99' 'EE09' 'EE06' 'EE01' 'EE02']\n",
      "True docID: 123 prediction of  EE14  was: ['EE11' 'EE14' 'EE99' 'EE01' 'EE02']\n",
      "False docID: 130 prediction of  EE14  was: ['EE02' 'EE04' 'EE10' 'EE09' 'EE06']\n",
      "True docID: 216 prediction of  EE14  was: ['EE09' 'EE99' 'EE14' 'EE02' 'EE01']\n",
      "True docID: 225 prediction of  EE14  was: ['EE05' 'EE01' 'EE99' 'EE02' 'EE14']\n",
      "False docID: 290 prediction of  EE14  was: ['EE09' 'EE10' 'EE99' 'EE01' 'EE02']\n",
      "True docID: 436 prediction of  EE14  was: ['EE09' 'EE02' 'EE14' 'EE11' 'EE06']\n",
      "False docID: 500 prediction of  EE14  was: ['EE08' 'EE01' 'EE04' 'EE09' 'EE06']\n",
      "True docID: 503 prediction of  EE14  was: ['EE10' 'EE01' 'EE14' 'EE99' 'EE02']\n",
      "False docID: 524 prediction of  EE14  was: ['EE07' 'EE10' 'EE11' 'EE01' 'EE02']\n",
      "False docID: 566 prediction of  EE14  was: ['EE99' 'EE10' 'EE02' 'EE01' 'EE03']\n",
      "False docID: 675 prediction of  EE14  was: ['EE02' 'EE01' 'EE09' 'EE04' 'EE06']\n",
      "True docID: 758 prediction of  EE14  was: ['EE14' 'EE99' 'EE09' 'EE02' 'EE01']\n",
      "False docID: 783 prediction of  EE14  was: ['EE10' 'EE02' 'EE09' 'EE11' 'EE06']\n",
      "\t EE05 Acc.: 0.904761904762 Correct: 19.0 Tested: 21.0 #Train 239.0\n",
      "\t EE99 Acc.: 0.901408450704 Correct: 64.0 Tested: 71.0 #Train 713.0\n",
      "\t EE10 Acc.: 0.9 Correct: 27.0 Tested: 30.0 #Train 457.0\n",
      "!Low precision :! #Correct: 6.0 #Tested: 14.0 #Train 115.0\n",
      "\t EE14 Acc.: 0.428571428571 Correct: 6.0 Tested: 14.0 #Train 115.0\n",
      "\t EE06 Acc.: 0.967391304348 Correct: 89.0 Tested: 92.0 #Train 634.0\n",
      "\t EE04 Acc.: 0.9 Correct: 27.0 Tested: 30.0 #Train 237.0\n",
      "\t EE08 Acc.: 0.681818181818 Correct: 15.0 Tested: 22.0 #Train 210.0\n",
      "\t EE09 Acc.: 0.955882352941 Correct: 65.0 Tested: 68.0 #Train 493.0\n",
      "\t EE11 Acc.: 0.95652173913 Correct: 66.0 Tested: 69.0 #Train 571.0\n",
      "\t EE07 Acc.: 0.875 Correct: 21.0 Tested: 24.0 #Train 223.0\n",
      "\t EE13 Acc.: 0.75 Correct: 12.0 Tested: 16.0 #Train 188.0\n",
      "\t EE12 Acc.: 0.875 Correct: 14.0 Tested: 16.0 #Train 193.0\n",
      "\t EE02 Acc.: 1.0 Correct: 288.0 Tested: 288.0 #Train 2582.0\n",
      "\t EE03 Acc.: 0.971830985915 Correct: 69.0 Tested: 71.0 #Train 679.0\n",
      "\t EE01 Acc.: 0.98 Correct: 147.0 Tested: 150.0 #Train 1298.0\n",
      "Total Test Examples 982 \n",
      "Micro Acc.(item level) 0.946028513238\n",
      "Average of EE 0.946028513238\n",
      "Macro Acc.(class level) 0.869879089879 \n",
      "\n",
      "\n",
      "Trial: 2 R_s 7\n",
      "8832 982\n",
      "data loaded\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 8832, n_features: 25436\n",
      "Extracting features from the test data using the same vectorizer\n",
      "n_samples: 982, n_features: 25436\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 3.918s\n",
      "test time:  0.016s\n",
      "Top- 5\n",
      "True docID: 58 prediction of  EE14  was: ['EE99' 'EE02' 'EE05' 'EE06' 'EE14']\n",
      "True docID: 181 prediction of  EE14  was: ['EE09' 'EE10' 'EE14' 'EE99' 'EE02']\n",
      "False docID: 234 prediction of  EE14  was: ['EE11' 'EE04' 'EE02' 'EE06' 'EE07']\n",
      "False docID: 243 prediction of  EE14  was: ['EE99' 'EE09' 'EE11' 'EE06' 'EE03']\n",
      "False docID: 266 prediction of  EE14  was: ['EE10' 'EE99' 'EE01' 'EE02' 'EE03']\n",
      "True docID: 347 prediction of  EE14  was: ['EE09' 'EE99' 'EE01' 'EE02' 'EE14']\n",
      "False docID: 482 prediction of  EE14  was: ['EE99' 'EE05' 'EE01' 'EE03' 'EE11']\n",
      "True docID: 539 prediction of  EE14  was: ['EE11' 'EE01' 'EE14' 'EE99' 'EE02']\n",
      "True docID: 563 prediction of  EE14  was: ['EE02' 'EE14' 'EE05' 'EE11' 'EE06']\n",
      "False docID: 632 prediction of  EE14  was: ['EE10' 'EE11' 'EE99' 'EE01' 'EE02']\n",
      "False docID: 703 prediction of  EE14  was: ['EE04' 'EE99' 'EE02' 'EE06' 'EE11']\n",
      "True docID: 719 prediction of  EE14  was: ['EE11' 'EE14' 'EE99' 'EE04' 'EE06']\n",
      "False docID: 961 prediction of  EE14  was: ['EE11' 'EE01' 'EE02' 'EE06' 'EE04']\n",
      "!Low precision :! #Correct: 6.0 #Tested: 13.0 #Train 116.0\n",
      "\t EE14 Acc.: 0.461538461538 Correct: 6.0 Tested: 13.0 #Train 116.0\n",
      "\t EE05 Acc.: 0.846153846154 Correct: 22.0 Tested: 26.0 #Train 234.0\n",
      "\t EE99 Acc.: 0.977011494253 Correct: 85.0 Tested: 87.0 #Train 697.0\n",
      "\t EE07 Acc.: 0.892857142857 Correct: 25.0 Tested: 28.0 #Train 219.0\n",
      "\t EE03 Acc.: 0.985915492958 Correct: 70.0 Tested: 71.0 #Train 679.0\n",
      "\t EE06 Acc.: 0.929577464789 Correct: 66.0 Tested: 71.0 #Train 655.0\n",
      "\t EE08 Acc.: 0.782608695652 Correct: 18.0 Tested: 23.0 #Train 209.0\n",
      "\t EE09 Acc.: 0.983050847458 Correct: 58.0 Tested: 59.0 #Train 502.0\n",
      "\t EE11 Acc.: 0.981481481481 Correct: 53.0 Tested: 54.0 #Train 586.0\n",
      "\t EE10 Acc.: 0.84 Correct: 42.0 Tested: 50.0 #Train 437.0\n",
      "\t EE13 Acc.: 0.76 Correct: 19.0 Tested: 25.0 #Train 179.0\n",
      "\t EE12 Acc.: 0.869565217391 Correct: 20.0 Tested: 23.0 #Train 186.0\n",
      "\t EE02 Acc.: 1.0 Correct: 288.0 Tested: 288.0 #Train 2582.0\n",
      "\t EE04 Acc.: 0.758620689655 Correct: 22.0 Tested: 29.0 #Train 238.0\n",
      "\t EE01 Acc.: 1.0 Correct: 135.0 Tested: 135.0 #Train 1313.0\n",
      "Total Test Examples 982 \n",
      "Micro Acc.(item level) 0.946028513238\n",
      "Average of EE 0.946028513238\n",
      "Macro Acc.(class level) 0.871225388946 \n",
      "\n",
      "\n",
      "EE14 3\n",
      "Cumulative 0.944331296673\n"
     ]
    }
   ],
   "source": [
    "#results = []\n",
    "# Train SGD model\n",
    "accumulated_fail_list = {}\n",
    "TRIAL_SIZE = 3\n",
    "RANDOM_STATE_START = 5\n",
    "cumulative_micro_avg = 0\n",
    "ee_correct = 0\n",
    "ee_tested = 0\n",
    "cumulative_class_score = {}\n",
    "CODE = 'EE14'\n",
    "for t,trial in enumerate(range(RANDOM_STATE_START,RANDOM_STATE_START + TRIAL_SIZE)):\n",
    "    print(\"Trial:\",t,\"R_s\",trial)\n",
    "    divide_data(trial)\n",
    "    vectorize()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    feature_names = np.asarray(feature_names)\n",
    "    fail_list = []\n",
    "    fail_list_for_code = []\n",
    "    cumulative_class_score = {}\n",
    "    suggested_n_iter = np.ceil(10**6/len(data_train_data))\n",
    "    clf = SGDClassifier(loss='log', alpha=.0001, n_iter=50, penalty=\"l2\")\n",
    "    benchmark(clf)\n",
    "    for x in fail_list:\n",
    "        if not accumulated_fail_list.has_key(x):\n",
    "            accumulated_fail_list[x] = 0\n",
    "        accumulated_fail_list[x] +=1\n",
    "    #print(fail_list)\n",
    "    for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] == TRIAL_SIZE:\n",
    "            print(x,accumulated_fail_list[x])\n",
    "print('Cumulative',cumulative_micro_avg/TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statistics = open('statistics_2ndtest.txt','w')\n",
    "statistics.write('\\t'.join(['CODE','ALL','TRAIN','TEST','CORRECT','correct%'])+'\\n')\n",
    "\n",
    "for x in count:\n",
    "    a_row = [x,count[x],count[x]-cumulative_class_score[x][1],cumulative_class_score[x][1],cumulative_class_score[x][0],cumulative_class_score[x][0]/cumulative_class_score[x][1]]#code,train,tested,correct\n",
    "    for i in range(len(a_row)):\n",
    "        a_row[i] = str(a_row[i])\n",
    "    statistics.write('\\t'.join(a_row)+'\\n')\n",
    "statistics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE14 2\n"
     ]
    }
   ],
   "source": [
    "for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] >= TRIAL_SIZE -2:\n",
    "            print(x,accumulated_fail_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE14 [6.0, 13.0] 387\n",
      "EE08 [14.0, 23.0] 696\n"
     ]
    }
   ],
   "source": [
    "for x in cumulative_class_score:\n",
    "    if(x[0] == \"E\"):\n",
    "        if(cumulative_class_score[x][0]/cumulative_class_score[x][1]<0.7):\n",
    "            print(x,cumulative_class_score[x],count[x]*TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7c874a83a4ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"features.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_names' is not defined"
     ]
    }
   ],
   "source": [
    "out = file(\"features.txt\",\"w\")\n",
    "\n",
    "for x in feature_names:\n",
    "    out.write(x.encode('utf-8','ignore')+\"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class index of EE02 is 34\n",
    "#class index of LC06 is 94\n",
    "#class index of EE99 is 47\n",
    "#class index of EA10 is 9 \n",
    "#class index of EF05 is 50 \n",
    "#\n",
    "CODE_INDEX = clf.classes_.tolist().index('EE14')\n",
    "CODE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE02\n",
      "1.14282592455 app\n",
      "1.35856181444 cloud\n",
      "1.56298887264 embedded\n",
      "1.00810311453 image\n",
      "1.02605625006 multicore\n",
      "1.08067565512 music\n",
      "2.3271957126 platform\n",
      "1.20196970714 rendering\n",
      "1.0364109946 simulation\n",
      "1.02092016285 so\n",
      "2.79176164434 software\n",
      "2.47863959191 sw\n",
      "1.32141350468 tech\n",
      "1.13308878661 tracking\n",
      "2.06660542952 web\n",
      "1.33178010219 강화\n",
      "1.50167551358 개발자\n",
      "1.05606228776 결제\n",
      "1.55986971754 고객\n",
      "1.29020565052 공유\n",
      "2.09518744953 관리\n",
      "1.24088950893 관리자\n",
      "1.17888577906 교사\n",
      "1.18943007222 구매\n",
      "1.7415797119 기능\n",
      "1.10779759143 기록\n",
      "1.45299159421 내역\n",
      "1.16071690455 다운로드\n",
      "1.00101769818 단위\n",
      "1.07040836642 당사\n",
      "1.27274768745 데이타\n",
      "1.59657845701 데이터\n",
      "1.77572160479 디드\n",
      "1.14986143742 렌더링\n",
      "1.23182666525 로그\n",
      "1.30493359151 마케팅\n",
      "2.348930167 모바일\n",
      "1.29357447527 문서\n",
      "1.32225690476 병렬\n",
      "1.50676687555 보유\n",
      "1.01439895341 사이트\n",
      "1.12402702271 생성\n",
      "1.13137792521 서버\n",
      "2.29382990353 소프트\n",
      "2.32077474088 소프트웨어\n",
      "2.47716902662 솔루션\n",
      "1.61772515009 실시간\n",
      "1.15766332857 실행\n",
      "1.03876081429 언어\n",
      "1.97243565374 엔진\n",
      "1.15787020202 오픈\n",
      "1.56851799932 온라인\n",
      "1.18242318161 운영체제\n",
      "2.16268366543 웨어\n",
      "1.68934873822 웹기반\n",
      "1.11338094789 웹서비스\n",
      "1.07732645541 유저\n",
      "1.28842449841 융합기술고도화\n",
      "1.1930366814 이미지\n",
      "1.82391415578 임베디드\n",
      "1.2533675441 임상\n",
      "1.49825589279 입력\n",
      "1.60904671325 자동\n",
      "1.04496577096 자동차\n",
      "1.56453013401 전문\n",
      "1.65154839704 전문가\n",
      "1.27709802413 제공\n",
      "1.05413576356 제품\n",
      "1.02287818683 조작\n",
      "1.1469704367 조회\n",
      "1.07813718373 주제\n",
      "1.48411536149 지원\n",
      "1.46467884013 처리\n",
      "1.45652771505 체크\n",
      "1.61347833169 추가\n",
      "1.63451063029 출시\n",
      "1.10844941985 커뮤니케이션\n",
      "1.89256348435 컨텐츠\n",
      "1.36665008692 콘텐츠\n",
      "1.23968493009 통합\n",
      "1.11239411309 파일\n",
      "1.47768812759 프로그램\n",
      "1.74331021308 플랫폼\n",
      "1.19944670321 피드백\n",
      "1.24211807825 학생\n",
      "1.00174667238 한글\n",
      "1.13304307909 해당\n",
      "1.18092925977 확인\n",
      "1.07336231864 회원\n"
     ]
    }
   ],
   "source": [
    "#deceiving category? EE02?\n",
    "#Powerful features of EE02, the biggest category\n",
    "INDEX_BLACK = clf.classes_.tolist().index('EE02')\n",
    "black_list = []\n",
    "print(clf.classes_[INDEX_BLACK])\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(3>clf.coef_[INDEX_BLACK][i]>1):\n",
    "        print(clf.coef_[INDEX_BLACK][i],x)\n",
    "        black_list.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.85820428818 개량\n",
      "3.44732940234 국방\n",
      "1.06609625693 모델\n",
      "1.99463392068 모의\n",
      "1.22750711579 무선메쉬백\n",
      "1.16471629469 방해\n",
      "1.70504379588 분석모델\n",
      "1.01187581621 비기상\n",
      "1.67498171545 성능개량\n",
      "1.11475319915 연합\n",
      "2.81311470684 전술\n",
      "1.56024056575 지상\n",
      "1.0436526559 지휘\n",
      "1.0029989774 체계\n",
      "1.40958937748 통신미들웨어\n",
      "1.16612003247 트레드밀\n",
      "1.07151674659 특화연구센터\n",
      "1.39904352593 특화연구실\n",
      "1.77380032494 합동\n"
     ]
    }
   ],
   "source": [
    "white_list = []\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(clf.coef_[CODE_INDEX][i]>1):\n",
    "        print(clf.coef_[CODE_INDEX][i],x)\n",
    "        white_list.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE14 tactical data link , n cw 국방 전술 전술통신 통신 기술 연구 전술데이터링크 데이터 링크 데이터링크 합동 완성 차기 차기위성 위성 구축 네트워크 핵심 개발 분야 이론 실무 겸비 전문 인력 양성 인지 기반 주파수 관리 방어 설계 안전 그룹 보안 전송 전투 전투무선망 무선망 효과 효과적인 적인 무선 전송제어 제어 재 재밍 밍 환경 신뢰성 향상 재 재밍 극복 망 생존 유지 체계 그룹간 간 운용 지상 지상망 연동 라 라우팅 우 팅 전략 보장 간 협업 규칙 매칭 시스템 간섭 영향 최소화 그룹협력통신 협력 지원 전술네트워크 자원 자원관리 프로 프로토콜 토 콜 협력기반 확보 스마트 산업 기여도 국방분야 기대 파급 파급효과 전장 전장공간 공간 정보 정보우위 우위 실시간 교전 교전능력 능력 핵심요소 요소 육 해 공군 합동 합동작전 작전 향후 센서 무기 타격 타격체계 적용 군수 군수물자 물자 수출 기여 수 해외 수입 막대 대체 취득 추후 우주 국방시대 시대 요구 기술요소 응용 국가 경쟁력 증대 이바지 가능 차세대 한국군 무기체계 첨단 가속 민간 공공 공공분야 전자 관련 핵심기술 군수산업 부가 부가가치 가치 이동 이동통신 4 5 등 상용 원천 국제 표준화 주도 재난 경보 구조 구조체계 적용가능 상황 상황공유 공유 절약 인명 인명피해 피해 요소기술 항공기 헬리콥터 인공 인공위성 다양 기업 산업화 창출 선진국 의존도 낮춤 경제적 민간분야 기대효과 현재 미군 변경 정도 기술력 사용 원천기술료 기술료 지급 상태 독자적 이용 통해 뿐 국방연구개발비 개발비 절감 부족 국방비 기초 인터넷 인터넷망 구성 중추적 역할 담당 동시 통신기술 국가경쟁력 독자 독자적인 동남아 지역 군 천문학 국가적 예상 기술인 앞 한국 주도적 기술적 성능 문제 해결 전술통신환경 최적 변조 기법 단말 전송성능 전술정보 교환 효율성 신\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(y_test[fail_list_for_code[0]],data_test_data[fail_list_for_code[0]])\n",
    "fail_data = []\n",
    "for x in fail_list_for_code:\n",
    "    fail_data.append(data_test_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tactical data link , n cw 국방 전술 전술통신 통신 기술 연구 전술데이터링크 데이터 링크 데이터링크 합동 완성 차기 차기위성 위성 구축 네트워크 핵심 개발 분야 이론 실무 겸비 전문 인력 양성 인지 기반 주파수 관리 방어 설계 안전 그룹 보안 전송 전투 전투무선망 무선망 효과 효과적인 적인 무선 전송제어 제어 재 재밍 밍 환경 신뢰성 향상 재 재밍 극복 망 생존 유지 체계 그룹간 간 운용 지상 지상망 연동 라 라우팅 우 팅 전략 보장 간 협업 규칙 매칭 시스템 간섭 영향 최소화 그룹협력통신 협력 지원 전술네트워크 자원 자원관리 프로 프로토콜 토 콜 협력기반 확보 스마트 산업 기여도 국방분야 기대 파급 파급효과 전장 전장공간 공간 정보 정보우위 우위 실시간 교전 교전능력 능력 핵심요소 요소 육 해 공군 합동 합동작전 작전 향후 센서 무기 타격 타격체계 적용 군수 군수물자 물자 수출 기여 수 해외 수입 막대 대체 취득 추후 우주 국방시대 시대 요구 기술요소 응용 국가 경쟁력 증대 이바지 가능 차세대 한국군 무기체계 첨단 가속 민간 공공 공공분야 전자 관련 핵심기술 군수산업 부가 부가가치 가치 이동 이동통신 4 5 등 상용 원천 국제 표준화 주도 재난 경보 구조 구조체계 적용가능 상황 상황공유 공유 절약 인명 인명피해 피해 요소기술 항공기 헬리콥터 인공 인공위성 다양 기업 산업화 창출 선진국 의존도 낮춤 경제적 민간분야 기대효과 현재 미군 변경 정도 기술력 사용 원천기술료 기술료 지급 상태 독자적 이용 통해 뿐 국방연구개발비 개발비 절감 부족 국방비 기초 인터넷 인터넷망 구성 중추적 역할 담당 동시 통신기술 국가경쟁력 독자 독자적인 동남아 지역 군 천문학 국가적 예상 기술인 앞 한국 주도적 기술적 성능 문제 해결 전술통신환경 최적 변조 기법 단말 전송성능 전술정보 교환 효율성 신\n",
      "\n",
      "ict , realtime monitoring , convergence , logistics , aviation 한국형 군수 군수무인기 무인기 기반 전술 전술군수 융합 융합시스템 시스템 개발 실시간 실시간모니터링 모니터링 항공  1 1 세부 세부 첨단 제작 응용 신뢰성 연구  2 2 세부 자율 중 무인 에이전트 설계 구현  3 3 세부 다 다중관 중관 네트 네트워킹 워킹 기술  4 4 세부  5 5 세부 스마트 물류 태양광 태양 태양에너지 에너지 축적 항공기 위치 자세 비행 동역학 모델링 기체 파라 파라포일시스템 포일 유도 유도제어 제어 알고리즘 바람 경우 추정 기법 기법연구 최종 착지 소프트 소프트랜딩기법 랜딩 비행시험 시험 수행 비행데이터 데이터 분석 파라포일의 포 일의 가용성 종합 종합분석 센서 네트워크 소프트웨어 웨어 평가 결과 향상 방안 에이전트기반 기능 의사 의사결정 결정 단위체 구성 이용 단일 구조 국방 전력 극대화 협업 협조 중재 다중 기계 기계학습 학습 환경 환경감지 감지 싱 싱인지 인지 항행 내 션 기술개발 좌표 카메라 적외선 초음파 초음파센서 자이로 자이로센서 등 티 통신 플랫폼 전방 라이 통 적 탐색 위치정보 정보 전송 전송기술 전술데이터링크 링크 지상 지상지원 지원 항공관제센터 관제 센터 지휘 지휘본부 본부 간 정보연계 연계 다중관제 용 통신단말 단말 데이터링크 수요 공급 사슬 관리 통합 도입 적합 품종 품종관리 이송 물류보관 보관 모델 구축 고려 운영 스케쥴 스케쥴링 링 기기 배정 자원 유기적 주기적 추적 배분 무인전력 라 라우팅 우 팅 시 비상 상황 형 화물 화물공수 공수 민군 활용 가능성 확장 자동 자동비행 제어기술 국산화 기존 무인기의 기의 정찰 자료 자료수집 수집 수준 물류지원 분야 감시 수색 다양 응용기술 세계 우위 선점 한국 전술체계 체계 표준화 진행 자원배분 스케줄 스케줄링 관련 관련기술 적용 확산 신규 비즈니스 창출 공중 공중보급체계 보급 개선 신속성 증대 효율적 자산 자산관리역량 역량 강화\n",
      "\n",
      "multimedia communication , scalable video codec , networked video codec , h w sw co design , bc n , system partition , iptv , realistic broadcasting , synthesis 급 고효율 코덱 기반 제어 기술 개발 멀티미디어 통신 계층 비디오 네트워크 하드웨어 소프트 소프트웨어 웨어 통합 통합설계 설계 광대역 광대역통합망 망 시스템 분 차세대 이종 이종망 환경 적합 요소 제안 이 요소기술 이용 실감 방송 등 미래형 방송기술 핵심 발판 마련 산업 분야 신 신성장 성장 동력 수 국제 기술력 확보 압축 부 복호 해상도 입력 시퀀스 실시간 복 레이어 레이어간 간 예측 방법 호화 개선 구조 부복호기 복호기 속도 미디어 스트리밍 전송 연구 고려 스트림 영상 품질 채널 특성 알고리즘 획득 표현 시 공간적 생성 기법 발생 열화 제거 감 다시 화질 점 영상간 간 상관관계 처리 콘텐츠 비트 결정 방안 평가 시뮬레이션 구축 이종망환경 중 접속 서버 클라이언트 구현 버퍼 조절 변화 본 효과적 다양 단말기 서비스 사용자 제공 연구결과 결과 화상 화상통신 관련 방송통신 융화 디지털 기기 융복 융복합화 합화 로 플랫폼 간의 호환성 문제 중장기 동 동력를 력를 촉진 사회적 비용 절감 관련업체 업체 리듬 복잡 효율적 가능 추가적 해외 시장 경쟁력 실제 기업 공동 공동연구 추진 실무 경험 미래 사회 필수적 제품 창조적 발상 맞춤 인력 양성 국내 연구소 진출 저전력 생산 국가 밑거름\n",
      "\n",
      "physical layer security , wireless channel , quantum key distribution , no - cloning theorem 무선 채널 복제 불가 특성 활용 완벽 완벽보안 보안 시스템 개발 물리 물리계층 계층 양자 보안키 키 분배 본 연구 대규모 다중 안테나 전송 기술 암호 통신 원리 응용 환경 일 대 다수 프로 프로토콜 토 콜 제안 분배과정 과정 발생 가능 능동적 도청 도청행위 행위 공격 시나리오 제시 탐지 수 송수신 검출 기법 프로토 나 아가 성능 검증 수행 사용자 통신환경 감지 판별 감지기 설계 달성 평균 생성 계산 무선통신 사전 필요 경우 일회성 장치 적 탈취 구조 공개 위험 방지 정보 정보이론 이론 신호 신호처리 처리 융합 형태 원천 확보 일반적 사용 범용 창의 방법 예산 통신시스템 보급\n",
      "\n",
      "account management , honey account , access control , big data , account leakage detection 웹 서비스 사용자 계정 정보 관리 유출 악용 탐지 기술 개발 어카운트 접근 접근통제 통제 계정유출탐지 계정관리 빅 빅데이터 데이터 이동식 저장 매체 등 활용 개인 암호화 자동 로그 로그인 인 입력 분석 이용 대규모 시도 안전 안전성과 성과 효율성 보장 자동화 생성 적용 의심 통보 해커 발생 시 실제 알람 제공 추가 인증 의 도메인 국가 접속 수집 블랙 블랙리스트 리스트 소지 소지기반 기반 계정정보 실 단말 웹서비스 유출탐지 시스템 저장매체 보안 일반 생 성 갱신 삭제 방식 자동로그인 주기적 위치 식별 식별값 값 단말정보 실시간 사용자행위 행위 프로 프로파일링 파일링 스코어 룰  2 2 차 차 수행 국내 4 , 0 0 0 대의 스마트 스마트폰 폰 모바일 결제 등 핀 핀테크 테크 접목 새 시장 창출 가능 예상 지속 범용 플랫폼 적용시 시대 조기 유도 표준화 보급 보급시 세계 개척 점유\n",
      "\n",
      " 합동 합동정보모의모델 정보 모의 모델\n",
      "\n",
      "deep learning , neural network , detection , antenna , algorithm 딥 딥러닝 러닝 이용 보안 전자 전자소자 소자 탐지 시스템 개발 신경 신경회로망 회로망 안테나 알고리즘 목표 본 연구 인식 인식기술 기술 초고 초고주파 주파 신호 신호처리 처리 초소형 반도체 탐지시스템 장치 세부 규격 작성 분별 시뮬레이션 후 시제품 제작 디지털 보드 초기 기능 구현 각 인터페이스 설계 자체 성능 성능시험 시험 함 식 학습 패턴 실험 송수신 송수신모듈 모듈 검토 설정 멀티 멀티채널 채널 회로 회로설계 기구 기구설계 도면 신호처리부 부 운용 운용프로그램 프로그램 처리부 다양 환경 간섭 요인 제거 측정 설계도면 검증 도면작성 시험환경 구성 지그 구축 시험용 탐지기 지능 분류 가능 적용 러 러스터링 스터링 적응 호의 오작동 여부 판별 인식률 획기적 향상 레이더 사용 수 융합 이 유사 산업 산업분류 기술발전 발전 기여 예상 제안 주파수 추정 추정방법인 방 법인 위치 방식 현재 수행 외국 크기 파악 세계 최초 진일보 능력 경쟁 제품 9 0 0 대역 국내 자유 2 . 4 필요 동작 원리 원리상 상  3 3 고조파 고조파 지원 독창적 구조  7 . 4 3 중대역 중대 역 광대역 판매 판매가능 영국 미국 상태 정형 보안검색대 검색 대 형태 장비 때문 탐지확률 확률 효율적 독자 확보 유럽 등 국가 기술경쟁력 경쟁력 측면 우위 선점\n",
      "\n",
      "idea audition , defense it sw fusion , smart value academy , military creative innovator , military innovation value 국방 융합 융합지원센터 지원 센터 아이디어 아이디어오디션 오디션 가치 가치창조아카데미 창조 아카데미 창조적 군사 군사혁신 혁신 전문가 군사혁신가치 1 국방산업별 산업별 수요 수요기업 기업 간 실질적 추진 민간 역량 역량강화 강화 상시 거점 거점기관 기관 구축 운영 2 수용 간 네트워크 뮤 케이 케이선 선 확대 사업 사업연계 연계 융합사업 모델 발굴 애로 애로사항 사항 해소 등 기반 기반구축 사업추진 기반조성 조성 협의체 사업수행 수행 후 전문 기술 구비 다수 필요성 인식 교육 훈련 군의 동기 유발 파급 파급효과 효과 개혁 견인 발전 정체 국방걔혁 이행 이행방안 방안 전달\n",
      "\n",
      "- . sds ( software defined syst me ) - . adc ( analog to digital converter ) - . dac ( digital to analog converter ) - . giga sampling - . bandwidth 광대역 기술 이용 분리형 기지국 장비 장비개발 개발 소프트 소프트웨어 웨어 기반 시스템 아날로그 디지털 변환 기가 샘플링 신호 대역폭 국방 분야 전자전 사용 중인 바탕 차세대 이동 이동통신 통신 5 이동통신용 통 신용 전체 1 별도 협대역 직접 처리 수 신호처리 필요 요구 수행 저속 하드웨어 복잡 비효율 장치 효율 활용 요소 다음 포함 고속 병렬 신호처리리 리 위 채널 채널라이 라이 결합 모듈 모듈과의 과의 연동 시리얼 인터페이스 군수 외의 레이더 위성 데이터 수신기 등 확대 적용 첨단 무기 무기체계 체계 독자 능력 확보 있음 민수 무선 무선통신 무선네트워크 네트워크 뿐 밀리미터 밀리미터파 파 센서 의료 의료분야 가능\n",
      "\n",
      "fluid animation , computer graphics , example based animation , machine learning , physics based simulation , vector potential , realtime animation , feature extraction , dimension reduction 예제 기반 유체 애니메이션 컴퓨터 그래픽스 기계 학습 물리 시뮬레이션 벡터 포 포터 터 셜 실시간 애 본 연구 정보 획득 분석 재구성 실제 포착 유동 유동장 장 데이터 계산 수치 사용자 요구 유 체 스타일 선택 소스 위치 유도 경로 등 변경 동일 수준 고품질 영상 초당  3 0 3 0 프레임 프레임 이상 수행 능력 연구과제 과제 기술 핵심 응용 심화 단계 구분 해당 개발 단순 형태  2 2 차원 차원 뒤 변화 새 실험 근간 체계 수립 전체 프레임 프레임워크 워크 완성 검증 방법론  3 3 차원 확장 크기 확대 축소 물리적 엄밀성 적용 문제 해결 활용 물체 상황 경계 조건 처리 도전 대규모 라이브러리 구축 산업 가능성 기술적 측면 의존 분야 본격적 제안 생산성 획기적 개선 패러다임 결과 영화 광고 모바일 플 플리케이션 리 케이 션 미디어 콘텐츠 내 장면 제작 특성 게임 방송 실 시간 효용 데 일조\n",
      "\n",
      "wire communication , transmission distance , long distance communication , ethernet , poe 선 최대 1 전원 통신 동시 전송 장거리 전송시스템 시스템 유선 유선통신 전송거리 거리 장거리통신 이더넷 파워 파워오버이더넷 오버 현재 통신제품 제품 작동 기술 개발 상태 활용 전원선 사용 연결 공급 수 때문 일상생활 적용 가능 우리 실질적 이유 다음 전압 3 6 5 7 5 1 2 직접적 일상적 생활 안정적 장거리전송 고전 경우 안전 위험성 한계 일반인 2 가격 회로 회로구조상 구조상 칩셋 칩셋가격  4 0 0 0 4 0 0 0 원정도 원 정도 칩셋주변회로 주변 해당 부품 부품가격  2 0 0 0 2 0 0 0 원  1 0 0 0 0 1 0 0 0 0 원 전환 컨버터  5 0 0 0 5 0 0 0 원 제조원 제조원가상 가상 소비자 판매 판매가격 제품당 당  4 5 만원정도 만 부담 답 답터 터  1 개 개 때 가격차이 차이 산업용 실정 3 신호 보통 1 0 0 리피터 설치 이더넷신호 증폭 통신신호 이용 4 0 0 5 0 0 이 전원공사 공사 근처 전기 추가적 문제점 최종 최종개발목표 목표 위 서술 기술적 단점 개선 자사 약점 중 하나 하나인 인 이번 이번개발 최종목표 저희 제품구성 구성 구분 인젝터 외부 결합 선하나 장비 외부이더넷신호 외부전력 전력 전송가능 그 필요 일부 기능 포함  9 9 개 최소한 전력소비 소비 최소화 설계 핵심 젠더 기반 기존 호환 필수적 최종개발내용 내용 앞 달성 바 나르크테크놀로지 효율적 설계도 구상 창업 창업과제 과제 선정 즉시 구상도 실현 마감일 내 계획 출시 상당 비중 차지 채택 상대적 여지 대개 건물 건물외부 곳 안 천장 구석 등에 각각 통신선과 선과 비용 요소 자리 범죄 범죄예방 예방 사건 사고 등 증거 증거확보 확보 효과적 감시 공공 공공기관 기관 사기업 개인 개인소비자 수요 증가 추세 공급업체 업체 측면 경쟁 경쟁업체 구매 욕구 공사비용 설치비용 시대적 선호 선호사항 사항 생각 궁극적 목적 전원공사비용 절감 편리성 기준 평균  3 0 3 0 만 추산 전원공사비용자체 자체 무엇 면 매력적 판단 일정 일정거리 이상 상황 군사 군사시설 시설 무선 무선신호 규제 유선통신기술인 기술인 군부대 특성 광범위 지역 통제 데 직면 대부분 산악 산악지형 지형 방식 불가능  2 0 1 4 2 0 1 4 년 년  1 2 월 월 국방부 요청 자사기술 시연 시연발표 발표 육군 육군정보통신학교 정보 학교 실시 부작용 범죄예방효과 효과 감시효과 증거확보효과 순기능 활 활용처 용처 요즘 장거리전송시스템 행정 행정기관 기업 해외 누구 어디 시장 대항 대항마 마 장 이 개척 자사측면 매출 증대 증대효과 기대 뿐 사회적 이전 동일 수준 보안 보안효과 나 아가 개인보안 투자 경제 경제부문 부문 국민 국민경제 이바지\n",
      "\n",
      "mobile mesh network , bio inspired , transmission technique , mathematical modeling , distributed synchronization , military communication 이동성 광대역 메 메쉬 쉬 통신 통신시스템 시스템 전송 기술 연구 이동 수학적 모델링 분산 동기화 군 군통신 국방 국방정보통신용 정보통 신용 무선망 구축 등 적합 노드 보장 경우 군함 전투기 헬리콥터 함대 비행 편 편대간 대간 효율적 사용 수 있음 다양 생물체 행동 원리 관찰 기반 고안 리듬 네트워크 적용 존재 처리 자원 할당 분야 문제 해결 가능 과제 목표 이 기법 군통신망 통신망  1 1 차년도 차 년도 전송기술 세부 내용 모델 시간 변동 연결 구조 송 수신 방식 레인 레인징 징 동기 간섭 전력 전력제어 제어 채널 핸드 핸드오버 오버  2 2 차년도 개발 이론 최적 배치 점근 네트워크상의 상의 정보 교환 지연 효과 프레임 프리 프리앰 앰 설계 고려 처리형 형  3 3 차년도 시뮬레이터 학문적 기대 기대효과 고속 관련 인력 양성 석 박사 관리 비상 재난 양성응용 응용 전술 전술이동통신망 전투 편대 무선 무선통신망 도시 철도 항만 도로 공장 학교 경찰 소방서 비상재난 긴급 특수 임무 지원\n",
      "\n",
      "network latency , transport protocol , g cellular network , next generation internet , smart wearable device , queueing theory , buffer bloat , hyper realtime internet services 최저 지연 지연시간 시간 달성 차세대 전송 프로 프로토콜 토 콜 설계 연구 5 셀룰러 네트워크 인터넷 스마트 이동 이동단말 단말 이론 버퍼 로트 초실 초실시간 본 원격 원격수술 수술 교 교통제 통제 증강 증강현실 현실 클라우드 게이 게이밍 밍 등 성능 우선 고부 응용 응용서비스 서비스 가능 최종 최종목표 목표 다음 포함 간 순위 균형 균형점 점 지정 제어 알고리즘 지원 소켓 1 0 오더 보장 계층 구조 초고 초고속 속 1 전송율의 율의 관계 분석 이용 상호 수학적 조절 전 송 반응 함수 도출 손실 최소화 허용 허용가능 제어기법 기법 개발 제안 구현 간의 임의 수 리눅스 다양 모바일 운영 운영체제 체제 송신단 신단 수신 각각 협력 동작 송수신 송수신단의 단의 변경 경우 한쪽 송수신단 단 효율 보완 간 공평 실측 테스트 테스트베드 베드 구축 별 현 비효율 입증 기존 공존 가능성 교통 원천 기술 지적 지적재산권 재산권 확보 전송률 우선순위 탐색 혁신 패러다임 탈피 대량 발굴 이 시연 신규 창업 시장 선도 기회 제공\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = vectorizer.transform(fail_data)\n",
    "v_array = v.toarray()\n",
    "important_word = 80000*[0]\n",
    "buffer = 80000*[0]\n",
    "for i,doc in enumerate(fail_data):\n",
    "    print(doc)\n",
    "    #print(v.toarray()[i])\n",
    "    #rev_list =  reversed(np.argsort(v.toarray()[i]))\n",
    "    for j in range(len(v_array[i])):\n",
    "        if(v_array[i][j]>0.0):\n",
    "     #       print(index,feature_names[index])\n",
    "            buffer[j] = 1\n",
    "        \n",
    "    for j in range(len(buffer)):\n",
    "        if buffer[j] > 0:\n",
    "            important_word[j] += 1\n",
    "            buffer[j] = 0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 구조\n",
      "8 구축\n",
      "5 국방\n",
      "7 네트워크\n",
      "6 다양\n",
      "5 데이터\n",
      "5 무선\n",
      "5 보안\n",
      "6 분야\n",
      "6 사용\n",
      "8 설계\n",
      "7 수행\n",
      "5 실시간\n",
      "6 응용\n",
      "8 이용\n",
      "8 적용\n",
      "7 전송\n",
      "5 제어\n",
      "6 지원\n",
      "5 채널\n",
      "6 처리\n",
      "7 통신\n",
      "7 확보\n",
      "5 환경\n",
      "5 효율적\n"
     ]
    }
   ],
   "source": [
    "#words that appear frequently in our low-quality code\n",
    "for i,word_id in enumerate(important_word):\n",
    "    if word_id > 4:\n",
    "        print(word_id,feature_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 140L)\n",
      "Max 0.673850471003 34 acronym\n",
      "[ 49 127 101   7  17  74 128 121  83  98 125 124 123 106  57 107  76  96\n",
      " 109   2  23  69 136  95  20  58 132 139  55 126  84  78  80 137 116  90\n",
      " 134  75  54  19  52  18   6  25 133  16 117 102 110 103  60  53  15  87\n",
      " 108 120 122 130  86 114 105  13 135  72 100  14  48  21  61  29 118 138\n",
      "  59   3  66  85  62  63  73 115  99   0   5  64  81 131  91 129  26  88\n",
      "  92  93 104  56  82  94  67  97  89  22 119  10  51 111  79  12 112  11\n",
      "   1   8  70  71  27   4  30  28 113  32  36  68  24  65  50  35  39  77\n",
      "  40  38  31  43  33   9  46  45  42  37  47  41  44  34] [u'addit' u'alm' u'airbag' u'abort' u'acc' u'aesthet' u'alon' u'aliz' u'ag'\n",
      " u'aid' u'alloc' u'allianc' u'allerg' u'ajax' u'administr' u'al' u'affect'\n",
      " u'ah' u'alarm' u'abbrevi' u'accord' u'advis' u'ambient' u'agricultur'\n",
      " u'access' u'admiss' u'alu' u'ami' u'adm' u'alloy' u'age' u'affin'\n",
      " u'africa' u'ambigu' u'ali' u'agnat' u'alzheim' u'af' u'adjust' u'accept'\n",
      " u'adher' u'acceler' u'abnorm' u'accur' u'alus' u'academi' u'alic'\n",
      " u'aircraft' u'albi' u'airplay' u'adolesc' u'adhes' u'academ' u'agger'\n",
      " u'ala' u'aliv' u'all' u'altern' u'agent' u'algebra' u'aiv' u'abus' u'am'\n",
      " u'aero' u'air' u'ac' u'addict' u'accessori' u'adopt' u'aconin' u'alien'\n",
      " u'amc' u'admixtur' u'abc' u'advers' u'agenc' u'adp' u'adult' u'aerospac'\n",
      " u'algorithm' u'ain' u'a' u'abl' u'advanc' u'aft' u'altitud' u'agno' u'alt'\n",
      " u'accuraci' u'aggreg' u'agnost' u'agreement' u'airstrip' u'admin' u'after'\n",
      " u'agri' u'advert' u'ai' u'agil' u'accid' u'align' u'absorb' u'adhd'\n",
      " u'alert' u'afp' u'abstract' u'alga' u'absorpt' u'abandon' u'abrupt' u'aec'\n",
      " u'aerial' u'ace' u'abil' u'acoust' u'achiev' u'algal' u'acquisit'\n",
      " u'action' u'advertis' u'account' u'adventur' u'address' u'act' u'actor'\n",
      " u'affili' u'actual' u'activex' u'acq' u'ad' u'acr' u'absolut' u'adc'\n",
      " u'adapt' u'acupunctur' u'activ' u'add' u'actuat' u'ada' u'acronym']\n"
     ]
    }
   ],
   "source": [
    "#print(v)\n",
    "prob = clf.predict_proba(v)\n",
    "print(prob.shape)\n",
    "Max = 0\n",
    "for i,x in enumerate(prob[0,:]):\n",
    "    if(x > 0.0001):\n",
    "#        print(i,x)\n",
    "        if(x > Max):\n",
    "            Max = x\n",
    "            index = i\n",
    "    \n",
    "print(\"Max\",Max,index,vectorizer.get_feature_names()[index])\n",
    "for word in np.argsort(prob):\n",
    "    print(word,feature_names[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "model\n",
      "simulator\n",
      "test\n",
      "격자\n",
      "계산\n",
      "관계식\n",
      "국방\n",
      "국토\n",
      "도움\n",
      "반사량\n",
      "비교\n",
      "시뮬레이터\n",
      "재질\n",
      "판독\n"
     ]
    }
   ],
   "source": [
    "\n",
    "table = pd.DataFrame(test_dtm.toarray())\n",
    "s = pd.Series([45])\n",
    "problems = pd.DataFrame()\n",
    "f_names = pd.Series(vectorizer.get_feature_names())\n",
    "for i,v in enumerate(s):\n",
    "    problems = problems.append(table.loc[s[i], table.loc[s[i]]>0],ignore_index = True)\n",
    "vocab = problems.T\n",
    "vocab['meaning']= f_names[vocab.index]\n",
    "fn_list = f_names.tolist()\n",
    "#vocab['meaning']= vocab['meaning'].apply(lambda x: x.encode(encoding='utf-8',errors=\"ignore\"))\n",
    "vocab = vocab[vocab[0]>0.1]\n",
    "#display(vocab)\n",
    "\n",
    "for i,x in enumerate(vocab['meaning']):\n",
    "    if x in black_list:\n",
    "        #print(\"Black L found\",i,x)\n",
    "        print(x)\n",
    "\n",
    "for i,x in enumerate(vocab['meaning']):\n",
    "    if x in white_list:\n",
    "        print(\"White L found\",i,x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (\n",
    "        english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame(train_dtm.toarray())\n",
    "s = pd.Series([59,60,61,62,63,64,65])\n",
    "problems = pd.DataFrame()\n",
    "f_names = pd.Series(vectorizer.get_feature_names())\n",
    "for i in range(6):\n",
    "    problems = problems.append(table.loc[s[i], table.loc[s[i]]>0],ignore_index = True)\n",
    "vocab = problems.T\n",
    "vocab['meaning']= f_names[vocab.index]\n",
    "fn_list = f_names.tolist()\n",
    "#vocab['meaning']= vocab['meaning'].apply(lambda x: x.encode('utf-8'))\n",
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
