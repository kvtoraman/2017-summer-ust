{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of text documents using sparse features\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# Updated by: Kisti\n",
    "# Finalized by: Kamil Veli TORAMAN <kvtoraman@kaist.ac.kr>\n",
    "# 23 August 2017\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import nltk.stem\n",
    "from optparse import OptionParser\n",
    "import sys, copy\n",
    "from time import time\n",
    "from random import randint\n",
    "#import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk_per_class(clf, actual, predicted, k=5):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items per each class\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : multi list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    class_score = {}\n",
    "    micro_correct = 0.0\n",
    "    length = 0\n",
    "    global ee_correct,ee_tested\n",
    "    global cumulative_class_score\n",
    "    ee_correct = 0\n",
    "    ee_tested = 0\n",
    "    if len(actual) == len(predicted):\t\t\n",
    "\n",
    "        for\ti in range(len(actual)):\n",
    "            if actual[i] not in class_score:\n",
    "                class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "            if actual[i] not in cumulative_class_score:\n",
    "                cumulative_class_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "                \n",
    "            well_classified = False\n",
    "            for pred in predicted[i]:\n",
    "                if actual[i] in pred:\n",
    "                    #if(randint(0, 500) == 50):\n",
    "                    #\tprint(\"act: -\" , actual[i], \"-pred:\", pred,\":\")\n",
    "                    class_score[actual[i]][0] += 1.0\n",
    "                    micro_correct += 1.0\n",
    "                    well_classified = True\n",
    "            if(type(actual[i]) is list):\n",
    "                print(\"!! actual[\",i,\"] is \",actual[i])\n",
    "            if(actual[i] == CODE):\n",
    "                print(well_classified , \"docID:\",i,\"prediction of \",CODE,\" was:\",predicted[i])\n",
    "                fail_list_for_code.append(i)\n",
    "                #print(test_dtm[i].toarray()[0])\n",
    "                #for j,word_rat in enumerate(test_dtm[i].toarray()[0]):\n",
    "                #\tif(word_rat>0.2):\n",
    "                #\t\tprint(word_rat)\n",
    "            class_score[actual[i]][1] += 1.0\n",
    "            length+=1\n",
    "\n",
    "    avg_acc = 0.0\n",
    "    \n",
    "    for cl in class_score.keys():\n",
    "        avg = class_score[cl][0]/class_score[cl][1]\n",
    "        if(avg<0.6 and count[cl]-class_score[cl][1] > class_score[cl][1]):\n",
    "            print(\"!Low precision :! #Correct:\", class_score[cl][0], \"#Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "            fail_list.append(cl)\n",
    "        print (\"\\t\", cl, \"Acc.:\", avg, \"Correct:\", class_score[cl][0], \"Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "        if cl[0] =='E':\n",
    "            ee_correct += class_score[cl][0]\n",
    "            ee_tested += class_score[cl][1]\n",
    "        avg_acc +=avg\n",
    "        cumulative_class_score[cl][0] += class_score[cl][0]\n",
    "        cumulative_class_score[cl][1] += class_score[cl][1]\n",
    "        \n",
    "\n",
    "    print ('Total Test Examples', length, \"\\nMicro Acc.(item level)\", micro_correct/length)\n",
    "    print('Average of EE',ee_correct/ee_tested) \n",
    "    global cumulative_micro_avg\n",
    "    cumulative_micro_avg += micro_correct/length\n",
    "    return avg_acc/len(class_score)\n",
    "\n",
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    # Top 1 \n",
    "    pred = clf.predict(X_test)    \n",
    "    probs = clf.predict_proba(X_test)\n",
    "\n",
    "    for topk in range(5,6):\n",
    "        best_n_label = transform_label(clf, probs, topk)\n",
    "\n",
    "        test_time = time() - t0\n",
    "        print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "        pred = best_n_label\n",
    "        print (\"Top-\", topk)\n",
    "        print (\"Macro Acc.(class level)\", apk_per_class(clf, y_test, best_n_label, topk), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_label(clf, prob, topk):\n",
    "    rst_arr = np.empty( (len(prob), topk), dtype=object) \n",
    "    for i in range(len(prob)):\n",
    "        s_items = np.argsort(prob[i])[-topk:]\n",
    "\n",
    "        for j in range(len(s_items)):\n",
    "            rst_arr[i][j] = clf.classes_[s_items[j]]\n",
    "    return rst_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NSCC  dataset for categories:\n",
      "['ED10', 'ED11', 'EI02', 'EI03', 'EI06', 'EI07', 'EI05', 'EI08', 'EH06', 'EF99', 'EB01', 'EA09', 'EE11', 'EE10', 'EE13', 'EE12', 'EI99', 'EE14', 'EA04', 'EA05', 'ED07', 'ED06', 'ED05', 'ED04', 'ED03', 'ED01', 'EE99', 'ED08', 'EA02', 'EH10', 'EI11', 'EI12', 'EA14', 'EA11', 'EA10', 'EA13', 'EA07', 'EF05', 'EF06', 'ED99', 'EE08', 'EE09', 'EE06', 'EE07', 'EE04', 'EE05', 'EE02', 'EE03', 'EE01', 'SB99', 'ND07', 'OA04', 'LC06', 'SI04', 'SH07']\n",
      "Category size 55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "CODE = \"LC04\" #the CODE we observe if we debug\n",
    "categories =  [x for x in open('KSCC_sample_data_170206_Codelist.dat','r').read().split('\\n') if len(x) > 0]\n",
    "\n",
    "print(\"Loading NSCC  dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "print(\"Category size\",len(categories))\n",
    "\n",
    "#data_train = open('KSSC_sample_data_170206_Train.dat').readlines()\n",
    "#data_test = open('KSSC_sample_data_170206_Test.dat').readlines()\n",
    "data_train = open('rev_utf8_train.dat').readlines()\n",
    "#all_data = open('rev_reserved_new_data_all.dat').readlines()\n",
    "all_data = open('kkma_koreanonly_withsentencebreaker_2cols.dat').readlines()\n",
    "#data_test = open('rev_utf8_test.dat').readlines()\n",
    "data_test = open(\"rev_utf8_test.dat\").readlines()\n",
    "ENCODING = 'utf-8'\n",
    "data_train_data, data_test_data = [], []\n",
    "y_train, y_test = [], []\n",
    "all_x = []\n",
    "count = {}\n",
    "all_y = []\n",
    "\n",
    "#read all data    \n",
    "for i,line in enumerate(all_data):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        if items[0][0:2] != 'EE':\n",
    "            continue\n",
    "        items[1] = items[1].split('%%') #name + ' %% ' + kor_kywd + ' %% ' + goal + ' %% ' + abstract + ' %% ' + efct\n",
    "        occur_many_times = \"\"\n",
    "        occur_many_times += items[1][0]*1 + \" \"\n",
    "        occur_many_times += items[1][1]*1 + \" \"\n",
    "        items[1] =occur_many_times + ' '.join(items[1][2:])\n",
    "        all_x.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        #if(items[0] == CODE):\n",
    "        #    print(line)\n",
    "        all_y.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in trai n\",i,len(items))\n",
    "\"\"\"      \n",
    "for i,line in enumerate(data_train):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        data_train_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        y_train.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in train\",i,len(items))\n",
    "for i,line in enumerate(data_test):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        data_test_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        y_test.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in test\",i,len(items))\n",
    "\"\"\"\n",
    "\n",
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "guess = 80000*[\"\"]\n",
    "#divides data to train&test with 9:1 ratio\n",
    "def divide_data(rs):    \n",
    "    global data_train_data,data_test_data,y_train,y_test,guess\n",
    "    data_train_data,data_test_data,y_train,y_test = train_test_split(all_x,all_y,random_state =rs, train_size = 0.9)\n",
    "    print (len(data_train_data), len(data_test_data))\n",
    "    print('data loaded')\n",
    "    guess = 80000*[\"\"]\n",
    "    #data_train_data,data_test_data = data_test_data,data_train_data\n",
    "    #y_test,y_train=y_train,y_test\n",
    "    #data_train_data = data_test_data\n",
    "    #y_train = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vectorize training data using tfidf vectorizer\n",
    "vectorizer,X_test,X_train = 0,0,0\n",
    "def vectorize():\n",
    "    print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "    my_stop_words = [np.unicode(x.strip(), 'utf-8','ignore') for x in open('kor_stop_word.txt', 'r').read().split('\\n')]\n",
    "    global vectorizer,X_test,X_train\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 100000,\n",
    "                                 min_df=3,ngram_range=(1,1))\n",
    "    #vectorizer = StemmedTfidfVectorizer(stop_words=my_stop_words,max_df=0.5,max_features = 50000,min_df=3)    \n",
    "    X_train = vectorizer.fit_transform(data_train_data)\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "    print(\"Extracting features from the test data using the same vectorizer\")\n",
    "    X_test = vectorizer.transform(data_test_data)\n",
    "    print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "    # mapping from integer feature name to original token string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0 R_s 5\n",
      "8832 982\n",
      "data loaded\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 8832, n_features: 25473\n",
      "Extracting features from the test data using the same vectorizer\n",
      "n_samples: 982, n_features: 25473\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 4.109s\n",
      "test time:  0.014s\n",
      "Top- 5\n",
      "True docID: 22 prediction of  EE14  was: ['EE05' 'EE11' 'EE14' 'EE99' 'EE02']\n",
      "False docID: 33 prediction of  EE14  was: ['EE04' 'EE99' 'EE01' 'EE09' 'EE06']\n",
      "False docID: 104 prediction of  EE14  was: ['EE02' 'EE08' 'EE10' 'EE09' 'EE03']\n",
      "False docID: 228 prediction of  EE14  was: ['EE13' 'EE99' 'EE06' 'EE04' 'EE09']\n",
      "True docID: 263 prediction of  EE14  was: ['EE11' 'EE99' 'EE14' 'EE02' 'EE01']\n",
      "True docID: 272 prediction of  EE14  was: ['EE14' 'EE99' 'EE09' 'EE02' 'EE01']\n",
      "False docID: 281 prediction of  EE14  was: ['EE06' 'EE99' 'EE10' 'EE01' 'EE02']\n",
      "True docID: 304 prediction of  EE14  was: ['EE14' 'EE10' 'EE02' 'EE01' 'EE03']\n",
      "False docID: 525 prediction of  EE14  was: ['EE10' 'EE09' 'EE02' 'EE11' 'EE06']\n",
      "True docID: 547 prediction of  EE14  was: ['EE04' 'EE14' 'EE05' 'EE11' 'EE06']\n",
      "True docID: 556 prediction of  EE14  was: ['EE10' 'EE01' 'EE14' 'EE99' 'EE02']\n",
      "False docID: 681 prediction of  EE14  was: ['EE05' 'EE06' 'EE02' 'EE99' 'EE11']\n",
      "True docID: 822 prediction of  EE14  was: ['EE03' 'EE11' 'EE99' 'EE02' 'EE14']\n",
      "True docID: 915 prediction of  EE14  was: ['EE14' 'EE09' 'EE01' 'EE02' 'EE99']\n",
      "\t EE05 Acc.: 0.842105263158 Correct: 16.0 Tested: 19.0 #Train 241.0\n",
      "\t EE13 Acc.: 0.85 Correct: 17.0 Tested: 20.0 #Train 184.0\n",
      "\t EE99 Acc.: 0.868421052632 Correct: 66.0 Tested: 76.0 #Train 708.0\n",
      "\t EE07 Acc.: 0.9 Correct: 18.0 Tested: 20.0 #Train 227.0\n",
      "!Low precision :! #Correct: 8.0 #Tested: 14.0 #Train 115.0\n",
      "\t EE14 Acc.: 0.571428571429 Correct: 8.0 Tested: 14.0 #Train 115.0\n",
      "\t EE11 Acc.: 0.91935483871 Correct: 57.0 Tested: 62.0 #Train 578.0\n",
      "\t EE08 Acc.: 0.833333333333 Correct: 20.0 Tested: 24.0 #Train 208.0\n",
      "\t EE09 Acc.: 0.963636363636 Correct: 53.0 Tested: 55.0 #Train 506.0\n",
      "\t EE06 Acc.: 0.960526315789 Correct: 73.0 Tested: 76.0 #Train 650.0\n",
      "\t EE10 Acc.: 0.916666666667 Correct: 44.0 Tested: 48.0 #Train 439.0\n",
      "\t EE04 Acc.: 0.88 Correct: 22.0 Tested: 25.0 #Train 242.0\n",
      "\t EE12 Acc.: 0.90625 Correct: 29.0 Tested: 32.0 #Train 177.0\n",
      "\t EE02 Acc.: 0.996551724138 Correct: 289.0 Tested: 290.0 #Train 2580.0\n",
      "\t EE03 Acc.: 0.924050632911 Correct: 73.0 Tested: 79.0 #Train 671.0\n",
      "\t EE01 Acc.: 0.971830985915 Correct: 138.0 Tested: 142.0 #Train 1306.0\n",
      "Total Test Examples 982 \n",
      "Micro Acc.(item level) 0.939918533605\n",
      "Average of EE 0.939918533605\n",
      "Macro Acc.(class level) 0.886943716555 \n",
      "\n",
      "\n",
      "Trial: 1 R_s 6\n",
      "8832 982\n",
      "data loaded\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 8832, n_features: 25411\n",
      "Extracting features from the test data using the same vectorizer\n",
      "n_samples: 982, n_features: 25411\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 3.708s\n",
      "test time:  0.016s\n",
      "Top- 5\n",
      "False docID: 82 prediction of  EE14  was: ['EE04' 'EE09' 'EE06' 'EE01' 'EE02']\n",
      "True docID: 123 prediction of  EE14  was: ['EE11' 'EE99' 'EE14' 'EE01' 'EE02']\n",
      "False docID: 130 prediction of  EE14  was: ['EE04' 'EE02' 'EE10' 'EE09' 'EE06']\n",
      "True docID: 216 prediction of  EE14  was: ['EE10' 'EE99' 'EE14' 'EE02' 'EE01']\n",
      "True docID: 225 prediction of  EE14  was: ['EE05' 'EE01' 'EE99' 'EE02' 'EE14']\n",
      "True docID: 290 prediction of  EE14  was: ['EE14' 'EE10' 'EE99' 'EE01' 'EE02']\n",
      "True docID: 436 prediction of  EE14  was: ['EE99' 'EE02' 'EE14' 'EE11' 'EE06']\n",
      "True docID: 500 prediction of  EE14  was: ['EE14' 'EE04' 'EE01' 'EE09' 'EE06']\n",
      "True docID: 503 prediction of  EE14  was: ['EE10' 'EE01' 'EE99' 'EE14' 'EE02']\n",
      "False docID: 524 prediction of  EE14  was: ['EE10' 'EE07' 'EE11' 'EE01' 'EE02']\n",
      "False docID: 566 prediction of  EE14  was: ['EE04' 'EE10' 'EE02' 'EE01' 'EE03']\n",
      "False docID: 675 prediction of  EE14  was: ['EE01' 'EE02' 'EE09' 'EE04' 'EE06']\n",
      "True docID: 758 prediction of  EE14  was: ['EE14' 'EE99' 'EE09' 'EE02' 'EE01']\n",
      "False docID: 783 prediction of  EE14  was: ['EE02' 'EE10' 'EE09' 'EE11' 'EE06']\n",
      "\t EE05 Acc.: 0.952380952381 Correct: 20.0 Tested: 21.0 #Train 239.0\n",
      "\t EE99 Acc.: 0.943661971831 Correct: 67.0 Tested: 71.0 #Train 713.0\n",
      "\t EE10 Acc.: 0.866666666667 Correct: 26.0 Tested: 30.0 #Train 457.0\n",
      "!Low precision :! #Correct: 8.0 #Tested: 14.0 #Train 115.0\n",
      "\t EE14 Acc.: 0.571428571429 Correct: 8.0 Tested: 14.0 #Train 115.0\n",
      "\t EE06 Acc.: 0.934782608696 Correct: 86.0 Tested: 92.0 #Train 634.0\n",
      "\t EE04 Acc.: 0.9 Correct: 27.0 Tested: 30.0 #Train 237.0\n",
      "\t EE08 Acc.: 0.636363636364 Correct: 14.0 Tested: 22.0 #Train 210.0\n",
      "\t EE09 Acc.: 0.985294117647 Correct: 67.0 Tested: 68.0 #Train 493.0\n",
      "\t EE11 Acc.: 0.942028985507 Correct: 65.0 Tested: 69.0 #Train 571.0\n",
      "\t EE07 Acc.: 0.916666666667 Correct: 22.0 Tested: 24.0 #Train 223.0\n",
      "\t EE13 Acc.: 0.8125 Correct: 13.0 Tested: 16.0 #Train 188.0\n",
      "\t EE12 Acc.: 1.0 Correct: 16.0 Tested: 16.0 #Train 193.0\n",
      "\t EE02 Acc.: 1.0 Correct: 288.0 Tested: 288.0 #Train 2582.0\n",
      "\t EE03 Acc.: 0.985915492958 Correct: 70.0 Tested: 71.0 #Train 679.0\n",
      "\t EE01 Acc.: 0.973333333333 Correct: 146.0 Tested: 150.0 #Train 1298.0\n",
      "Total Test Examples 982 \n",
      "Micro Acc.(item level) 0.952138492872\n",
      "Average of EE 0.952138492872\n",
      "Macro Acc.(class level) 0.894734866899 \n",
      "\n",
      "\n",
      "Trial: 2 R_s 7\n",
      "8832 982\n",
      "data loaded\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 8832, n_features: 25436\n",
      "Extracting features from the test data using the same vectorizer\n",
      "n_samples: 982, n_features: 25436\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 3.754s\n",
      "test time:  0.016s\n",
      "Top- 5\n",
      "True docID: 58 prediction of  EE14  was: ['EE04' 'EE02' 'EE05' 'EE06' 'EE14']\n",
      "True docID: 181 prediction of  EE14  was: ['EE09' 'EE10' 'EE99' 'EE14' 'EE02']\n",
      "False docID: 234 prediction of  EE14  was: ['EE02' 'EE11' 'EE99' 'EE06' 'EE07']\n",
      "False docID: 243 prediction of  EE14  was: ['EE09' 'EE99' 'EE11' 'EE06' 'EE03']\n",
      "False docID: 266 prediction of  EE14  was: ['EE10' 'EE99' 'EE01' 'EE02' 'EE03']\n",
      "True docID: 347 prediction of  EE14  was: ['EE09' 'EE99' 'EE01' 'EE02' 'EE14']\n",
      "False docID: 482 prediction of  EE14  was: ['EE99' 'EE05' 'EE01' 'EE03' 'EE11']\n",
      "True docID: 539 prediction of  EE14  was: ['EE09' 'EE11' 'EE14' 'EE99' 'EE02']\n",
      "True docID: 563 prediction of  EE14  was: ['EE04' 'EE14' 'EE05' 'EE11' 'EE06']\n",
      "False docID: 632 prediction of  EE14  was: ['EE10' 'EE07' 'EE99' 'EE01' 'EE02']\n",
      "False docID: 703 prediction of  EE14  was: ['EE09' 'EE99' 'EE02' 'EE06' 'EE11']\n",
      "True docID: 719 prediction of  EE14  was: ['EE02' 'EE14' 'EE99' 'EE04' 'EE06']\n",
      "True docID: 961 prediction of  EE14  was: ['EE14' 'EE01' 'EE02' 'EE06' 'EE04']\n",
      "!Low precision :! #Correct: 7.0 #Tested: 13.0 #Train 116.0\n",
      "\t EE14 Acc.: 0.538461538462 Correct: 7.0 Tested: 13.0 #Train 116.0\n",
      "\t EE05 Acc.: 0.884615384615 Correct: 23.0 Tested: 26.0 #Train 234.0\n",
      "\t EE99 Acc.: 0.954022988506 Correct: 83.0 Tested: 87.0 #Train 697.0\n",
      "\t EE07 Acc.: 0.892857142857 Correct: 25.0 Tested: 28.0 #Train 219.0\n",
      "\t EE03 Acc.: 0.985915492958 Correct: 70.0 Tested: 71.0 #Train 679.0\n",
      "\t EE06 Acc.: 0.943661971831 Correct: 67.0 Tested: 71.0 #Train 655.0\n",
      "\t EE08 Acc.: 0.739130434783 Correct: 17.0 Tested: 23.0 #Train 209.0\n",
      "\t EE09 Acc.: 0.983050847458 Correct: 58.0 Tested: 59.0 #Train 502.0\n",
      "\t EE11 Acc.: 0.981481481481 Correct: 53.0 Tested: 54.0 #Train 586.0\n",
      "\t EE10 Acc.: 0.84 Correct: 42.0 Tested: 50.0 #Train 437.0\n",
      "\t EE13 Acc.: 0.8 Correct: 20.0 Tested: 25.0 #Train 179.0\n",
      "\t EE12 Acc.: 0.869565217391 Correct: 20.0 Tested: 23.0 #Train 186.0\n",
      "\t EE02 Acc.: 0.996527777778 Correct: 287.0 Tested: 288.0 #Train 2582.0\n",
      "\t EE04 Acc.: 0.758620689655 Correct: 22.0 Tested: 29.0 #Train 238.0\n",
      "\t EE01 Acc.: 0.992592592593 Correct: 134.0 Tested: 135.0 #Train 1313.0\n",
      "Total Test Examples 982 \n",
      "Micro Acc.(item level) 0.945010183299\n",
      "Average of EE 0.945010183299\n",
      "Macro Acc.(class level) 0.877366904024 \n",
      "\n",
      "\n",
      "EE14 3\n",
      "Cumulative 0.945689069925\n"
     ]
    }
   ],
   "source": [
    "#results = []\n",
    "# Train SGD model\n",
    "accumulated_fail_list = {}\n",
    "TRIAL_SIZE = 3\n",
    "RANDOM_STATE_START = 5\n",
    "cumulative_micro_avg = 0\n",
    "ee_correct = 0\n",
    "ee_tested = 0\n",
    "cumulative_class_score = {}\n",
    "CODE = 'EE14' #code you want to investigate, doesn't affect the result\n",
    "#try the code with different train/test splts\n",
    "for t,trial in enumerate(range(RANDOM_STATE_START,RANDOM_STATE_START + TRIAL_SIZE)):\n",
    "    print(\"Trial:\",t,\"R_s\",trial)\n",
    "    divide_data(trial)\n",
    "    vectorize()\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    feature_names = np.asarray(feature_names)\n",
    "    fail_list = []\n",
    "    fail_list_for_code = []\n",
    "    cumulative_class_score = {}\n",
    "    suggested_n_iter = np.ceil(10**6/len(data_train_data))\n",
    "    clf = SGDClassifier(loss='log', alpha=.0001, n_iter=50, penalty=\"l2\")\n",
    "    benchmark(clf)\n",
    "    for x in fail_list:\n",
    "        if not accumulated_fail_list.has_key(x):\n",
    "            accumulated_fail_list[x] = 0\n",
    "        accumulated_fail_list[x] +=1\n",
    "    #print(fail_list)\n",
    "    for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] == TRIAL_SIZE:\n",
    "            print(x,accumulated_fail_list[x])\n",
    "print('Cumulative',cumulative_micro_avg/TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this block prints the statistics(info about each category)\n",
    "statistics = open('statistics_2ndtest.txt','w')\n",
    "statistics.write('\\t'.join(['CODE','ALL','TRAIN','TEST','CORRECT','correct%'])+'\\n')\n",
    "\n",
    "for x in count:\n",
    "    a_row = [x,count[x],count[x]-cumulative_class_score[x][1],cumulative_class_score[x][1],cumulative_class_score[x][0],cumulative_class_score[x][0]/cumulative_class_score[x][1]]#code,train,tested,correct\n",
    "    for i in range(len(a_row)):\n",
    "        a_row[i] = str(a_row[i])\n",
    "    statistics.write('\\t'.join(a_row)+'\\n')\n",
    "statistics.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE14 3\n"
     ]
    }
   ],
   "source": [
    "#which categories failed most\n",
    "for x in accumulated_fail_list:\n",
    "        if accumulated_fail_list[x] >= TRIAL_SIZE -2:\n",
    "            print(x,accumulated_fail_list[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE14 [7.0, 13.0] 387\n"
     ]
    }
   ],
   "source": [
    "#which categories failed most 2\n",
    "for x in cumulative_class_score:\n",
    "    if(x[0] == \"E\"):\n",
    "        if(cumulative_class_score[x][0]/cumulative_class_score[x][1]<0.7):\n",
    "            print(x,cumulative_class_score[x],count[x]*TRIAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = file(\"features.txt\",\"w\")\n",
    "\n",
    "for x in feature_names:\n",
    "    out.write(x.encode('utf-8','ignore')+\"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the index for specific code\n",
    "#class index of EE02 is 34\n",
    "#class index of LC06 is 94\n",
    "#class index of EE99 is 47\n",
    "#class index of EA10 is 9 \n",
    "#class index of EF05 is 50 \n",
    "#\n",
    "CODE_INDEX = clf.classes_.tolist().index('EE14')\n",
    "CODE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE02\n",
      "1.2325249747 개인정보\n",
      "1.53592121446 거래\n",
      "1.58752524746 게임\n",
      "1.6019800809 고객\n",
      "1.06334322866 공유\n",
      "1.3130082847 과정\n",
      "2.09353514583 관리\n",
      "1.22406217274 관리자\n",
      "1.21006990922 교사\n",
      "1.2828301061 구매\n",
      "1.10887280068 글로벌\n",
      "2.32901317571 기능\n",
      "1.19942699853 기업\n",
      "1.16084359737 내역\n",
      "1.08898348963 다운로드\n",
      "1.11972726869 단위\n",
      "1.0697982454 대화\n",
      "1.03332397988 데이타\n",
      "1.37578268902 데이터\n",
      "1.67501780483 디드\n",
      "1.27686718126 레이션\n",
      "1.42167953134 렌더링\n",
      "1.2567196695 로그\n",
      "1.07007469048 마이그레이션\n",
      "1.49753887385 마케팅\n",
      "1.36835061126 마켓\n",
      "1.01865588702 매쉬업\n",
      "2.22634493471 모바일\n",
      "1.00687164547 모바일앱\n",
      "1.29037957728 문서\n",
      "1.53119627125 번역\n",
      "1.70143294684 보유\n",
      "1.25281211344 복합무기체계\n",
      "1.05514928308 비만\n",
      "1.02627496833 사운드\n",
      "1.3013945151 서버\n",
      "1.01473475988 성과관리\n",
      "2.34078471461 소프트\n",
      "2.42094858084 소프트웨어\n",
      "1.19211562874 스트리밍\n",
      "1.25643794474 시뮬레이션\n",
      "2.00371658427 실시간\n",
      "1.96938857832 엔진\n",
      "1.05957562027 여행\n",
      "1.63020720646 온라인\n",
      "1.00890399597 운영\n",
      "1.5303715275 운영체제\n",
      "2.61685225179 웨어\n",
      "1.75043514342 웹기반\n",
      "1.15862432564 웹서비스\n",
      "1.03616129524 위젯\n",
      "1.26197142059 융합기술고도화\n",
      "1.28375374837 음원\n",
      "1.17545248362 이미지\n",
      "1.65287924891 임베디드\n",
      "1.44318784964 임상\n",
      "1.5899759932 입력\n",
      "1.60815655063 자동\n",
      "1.20011920099 저작\n",
      "1.15560827982 전문\n",
      "1.42823581726 전문가\n",
      "1.24369278016 제공\n",
      "1.14193357222 중독\n",
      "1.20093982313 지원\n",
      "1.39468152733 처리\n",
      "1.0923718259 체감\n",
      "1.21920688043 체크\n",
      "1.09216609194 체험\n",
      "1.35345090058 추가\n",
      "1.14466174145 출력\n",
      "1.16058605689 출시\n",
      "1.32069820085 커뮤니케이션\n",
      "2.08256426083 컨텐츠\n",
      "1.26848838409 케이\n",
      "1.02065068132 콘텐츠\n",
      "1.11545247854 큐레이션\n",
      "1.41872467301 통합\n",
      "1.14350827039 티브\n",
      "1.26636411435 파일\n",
      "1.1097521462 파티\n",
      "1.32533968621 편집\n",
      "1.53278257504 프로그램\n",
      "2.27124735856 플랫폼\n",
      "1.27258664273 플리케이션\n",
      "1.04514919864 피드백\n",
      "1.76710382982 하이브리드\n",
      "1.00286009304 학생\n",
      "1.00768477222 항공\n",
      "1.38148372315 해당\n",
      "1.22184220147 확인\n",
      "1.13113226643 회원\n"
     ]
    }
   ],
   "source": [
    "#deceiving category? EE02?\n",
    "#Powerful features of EE02, the biggest category\n",
    "INDEX_BLACK = clf.classes_.tolist().index('EE02')\n",
    "black_list = []\n",
    "print(clf.classes_[INDEX_BLACK])\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(3>clf.coef_[INDEX_BLACK][i]>1):\n",
    "        print(clf.coef_[INDEX_BLACK][i],x)\n",
    "        black_list.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.06732238452 감시\n",
      "1.86155732735 개량\n",
      "3.48116191995 국방\n",
      "1.52780349699 레이더\n",
      "1.10094687134 모델\n",
      "1.92851975951 모의\n",
      "1.20963622893 무선메쉬백\n",
      "1.12248950871 방해\n",
      "1.71841679384 분석모델\n",
      "1.04816316201 비기상\n",
      "1.69777584919 성능개량\n",
      "1.20562308521 연합\n",
      "2.9658528845 전술\n",
      "1.07343715189 전투\n",
      "1.49286358724 지상\n",
      "1.11350868593 체계\n",
      "1.42480281347 통신미들웨어\n",
      "1.08714627132 특화연구센터\n",
      "1.39324437543 특화연구실\n",
      "1.08566165472 함정\n",
      "1.81951303371 합동\n"
     ]
    }
   ],
   "source": [
    "white_list = []\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(clf.coef_[CODE_INDEX][i]>1):\n",
    "        print(clf.coef_[CODE_INDEX][i],x)\n",
    "        white_list.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE14 국방 전술 전술통신 통신 기술 연구   국방 전술 전술데이터링크 데이터 링크 데이터링크 합동 완성 차기 차기위성 위성   국방 전술 전술데이터링크 데이터 링크 구축 전술통신 통신 네트워크 핵심 기술 개발 분야 이론 실무 겸비 전문 인력 양성   국방 전술 데이터 링크 인지 기반 주파수 관리 방어 설계 안전 그룹 통신 보안 전송 기술 전투 전투무선망 무선망 효과 효과적인 적인 무선 전송제어 제어 재 재밍 밍 환경 신뢰성 향상 재 재밍 극복 망 생존 유지 체계 전술데이터링크 그룹간 간 네트워크 운용 위성 지상 지상망 연동 라 라우팅 우 팅 전략 보장 데이터링크 간 협업 규칙 매칭 시스템 간섭 영향 최소화 그룹협력통신 협력 지원 전술네트워크 자원 자원관리 프로 프로토콜 토 콜 협력기반 확보 스마트   산업 기여도 국방 국방분야 분야 기대 파급 파급효과 효과 전장 전장공간 공간 정보 정보우위 우위 확보 실시간 교전 교전능력 능력 향상 핵심 핵심요소 요소 기술 육 해 공군 합동 합동작전 작전 향후 센서 무기 타격 타격체계 체계 적용 군수 군수물자 물자 수출 기여 수 해외 수입 막대 대체 취득 추후 우주 국방시대 시대 요구 통신 네트워크 기술요소 응용 국가 경쟁력 증대 이바지 가능 차세대 전술 전술데이터링크 데이터 링크 개발 한국군 무기체계 첨단 가속 민간 공공 공공분야 전자 관련 핵심기술 군수산업 부가 부가가치 가치 이동 이동통신 4 5 등 상용 원천 국제 표준화 주도 재난 경보 구조 구조체계 적용가능 상황 상황공유 공유 자원 절약 인명 인명피해 피해 최소화 데이터링크 요소기술 항공기 헬리콥터 인공 인공위성 위성 다양 기업 산업화 창출 선진국 의존도 낮춤 경제적 민간분야 기대효과 현재 미군 변경 정도 기술력 사용 원천기술료 기술료 지급 상태 독자적 이용 통해 뿐 국방연구개발비 연구 개발비 절감 부족 국방비 기초 운용 인터넷 인터넷망 망 구성 중추적 역할 담당 동시 통신기술 국가경쟁력 독자 독자적인 적인 동남아 지역 군 천문학 국가적 예상 기술인 앞 한국 주도적 기술적 성능 문제 해결 전술통신환경 환경 최적 변조 기법 단말 전송 전송성능 전술정보 교환 효율성 신\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(y_test[fail_list_for_code[0]],data_test_data[fail_list_for_code[0]])\n",
    "fail_data = []\n",
    "for x in fail_list_for_code:\n",
    "    fail_data.append(data_test_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국방 전술 전술통신 통신 기술 연구   국방 전술 전술데이터링크 데이터 링크 데이터링크 합동 완성 차기 차기위성 위성   국방 전술 전술데이터링크 데이터 링크 구축 전술통신 통신 네트워크 핵심 기술 개발 분야 이론 실무 겸비 전문 인력 양성   국방 전술 데이터 링크 인지 기반 주파수 관리 방어 설계 안전 그룹 통신 보안 전송 기술 전투 전투무선망 무선망 효과 효과적인 적인 무선 전송제어 제어 재 재밍 밍 환경 신뢰성 향상 재 재밍 극복 망 생존 유지 체계 전술데이터링크 그룹간 간 네트워크 운용 위성 지상 지상망 연동 라 라우팅 우 팅 전략 보장 데이터링크 간 협업 규칙 매칭 시스템 간섭 영향 최소화 그룹협력통신 협력 지원 전술네트워크 자원 자원관리 프로 프로토콜 토 콜 협력기반 확보 스마트   산업 기여도 국방 국방분야 분야 기대 파급 파급효과 효과 전장 전장공간 공간 정보 정보우위 우위 확보 실시간 교전 교전능력 능력 향상 핵심 핵심요소 요소 기술 육 해 공군 합동 합동작전 작전 향후 센서 무기 타격 타격체계 체계 적용 군수 군수물자 물자 수출 기여 수 해외 수입 막대 대체 취득 추후 우주 국방시대 시대 요구 통신 네트워크 기술요소 응용 국가 경쟁력 증대 이바지 가능 차세대 전술 전술데이터링크 데이터 링크 개발 한국군 무기체계 첨단 가속 민간 공공 공공분야 전자 관련 핵심기술 군수산업 부가 부가가치 가치 이동 이동통신 4 5 등 상용 원천 국제 표준화 주도 재난 경보 구조 구조체계 적용가능 상황 상황공유 공유 자원 절약 인명 인명피해 피해 최소화 데이터링크 요소기술 항공기 헬리콥터 인공 인공위성 위성 다양 기업 산업화 창출 선진국 의존도 낮춤 경제적 민간분야 기대효과 현재 미군 변경 정도 기술력 사용 원천기술료 기술료 지급 상태 독자적 이용 통해 뿐 국방연구개발비 연구 개발비 절감 부족 국방비 기초 운용 인터넷 인터넷망 망 구성 중추적 역할 담당 동시 통신기술 국가경쟁력 독자 독자적인 적인 동남아 지역 군 천문학 국가적 예상 기술인 앞 한국 주도적 기술적 성능 문제 해결 전술통신환경 환경 최적 변조 기법 단말 전송 전송성능 전술정보 교환 효율성 신\n",
      "\n",
      "한국형 군수 군수무인기 무인기 기반 전술 전술군수 융합 융합시스템 시스템 개발   실시간 실시간모니터링 모니터링 융합 군수 항공   1 1세부 세부 첨단 무인기 제작 응용 신뢰성 연구 개발 2 2세부 자율 중 무인 시스템 에이전트 기반 설계 구현 3 3세부 다 다중관 중관 네트 네트워킹 워킹 기술 4 4세부 군수 5 5세부 스마트 물류   1 1세부 세부 첨단 무인기 제작 응용 신뢰성 연구 태양광 시스템 개발 태양 태양에너지 에너지 축적 항공기 위치 자세 비행 동역학 모델링 기체 설계 파라 파라포일시스템 포일 유도 유도제어 제어 알고리즘 바람 경우 추정 기법 기법연구 최종 착지 소프트 소프트랜딩기법 랜딩 비행시험 시험 수행 비행데이터 데이터 분석 파라포일의 포 일의 가용성 종합 종합분석 센서 네트워크 기반 소프트웨어 웨어 평가 결과 향상 방안 2 2세부 자율 중 무인 에이전트 에이전트기반 구현 기능 의사 의사결정 결정 단위체 구성 기술 이용 단일 구조 국방 전력 극대화 협업 협조 중재 다중 기계 기계학습 학습 환경 환경감지 감지 싱 싱인지 인지 항행 내 션 3 3세부 다 다중관 중관 네트 네트워킹 워킹 기술개발 좌표 카메라 적외선 초음파 초음파센서 자이로 자이로센서 등 티 통신 플랫폼 전방 라이 통 적 탐색 위치정보 정보 전송 전송기술 한국형 전술 전술데이터링크 링크 지상 지상지원 지원 항공 항공관제센터 관제 센터 지휘 지휘본부 본부 간 정보연계 연계 다중관제 용 통신단말 단말 데이터링크 4 4세부 군수 물류 수요 공급 사슬 관리 통합 도입 적합 품종 품종관리 이송 물류보관 보관 모델 구축 고려 운영 스케쥴 스케쥴링 링 기기 배정 자원 유기적 주기적 추적 배분 무인전력 라 라우팅 우 팅 시 비상 상황 형   무인기 화물 화물공수 공수 민군 활용 가능성 확장 자동 자동비행 비행 제어 제어기술 기술 국산화 기존 무인 무인기의 기의 정찰 자료 자료수집 수집 개발 수준 물류 물류지원 지원 분야 감시 수색 군수 등 다양 응용 응용기술 세계 우위 선점 한국 전술 전술체계 체계 적합 네트 네트워킹 워킹 데이터 데이터링크 링크 표준화 진행 자원 자원배분 배분 스케줄 스케줄링 링 라 라우팅 우 팅 관련 관련기술 적용 확산 신규 비즈니스 모델 창출 공중 공중보급체계 보급 개선 신속성 증대 통합 모니터링 효율적 자산 자산관리역량 관리 역량 강화\n",
      "\n",
      "급 고효율 코덱 기반 제어 기술 개발   멀티미디어 통신 계층 비디오 코덱 네트워크 하드웨어 소프트 소프트웨어 웨어 통합 통합설계 설계 광대역 광대역통합망 망 시스템 분   차세대 이종 이종망 망 환경 적합 급 비디오 코덱 기반 제어 설계 요소 기술 제안 이 요소기술 이용 실감 방송 등 미래형 방송기술 핵심 발판 마련 산업 분야 신 신성장 성장 동력 수 국제 기술력 확보   고효율 비디오 압축 부 복호 기술 개발 해상도 입력 시퀀스 실시간 복 수 코덱 레이어 레이어간 간 예측 방법 호화 개선 계층 구조 이용 부복호기 복호기 속도 미디어 스트리밍 전송 연구 이종 이종망 망 환경 고려 스트림 영상 품질 제어 채널 특성 알고리즘 실감 급 획득 표현 시 공간적 생성 기법 발생 열화 제거 감 방송 다시 화질 점 영상간 간 상관관계 처리 콘텐츠 기반 비트 결정 방안 평가 네트워크 시뮬레이션 구축 이종망환경 설계 중 접속 서버 클라이언트 구현 버퍼 조절 변화   연구 차세대 이종 이종망 망 환경 미디어 전송 설계 효과적 개발 다양 단말기 비디오 서비스 사용자 제공 수 연구결과 결과 방송 화상 화상통신 통신 기반 콘텐츠 관련 방송통신 융화 디지털 기기 네트워크 융복 융복합화 합화 로 플랫폼 기술 간의 호환성 문제 중장기 광대역 광대역통합망 통합 신 신성장 성장 동 동력를 력를 촉진 사회적 비용 절감 관련업체 업체 멀티미디어 리듬 복잡 고려 효율적 통합설계 가능 추가적 해외 시장 경쟁력 확보 실제 기업 공동 공동연구 추진 실무 경험 미래 사회 필수적 제품 창조적 발상 미래형 맞춤 인력 양성 국내 연구소 진출 실감 급 저전력 시스템 생산 국가 밑거름\n",
      "\n",
      "무선 채널 복제 불가 특성 활용 완벽 완벽보안 보안 시스템 개발   물리 물리계층 계층 보안 무선 채널 양자 보안키 키 분배 복제 불가 특성   연구 대규모 다중 안테나 전송 기술 양자 암호 통신 보안 보안키 키 분배 원리 응용 무선 채널 환경 일 대 다수 프로 프로토콜 토 콜 제안 분배과정 과정 발생 가능 능동적 도청 도청행위 행위 공격 시나리오 제시 탐지 수 송수신 검출 기법 프로토 나 아가 성능 검증 수행   다중 사용자 안테나 환경 일 대 다수 보안 보안키 키 분배 기술 프로토 프로토콜 콜 제안 통신 통신환경 도청 능동적 행위 감지 판별 수 송수신 기법 감지기 설계 시스템 달성 가능 평균 생성 계산 성능 검증   연구 개발 무선 무선통신 통신 시스템 사전 보안 보안키 키 분배 필요 경우 일회성 장치 적 탈취 구조 공개 위험 방지 수 기술 정보 정보이론 이론 신호 신호처리 처리 융합 형태 물리 물리계층 계층 원천 확보 일반적 사용 범용 창의 방법 활용 예산 통신시스템 보급\n",
      "\n",
      "웹 서비스 사용자 계정 정보 관리 유출 악용 탐지 기술 개발   어카운트 접근 접근통제 통제 계정 계정유출탐지 유출 탐지 계정관리 관리 빅 빅데이터 데이터   이동식 저장 매체 등 활용 개인 계정 정보 관리 기술 개발 웹 서비스 암호화 자동 로그 로그인 인 사용자 입력 분석 유출 탐지 이용 대규모 시도 안전 안전성과 성과 효율성 보장 자동화 생성 적용 의심 통보 해커 발생 시 실제 알람 제공 추가 인증 의 도메인 국가 접속 수집 블랙 블랙리스트 리스트   소지 소지기반 기반 계정 계정정보 정보 실 접속 단말 활용 웹 웹서비스 서비스 계정관리 관리 유출 유출탐지 탐지 시스템 개발 이동식 저장 저장매체 매체 보안 일반 생 생성 성 갱신 삭제 기술 방식 자동 자동로그인 로그 인 주기적 위치 수집 식별 식별값 값 단말정보 실시간 의심 사용자 사용자행위 행위 프로 프로파일링 파일링 스코어 룰 이용 대규모 시도 도메인 국가 등 블랙 블랙리스트 리스트 시 2 2차 차 인증 수행   국내 4,000 대의 스마트 스마트폰 폰 활용 모바일 결제 등 핀 핀테크 테크 접목 시 새 시장 창출 가능 예상 개발 웹 웹서비스 서비스 인증 지속 범용 플랫폼 적용 적용시 시대 조기 유도 표준화 기술 보급 보급시 세계 개척 점유\n",
      "\n",
      "합동 합동정보모의모델 정보 모의 모델            \n",
      "\n",
      "딥 딥러닝 러닝 이용 보안 전자 전자소자 소자 탐지 시스템 개발   딥 딥러닝 러닝 신경 신경회로망 회로망 탐지 안테나 알고리즘   목표 본 연구 딥 딥러닝 러닝 인식 인식기술 기술 초고 초고주파 주파 신호 신호처리 처리 이용 초소형 반도체 전자 전자소자 소자 탐지 탐지시스템 시스템 개발 장치 세부 규격 작성 분별 시뮬레이션 후 시제품 제작 디지털 보드 알고리즘 초기 기능 구현 각 인터페이스 설계 자체 성능 성능시험 시험 함   식 알고리즘 개발 학습 패턴 인식 실험 송수신 송수신모듈 모듈 시제품 설계 검토 규격 설정 멀티 멀티채널 채널 시뮬레이션 회로 회로설계 기구 기구설계 도면 작성 제작 성능 시험 디지털 신호 신호처리부 처리 부 운용 운용프로그램 프로그램 처리부 다양 환경 간섭 요인 제거 이용 측정 안테나 설계도면 검증 도면작성 시험환경 구성 지그 구축 시험용   연구 개발 초소형 전자 전자소자 소자 탐지기 학습 지능 분류 가능 기술 적용 러 러스터링 스터링 알고리즘 이용 적응 호의 오작동 여부 판별 인식률 획기적 향상 레이더 시스템 사용 수 신호 신호처리 처리 융합 이 유사 산업 산업분류 기술발전 발전 기여 예상 제안 주파수 추정 추정방법인 방 법인 위치 방식 현재 탐지 수행 외국 크기 파악 세계 최초 진일보 능력 경쟁 제품 900 대역 국내 자유 2.4 안테나 필요 동작 원리 원리상 상 3 3고조파 고조파 지원 독창적 구조 7.4 3중대역 중대 역 광대역 판매 판매가능 영국 미국 상태 정형 보안 보안검색대 검색 대 형태 장비 때문 탐지확률 확률 효율적 독자 확보 유럽 등 국가 기술경쟁력 경쟁력 측면 우위 선점\n",
      "\n",
      "국방 융합 융합지원센터 지원 센터   아이디어 아이디어오디션 오디션 국방 융합 가치 가치창조아카데미 창조 아카데미 창조적 군사 군사혁신 혁신 전문가 군사혁신가치   1 국방 국방산업별 산업별 수요 수요기업 기업 간 실질적 융합 추진 민간 역량 역량강화 강화 지원 상시 거점 거점기관 기관 구축 운영 2 수용 간 네트워크 뮤 케이 케이선 선 확대 사업 사업연계 연계 융합사업 모델 발굴 애로 애로사항 사항 해소 등 기반 기반구축 사업추진   네트워크 구축 국방 융합 융합사업 사업 지원 기반 기반조성 조성 전문가 협의체 운영 사업수행 수행 후 전문 기술 기관 역량 구비   다수 군사 군사혁신 혁신 전문가 필요성 인식 교육 훈련 연계 군의 동기 유발 국방 융합 파급 파급효과 효과 개혁 견인 창조 발전 정체 국방걔혁 이행 이행방안 방안 전달\n",
      "\n",
      "광대역 기술 이용 분리형 기지국 장비 장비개발 개발   소프트 소프트웨어 웨어 기반 시스템 기술 아날로그 디지털 변환 기가 샘플링 신호 대역폭   국방 분야 전자전 장비 사용 중인 광대역 기술 바탕 차세대 이동 이동통신 통신 시스템 5 이동통신용 통 신용 분리형 기지국 개발   5 이동 이동통신용 통 신용 분리형 기지국 장비 전체 대역폭 1 신호 별도 협대역 직접 처리 수 신호처리 기술 필요 요구 수행 광대역 사용 저속 하드웨어 기반 복잡 비효율 장치 효율 개발 활용 요소 다음 포함 디지털 고속 병렬 신호처리리 리 위 채널 채널라이 라이 결합 모듈 모듈과의 과의 연동 시리얼 인터페이스   군수 전자전 분야 외의 레이더 시스템 고속 위성 데이터 수신기 등 광대역 신호 신호처리 처리 기술 필요 확대 적용 첨단 무기 무기체계 체계 독자 개발 능력 확보 수 있음 민수 5 무선 무선통신 통신 무선네트워크 네트워크 뿐 밀리미터 밀리미터파 파 센서 의료 의료분야 가능\n",
      "\n",
      "예제 기반 유체 애니메이션   유체 애니메이션 컴퓨터 그래픽스 예제 기반 기계 학습 물리 시뮬레이션 벡터 포 포터 터 셜 실시간 애   연구 예제 유체 정보 획득 기계 학습 분석 물리 시뮬레이션 애니메이션 재구성 실제 포착 유동 유동장 장 데이터 계산 수치 사용자 요구 유 체 스타일 선택 소스 위치 유도 경로 등 변경 동일 수준 고품질 영상 초당 30 30프레임 프레임 이상 실시간 수행 능력   연구 연구과제 과제 예제 기반 유체 애니메이션 기술 핵심 응용 심화 단계 구분 해당 개발 단순 형태 2 2차원 차원 유동 데이터 학습 뒤 소스 위치 변화 새 재구성 실험 근간 체계 수립 전체 프레임 프레임워크 워크 완성 검증 방법론 3 3차원 확장 크기 확대 축소 물리적 엄밀성 적용 등 문제 해결 활용 물체 상황 경계 조건 처리 도전 대규모 라이브러리 구축 산업 가능성   기술적 측면 물리 기반 시뮬레이션 의존 유체 애니메이션 분야 예제 활용 방법론 본격적 제안 생산성 획기적 개선 새 패러다임 산업 본 과제 연구 결과 영화 광고 모바일 플 플리케이션 리 케이 션 등 미디어 콘텐츠 내 장면 제작 특성 게임 방송 실 실시간 시간 응용 효용 고품질 영상 전체 데 일조\n",
      "\n",
      "선 최대 1 전원 통신 동시 전송 장거리 전송시스템 시스템   유선 유선통신 통신 전송 전송거리 거리 장거리 장거리통신 이더넷 파워 파워오버이더넷 오버   현재 선 전원 통신 동시 전송 통신제품 제품 작동 기술 개발 상태 활용 전원선 사용 연결 공급 수 때문 일상생활 적용 가능 우리 실질적 이유 다음 1 전압 시스템 36 57 5 12 직접적 일상적 생활 안정적 장거리 장거리전송 고전 경우 안전 위험성 한계 일반인 2 가격 회로 회로구조상 구조상 칩셋 칩셋가격 4000 4000원정도 원 정도 칩셋주변회로 주변 해당 부품 부품가격 2000 2000원 10000 10000원 전환 컨버터 5000 5000원 제조원 제조원가상 가상 소비자 판매 판매가격 제품당 당 4 5만원정도 만 부담 답 답터 터 1개 개 때 가격차이 차이 산업용 실정 3 전송거리 거리 이더넷 신호 보통 100 리피터 설치 이더넷신호 증폭 통신신호 이용 최대 400 500 이 전원공사 공사 근처 전기 추가적 문제점 최종 최종개발목표 목표 위 서술 기술적 단점 개선 자사 약점 중 하나 하나인 인 이번 이번개발 최종목표   선 하나 최대 1 전원 통신 동시 전송 저희 시스템 제품 제품구성 구성 다음 구분 인젝터 외부 이더넷 이더넷신호 신호 결합 선하나 장비 작동 외부이더넷신호 외부전력 전력 수 2 리피터 100 전송가능 가능 때문 그 증폭 필요 연결 통신신호 공급 일부 사용 기능 포함 9 9개 개 최소한 전력소비 소비 최소화 설계 핵심 3 젠더 통신제품 기반 기존 호환 회로 전환 필수적 최종 최종개발내용 개발 내용 앞 최종개발목표 목표 달성 위 바 나르크테크놀로지 효율적 설계도 구상 창업 창업과제 과제 선정 즉시 구상도 실현 마감일 내 계획   현재 산업용 기술 적용 제품 출시 중 상당 비중 차지 채택 통신 통신제품 상대적 여지 대개 건물 건물외부 외부 곳 설치 경우 안 천장 구석 등에 때문 각각 통신선과 선과 전원 전원선 선 기술적 비용 부담 동시 전송 필수적 요소 자리 범죄 범죄예방 예방 사건 사고 등 증거 증거확보 확보 효과적 감시 공공 공공기관 기관 사기업 개인 개인소비자 소비자 구분 수요 증가 추세 공급 공급업체 업체 측면 경쟁 경쟁업체 가격 구매 욕구 하나 가능 공사 공사비용 설치비용 수 시대적 선호 선호사항 사항 생각 위 사용 궁극적 목적 전원공사비용 절감 연결 편리성 100 기준 때 평균 30 30만 만 원 정도 추산 전원공사비용자체 자체 무엇 면 매력적 판단 일정 일정거리 거리 500 이상 상황 군사 군사시설 시설 무선 무선신호 신호 규제 유선 유선통신기술인 기술인 군부대 특성 광범위 지역 통제 데 직면 대부분 산악 산악지형 지형 전원공사 기존 방식 장거리 불가능 저희 시스템 2014 2014년 년 12 12월 월 국방부 요청 자사 자사기술 시연 시연발표 발표 육군 육군정보통신학교 정보 학교 실시 부작용 범죄예방효과 효과 감시효과 증거확보효과 순기능 활 활용처 용처 요즘 장거리전송시스템 행정 행정기관 기업 해외 누구 어디 시장 대항 대항마 마 장 이 개척 자사측면 매출 증대 증대효과 기대 뿐 사회적 이전 동일 수준 보안 보안효과 나 아가 개인보안 투자 경제 경제부문 부문 소비 국민 국민경제 이바지\n",
      "\n",
      "이동성 광대역 메 메쉬 쉬 통신 통신시스템 시스템 전송 기술 연구   이동 메 메쉬 쉬 통신 통신시스템 시스템 전송 기술 수학적 모델링 분산 동기화 군 군통신   이동성 메 메쉬 쉬 통신 통신시스템 시스템 국방 국방정보통신용 정보통 신용 무선망 구축 등 적합 노드 보장 경우 군함 전투기 헬리콥터 이동 함대 비행 편 편대간 대간 효율적 사용 수 있음 다양 생물체 행동 원리 관찰 기반 고안 리듬 네트워크 적용 존재 분산 동기화 처리 자원 할당 분야 문제 해결 가능 과제 광대역 전송 기술 연구 목표 이 수학적 모델링 기법 군 군통신망 통신망   1 1차년도 차 년도 이동 메 메쉬 쉬 통신 통신시스템 시스템 수학적 모델링 전송 전송기술 기술 연구 세부 내용 네트워크 모델 기법 시간 변동 연결 구조 송 수신 방식 레인 레인징 징 분산 동기 간섭 전력 전력제어 제어 보장 채널 할당 핸드 핸드오버 오버 2 2차년도 동기화 효율적 리듬 개발 이론 노드 최적 배치 점근 네트워크상의 상의 정보 교환 지연 효과 프레임 프리 프리앰 앰 설계 이동성 고려 처리 처리형 형 3 3차년도 군 군통신 등 적용 군통신망 통신망 시뮬레이터   학문적 기대 기대효과 효과 기반 이동 메 메쉬 쉬 네트워크 수학적 모델 동기화 통신 통신시스템 시스템 송 수신 기법 프레임 구조 프리 프리앰 앰 설계 레인 레인징 징 고속 분산 전력 제어 간섭 채널 할당 핸드 핸드오버 오버 개발 관련 연구 인력 양성 모델링 석 박사 전송 자원 관리 기술 군 군통신 비상 재난 통신망 양성응용 응용 분야 국방 국방정보통신용 정보통 신용 전술 전술이동통신망 전투 무선망 군함 전투기 헬리콥터 등 함대 비행 편대 무선 무선통신망 도시 철도 항만 도로 공장 학교 경찰 소방서 구축 비상재난 긴급 특수 임무 지원\n",
      "\n",
      "최저 지연 지연시간 시간 달성 차세대 전송 프로 프로토콜 토 콜 설계 연구   지연 지연시간 시간 전송 프로 프로토콜 토 콜 5 셀룰러 네트워크 차세대 인터넷 스마트 이동 이동단말 단말 이론 버퍼 로트 초실 초실시간   연구 원격 원격수술 수술 초실 초실시간 시간 교 교통제 통제 증강 증강현실 현실 클라우드 게이 게이밍 밍 등 지연 지연시간 성능 우선 차세대 고부 인터넷 응용 응용서비스 서비스 가능 최저 달성 전송 프로 프로토콜 토 콜 설계 최종 최종목표 목표 다음 포함 간 순위 균형 균형점 점 지정 제어 알고리즘 지원 네트워크 소켓 5 셀룰러 10 오더 보장 계층 구조 초고 초고속 속 1   5 셀룰러 네트워크 초고속 인터넷 지연 지연시간 시간 전송 전송율의 율의 프로 프로토콜 토 콜 관계 분석 이론 이용 간 상호 수학적 균형 조절 제어 알고리즘 구조 최저 달성 설계 전 송 반응 함수 도출 손실 최소화 허용 허용가능 가능 제어기법 기법 개발 제안 차세대 소켓 구현 간의 순위 균형점 점 임의 지정 수 리눅스 다양 모바일 운영 운영체제 체제 지원 송신단 신단 수신 각각 협력 동작 송수신 송수신단의 단의 변경 경우 한쪽 송수신단 단 효율 보완 스마트 이동 이동단말 단말 간 성능 공평 실측 테스트 테스트베드 베드 구축 서비스 별 현 비효율 입증 기존 공존 가능성   원격 원격수술 수술 초실 초실시간 시간 교통 제어 증강 증강현실 현실 등 지연 지연시간 성능 우선 차세대 고부 인터넷 서비스 가능 원천 기술 지적 지적재산권 재산권 확보 전송률 간 우선순위 순위 조절 균형 균형점 점 탐색 혁신 전송 패러다임 탈피 대량 발굴 이 동작 시연 신규 창업 시장 선도 기회 제공\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = vectorizer.transform(fail_data)\n",
    "v_array = v.toarray()\n",
    "important_word = 80000*[0]\n",
    "buffer = 80000*[0]\n",
    "for i,doc in enumerate(fail_data):\n",
    "    print(doc)\n",
    "    #print(v.toarray()[i])\n",
    "    #rev_list =  reversed(np.argsort(v.toarray()[i]))\n",
    "    for j in range(len(v_array[i])):\n",
    "        if(v_array[i][j]>0.0):\n",
    "     #       print(index,feature_names[index])\n",
    "            buffer[j] = 1\n",
    "        \n",
    "    for j in range(len(buffer)):\n",
    "        if buffer[j] > 0:\n",
    "            important_word[j] += 1\n",
    "            buffer[j] = 0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 구조\n",
      "8 구축\n",
      "5 국방\n",
      "7 네트워크\n",
      "6 다양\n",
      "5 데이터\n",
      "5 무선\n",
      "5 보안\n",
      "6 분야\n",
      "6 사용\n",
      "8 설계\n",
      "7 수행\n",
      "5 실시간\n",
      "6 응용\n",
      "8 이용\n",
      "8 적용\n",
      "7 전송\n",
      "5 제어\n",
      "6 지원\n",
      "5 채널\n",
      "6 처리\n",
      "7 통신\n",
      "7 확보\n",
      "5 환경\n",
      "5 효율적\n"
     ]
    }
   ],
   "source": [
    "#words that appear frequently in our low-quality code\n",
    "for i,word_id in enumerate(important_word):\n",
    "    if word_id > 4:\n",
    "        print(word_id,feature_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black L found 7 소프트\n",
      "소프트\n",
      "Black L found 8 소프트웨어\n",
      "소프트웨어\n"
     ]
    }
   ],
   "source": [
    "test_dtm = vectorizer.transform(data_test_data)\n",
    "train_dtm = vectorizer.transform(data_train_data)\n",
    "table = pd.DataFrame(test_dtm.toarray())\n",
    "s = pd.Series([45])\n",
    "problems = pd.DataFrame()\n",
    "f_names = pd.Series(vectorizer.get_feature_names())\n",
    "for i,v in enumerate(s):\n",
    "    problems = problems.append(table.loc[s[i], table.loc[s[i]]>0],ignore_index = True)\n",
    "vocab = problems.T\n",
    "vocab['meaning']= f_names[vocab.index]\n",
    "fn_list = f_names.tolist()\n",
    "#vocab['meaning']= vocab['meaning'].apply(lambda x: x.encode(encoding='utf-8',errors=\"ignore\"))\n",
    "vocab = vocab[vocab[0]>0.1]\n",
    "#display(vocab)\n",
    "\n",
    "for i,x in enumerate(vocab['meaning']):\n",
    "    if x in black_list:\n",
    "        print(\"Black L found\",i,x)\n",
    "        print(x)\n",
    "\n",
    "for i,x in enumerate(vocab['meaning']):\n",
    "    if x in white_list:\n",
    "        print(\"White L found\",i,x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#english stemmer, not used . It doesn't improve the accuracy\n",
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (\n",
    "        english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame(train_dtm.toarray())\n",
    "s = pd.Series([59,60,61,62,63,64,65])\n",
    "problems = pd.DataFrame()\n",
    "f_names = pd.Series(vectorizer.get_feature_names())\n",
    "for i in range(6):\n",
    "    problems = problems.append(table.loc[s[i], table.loc[s[i]]>0],ignore_index = True)\n",
    "vocab = problems.T\n",
    "vocab['meaning']= f_names[vocab.index]\n",
    "fn_list = f_names.tolist()\n",
    "#vocab['meaning']= vocab['meaning'].apply(lambda x: x.encode('utf-8'))\n",
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
