{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of text documents using sparse features\n",
    "\n",
    "This is an example showing how scikit-learn can be used to classify documents\n",
    "by topics using a bag-of-words approach. This example uses a scipy.sparse\n",
    "matrix to store the features and demonstrates various classifiers that can\n",
    "efficiently handle sparse matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import nltk.stem\n",
    "from optparse import OptionParser\n",
    "import sys, copy\n",
    "from time import time\n",
    "from random import randint\n",
    "#import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk_per_class(clf, actual, predicted, k=5):\n",
    "\t\"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items per each class\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : multi list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\t\"\"\"\n",
    "\tclass_score = {}\n",
    "\tmicro_correct = 0.0\n",
    "\tlength = 0\n",
    "    \n",
    "\tif len(actual) == len(predicted):\t\t\n",
    "\t\t\t\n",
    "\t\tfor\ti in range(len(actual)):\n",
    "\t\t\tif actual[i] not in class_score:\n",
    "\t\t\t\tclass_score[actual[i]] = [0.0, 0.0] # correct_score, length\n",
    "\t\t\twell_classified = False\n",
    "\t\t\tif(guess[i] is not \"\"):\n",
    "\t\t\t\tpredicted[i][0] = guess[i]    \n",
    "\t\t\tfor pred in predicted[i]:\n",
    "\t\t\t\tif actual[i] in pred:\n",
    "\t\t\t\t\t#if(randint(0, 500) == 50):\n",
    "\t\t\t\t\t#\tprint(\"act: -\" , actual[i], \"-pred:\", pred,\":\")\n",
    "\t\t\t\t\tclass_score[actual[i]][0] += 1.0\n",
    "\t\t\t\t\tmicro_correct += 1.0\n",
    "\t\t\t\t\twell_classified = True\n",
    "\t\t\tif(type(actual[i]) is list):\n",
    "\t\t\t\tprint(\"!! actual[\",i,\"] is \",actual[i])\n",
    "\t\t\tif(actual[i] == CODE):\n",
    "\t\t\t\tprint(well_classified , \"docID:\",i,\"prediction of \",CODE,\" was:\",predicted[i])\n",
    "\t\t\t\tfail_list.append(i)\n",
    "\t\t\t\t#print(test_dtm[i].toarray()[0])\n",
    "\t\t\t\t#for j,word_rat in enumerate(test_dtm[i].toarray()[0]):\n",
    "\t\t\t\t#\tif(word_rat>0.2):\n",
    "\t\t\t\t#\t\tprint(word_rat)\n",
    "\t\t\tclass_score[actual[i]][1] += 1.0\n",
    "\t\t\tlength+=1\n",
    "\t\t\t\t\n",
    "\tavg_acc = 0.0 \n",
    "\tfor cl in class_score.keys():\n",
    "\t\tavg = class_score[cl][0]/class_score[cl][1]\n",
    "\t\tif(avg<0.4 and count[cl]-class_score[cl][1] > class_score[cl][1]):\n",
    "\t\t\tprint(\"!Low precision :! #Correct:\", class_score[cl][0], \"#Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "\t\tprint (\"\\t\", cl, \"Acc.:\", avg, \"Correct:\", class_score[cl][0], \"Tested:\", class_score[cl][1],\"#Train\",count[cl]-class_score[cl][1])\n",
    "\t\tavg_acc +=avg\n",
    "\n",
    "\tprint ('Total Test Examples', length, \"\\nMicro Acc.(item level)\", micro_correct/length)\n",
    "\treturn avg_acc/len(class_score)\n",
    "\n",
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "\tprint('_' * 80)\n",
    "\tprint(\"Training: \")\n",
    "\tprint(clf)\n",
    "\tt0 = time()\n",
    "\tclf.fit(X_train, y_train)\n",
    "\ttrain_time = time() - t0\n",
    "\tprint(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "\tt0 = time()\n",
    "\t\n",
    "\t# Top 1 \n",
    "\tpred = clf.predict(X_test)    \n",
    "\tprobs = clf.predict_proba(X_test)\n",
    "    \n",
    "\tfor topk in range(5,6):\n",
    "\t\tbest_n_label = transform_label(clf, probs, topk)\n",
    "\t\t\n",
    "\t\ttest_time = time() - t0\n",
    "\t\tprint(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "\t\tpred = best_n_label\n",
    "\t\tprint (\"Top-\", topk)\n",
    "\t\tprint (\"Macro Acc.(class level)\", apk_per_class(clf, y_test, best_n_label, topk), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_label(clf, prob, topk):\n",
    "\tglobal target_names\n",
    "\t\n",
    "\trst_arr = np.empty( (len(prob), topk), dtype=object) \n",
    "\tfor i in range(len(prob)):\n",
    "\t\ts_items = np.argsort(prob[i])[-topk:]\n",
    "\t\t\n",
    "\t\tfor j in range(len(s_items)):\n",
    "\t\t\trst_arr[i][j] = clf.classes_[s_items[j]]\n",
    "\t\t\t\n",
    "\t\t\t\n",
    "\treturn rst_arr\n",
    "def apk(actual, predicted, k=5):\n",
    "\t\"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : multi list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\t\"\"\"\n",
    "\n",
    "\tscore = 0.0\n",
    "\tnum_hits = 0.0\n",
    "\tif len(actual) == len(predicted):\n",
    "\t\tfor\ti in range(len(actual)):\n",
    "\t\t\tfor pred in predicted[i]:\n",
    "\t\t\t\tif actual[i] in pred:\n",
    "\t\t\t\t\tscore += 1\n",
    "\n",
    "\t\t\tif not actual:\n",
    "\t\t\t\treturn 0.0\n",
    "\n",
    "\treturn score / len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NSCC  dataset for categories:\n",
      "['ED10', 'ED11', 'EI02', 'EI03', 'EI06', 'EI07', 'EI05', 'EI08', 'EH06', 'EF99', 'EB01', 'EA09', 'EE11', 'EE10', 'EE13', 'EE12', 'EI99', 'EE14', 'EA04', 'EA05', 'ED07', 'ED06', 'ED05', 'ED04', 'ED03', 'ED01', 'EE99', 'ED08', 'EA02', 'EH10', 'EI11', 'EI12', 'EA14', 'EA11', 'EA10', 'EA13', 'EA07', 'EF05', 'EF06', 'ED99', 'EE08', 'EE09', 'EE06', 'EE07', 'EE04', 'EE05', 'EE02', 'EE03', 'EE01', 'SB99', 'ND07', 'OA04', 'LC06', 'SI04', 'SH07']\n",
      "Category size 55\n",
      "운전 안전 편의 향상 운전자 시야 중심 차량 증강 현실 정보 제공 시스템 기술 개발 증강 현실 안전 운전 헤드업 디스플레이 나이트비전 장애물 인식 Head up display Night vision Object recognition Augmented reality Driving safety차량 증강 현실 정보 제공 핵심 요소 기술 개발 차량 증강 현실 정보 제공 통합 개발 증강 현실 시제품 개발 성능 검증 차량 증강 현실 실차 테스트 베드 구축 차량 증강 현실 정보 제공 서비스 프로토타입 개발 차량 증강 현실 정보 제공 표준 추진 주관 기관 한국전자통신연구원 차량 증강 현실 정보 제공 통합 개발 테스트 베드 구축 참여 기관 경북대학교 산학 협력단 실세계 정보 실시간 인식 추적 기술 개발 참여 기관 자동차 부품 연구원 운전자 인지 향상 증강 현실 처리 기술 개발 참여 기관 현대오 트론 증강 현실 시제품 제어 개발 실용 방안 도출 참여 기관 현대엠엔소프트 고정밀 차원 디지털 맵 내비게이션 연동 기술 개발 참여 기관 네이버시스템 운전자 뷰 증강 현실 정보 정합 기술 개발 참여 기관 웨이브엠 차량 증강 현실 정보 제공 통합 개발 참여 기관 코어벨 운전자 헤드 시야 추출 기술 개발 참여 기관 오빛 증강 현실 시제품 개발 차량 증강 현실 정보 제공 핵심 요소 기술 개발 차량 증강 현실 정보 제공 통합 개발 증강 현실 시제품 개발 성능 검증 차량 증강 현실 실차 테스트 베드 구축 차량 증강 현실 정보 제공 서비스 프로토타입 개발 차량 증강 현실 정보 제공 표준 추진 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "CODE = \"LC04\"\n",
    "categories =  [x for x in open('KSCC_sample_data_170206_Codelist.dat','r').read().split('\\n') if len(x) > 0]\n",
    "\t\n",
    "remove = ()\n",
    "\n",
    "print(\"Loading NSCC  dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "print(\"Category size\",len(categories))\n",
    "\t\n",
    "#data_train = open('KSSC_sample_data_170206_Train.dat').readlines()\n",
    "#data_test = open('KSSC_sample_data_170206_Test.dat').readlines()\n",
    "data_train = open('KSSC_sample_data_170206_Train.dat').readlines()\n",
    "#all_data = open('rev_reserved_new_data_all.dat').readlines()\n",
    "all_data = open('rev_kkma_data_all_3cols.dat').readlines()\n",
    "#data_test = open('rev_utf8_test.dat').readlines()\n",
    "data_test = open(\"KSSC_sample_data_170206_Test.dat\").readlines()\n",
    "ENCODING = 'euc-kr'\n",
    "data_train_data, data_test_data = [], []\n",
    "y_train, y_test = [], []\n",
    "all_x = []\n",
    "count = {}\n",
    "all_y = []\n",
    "for cat in categories:\n",
    "    count[cat] = 0\n",
    "    \"\"\"\n",
    "for i,line in enumerate(all_data):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        all_x.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        #if(items[0] == CODE):\n",
    "        #    print(line)\n",
    "        all_y.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in train\",i,len(items))\n",
    "    \"\"\"      \n",
    "for i,line in enumerate(data_train):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        data_train_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        if(i == 0):\n",
    "            print(items[1].decode(ENCODING, 'ignore'))\n",
    "        y_train.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in train\",i,len(items))\n",
    "for i,line in enumerate(data_test):\n",
    "    items = line.split('\\t')\n",
    "    if len(items) == 2:\n",
    "        data_test_data.append(items[1].decode(ENCODING, 'ignore'))\n",
    "        y_test.append(items[0])\n",
    "        if not count.has_key(items[0]):\n",
    "            count[items[0]] = 0\n",
    "        count[items[0]] += 1\n",
    "    else:\n",
    "        print(\"ERROR in test\",i,len(items))\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7106 4856\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "#data_train_data,data_test_data,y_train,y_test = train_test_split(all_x,all_y,random_state =1, train_size = 0.65)\n",
    "print (len(data_train_data), len(data_test_data))\n",
    "print('data loaded')\n",
    "guess = 80000*[\"\"]\n",
    "#data_train_data,data_test_data = data_test_data,data_train_data\n",
    "#y_test,y_train=y_train,y_test\n",
    "#data_train_data = data_test_data\n",
    "#y_train = y_test\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "for i,line in enumerate(data_test_data):\n",
    "    if(u'선박' in line and u'해양' in line):\n",
    "        #print(\"Obvious: EA10\",y_test[i])\n",
    "        #guess[i] = \"EA10\"\n",
    "        pass\n",
    "    if(u'power' in line and u'에너지' in line):\n",
    "        #print(\"Obvious:\",CODE,y_test[i])\n",
    "        #guess[i] = \"EF05\"\n",
    "        pass\n",
    "    #if(u'데이터' in line and u'임상' in line and u'적용' in line and  u'측정' in line):\n",
    "        #print(\"Obvious:\",CODE,y_test[i])\n",
    "        #guess[i] = \"LC04\"\n",
    "target_names = categories #data_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "n_samples: 7106, n_features: 15254\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "n_samples: 4856, n_features: 15254\n"
     ]
    }
   ],
   "source": [
    "# Add Word Embedding (Word Embedding, Topic Embedding, Topic-Event Embedding) Features\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "my_stop_words = [np.unicode(x.strip(), 'utf-8','ignore') for x in open('kor_stop_word.txt', 'r').read().split('\\n')]\n",
    "\n",
    "\n",
    "#print (my_stop_words)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5,stop_words=my_stop_words,max_features = 100000,\n",
    "                             min_df=3)\n",
    "#vectorizer = StemmedTfidfVectorizer(stop_words=my_stop_words,max_df=0.5,max_features = 50000,min_df=3)    \n",
    "X_train = vectorizer.fit_transform(data_train_data)\n",
    "\n",
    "duration = time() - t0\n",
    "\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test_data)\n",
    "duration = time() - t0\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "# mapping from integer feature name to original token string\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "feature_names = np.asarray(feature_names)\n",
    "#test_dtm = vectorizer.transform(data_test_data)\n",
    "#train_dtm = vectorizer.transform(data_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 9.181s\n",
      "test time:  0.102s\n",
      "Top- 5\n",
      "!Low precision :! #Correct: 0.0 #Tested: 14.0 #Train 17.0\n",
      "\t ED10 Acc.: 0.0 Correct: 0.0 Tested: 14.0 #Train 17.0\n",
      "\t ED11 Acc.: 0.548387096774 Correct: 17.0 Tested: 31.0 #Train 42.0\n",
      "!Low precision :! #Correct: 0.0 #Tested: 6.0 #Train 7.0\n",
      "\t EI02 Acc.: 0.0 Correct: 0.0 Tested: 6.0 #Train 7.0\n",
      "!Low precision :! #Correct: 3.0 #Tested: 8.0 #Train 9.0\n",
      "\t EI03 Acc.: 0.375 Correct: 3.0 Tested: 8.0 #Train 9.0\n",
      "\t EI06 Acc.: 0.777777777778 Correct: 7.0 Tested: 9.0 #Train 9.0\n",
      "\t EI07 Acc.: 0.166666666667 Correct: 1.0 Tested: 6.0 #Train 5.0\n",
      "\t EI05 Acc.: 0.526315789474 Correct: 10.0 Tested: 19.0 #Train 24.0\n",
      "!Low precision :! #Correct: 1.0 #Tested: 9.0 #Train 10.0\n",
      "\t EI08 Acc.: 0.111111111111 Correct: 1.0 Tested: 9.0 #Train 10.0\n",
      "\t EH06 Acc.: 0.428571428571 Correct: 3.0 Tested: 7.0 #Train 7.0\n",
      "\t EB01 Acc.: 0.0 Correct: 0.0 Tested: 5.0 #Train 5.0\n",
      "\t EA09 Acc.: 0.705882352941 Correct: 12.0 Tested: 17.0 #Train 23.0\n",
      "\t EE11 Acc.: 0.921708185053 Correct: 259.0 Tested: 281.0 #Train 418.0\n",
      "\t EE10 Acc.: 0.834101382488 Correct: 181.0 Tested: 217.0 #Train 323.0\n",
      "\t EE13 Acc.: 0.869158878505 Correct: 93.0 Tested: 107.0 #Train 158.0\n",
      "\t EE12 Acc.: 0.884210526316 Correct: 84.0 Tested: 95.0 #Train 139.0\n",
      "\t EI99 Acc.: 0.571428571429 Correct: 4.0 Tested: 7.0 #Train 6.0\n",
      "\t EE14 Acc.: 0.488888888889 Correct: 22.0 Tested: 45.0 #Train 63.0\n",
      "\t EA04 Acc.: 0.0 Correct: 0.0 Tested: 6.0 #Train 5.0\n",
      "\t EA05 Acc.: 0.742857142857 Correct: 26.0 Tested: 35.0 #Train 48.0\n",
      "!Low precision :! #Correct: 0.0 #Tested: 15.0 #Train 20.0\n",
      "\t ED07 Acc.: 0.0 Correct: 0.0 Tested: 15.0 #Train 20.0\n",
      "!Low precision :! #Correct: 6.0 #Tested: 21.0 #Train 29.0\n",
      "\t ED06 Acc.: 0.285714285714 Correct: 6.0 Tested: 21.0 #Train 29.0\n",
      "!Low precision :! #Correct: 4.0 #Tested: 31.0 #Train 42.0\n",
      "\t ED05 Acc.: 0.129032258065 Correct: 4.0 Tested: 31.0 #Train 42.0\n",
      "\t ED04 Acc.: 0.723076923077 Correct: 47.0 Tested: 65.0 #Train 93.0\n",
      "!Low precision :! #Correct: 0.0 #Tested: 8.0 #Train 9.0\n",
      "\t ED03 Acc.: 0.0 Correct: 0.0 Tested: 8.0 #Train 9.0\n",
      "\t ED01 Acc.: 0.521739130435 Correct: 12.0 Tested: 23.0 #Train 31.0\n",
      "\t EE99 Acc.: 0.951612903226 Correct: 295.0 Tested: 310.0 #Train 461.0\n",
      "\t ED08 Acc.: 0.660377358491 Correct: 35.0 Tested: 53.0 #Train 77.0\n",
      "\t EA02 Acc.: 0.5 Correct: 6.0 Tested: 12.0 #Train 15.0\n",
      "\t EH10 Acc.: 0.777777777778 Correct: 7.0 Tested: 9.0 #Train 11.0\n",
      "\t EF99 Acc.: 0.0 Correct: 0.0 Tested: 8.0 #Train 8.0\n",
      "\t EI11 Acc.: 0.5625 Correct: 9.0 Tested: 16.0 #Train 20.0\n",
      "\t EI12 Acc.: 0.0 Correct: 0.0 Tested: 7.0 #Train 7.0\n",
      "\t EA14 Acc.: 0.0 Correct: 0.0 Tested: 9.0 #Train 9.0\n",
      "\t EA11 Acc.: 0.222222222222 Correct: 2.0 Tested: 9.0 #Train 9.0\n",
      "!Low precision :! #Correct: 2.0 #Tested: 15.0 #Train 17.0\n",
      "\t EA10 Acc.: 0.133333333333 Correct: 2.0 Tested: 15.0 #Train 17.0\n",
      "\t EA13 Acc.: 0.0 Correct: 0.0 Tested: 7.0 #Train 6.0\n",
      "!Low precision :! #Correct: 0.0 #Tested: 8.0 #Train 9.0\n",
      "\t EA07 Acc.: 0.0 Correct: 0.0 Tested: 8.0 #Train 9.0\n",
      "!Low precision :! #Correct: 5.0 #Tested: 21.0 #Train 29.0\n",
      "\t EF05 Acc.: 0.238095238095 Correct: 5.0 Tested: 21.0 #Train 29.0\n",
      "!Low precision :! #Correct: 0.0 #Tested: 9.0 #Train 11.0\n",
      "\t EF06 Acc.: 0.0 Correct: 0.0 Tested: 9.0 #Train 11.0\n",
      "!Low precision :! #Correct: 4.0 #Tested: 32.0 #Train 44.0\n",
      "\t ED99 Acc.: 0.125 Correct: 4.0 Tested: 32.0 #Train 44.0\n",
      "\t EE08 Acc.: 0.769911504425 Correct: 87.0 Tested: 113.0 #Train 165.0\n",
      "\t EE09 Acc.: 0.95983935743 Correct: 239.0 Tested: 249.0 #Train 370.0\n",
      "\t EE06 Acc.: 0.928571428571 Correct: 299.0 Tested: 322.0 #Train 479.0\n",
      "\t EE07 Acc.: 0.875 Correct: 98.0 Tested: 112.0 #Train 164.0\n",
      "\t EE04 Acc.: 0.864 Correct: 108.0 Tested: 125.0 #Train 183.0\n",
      "\t EE05 Acc.: 0.834862385321 Correct: 91.0 Tested: 109.0 #Train 159.0\n",
      "\t EE02 Acc.: 0.999178307313 Correct: 1216.0 Tested: 1217.0 #Train 1822.0\n",
      "\t EE03 Acc.: 0.960244648318 Correct: 314.0 Tested: 327.0 #Train 488.0\n",
      "\t EE01 Acc.: 0.983582089552 Correct: 659.0 Tested: 670.0 #Train 1001.0\n",
      "Total Test Examples 4856 \n",
      "Micro Acc.(item level) 0.878912685338\n",
      "Macro Acc.(class level) 0.468525243882 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#results = []\n",
    "# Train SGD model\n",
    "fail_list = []\n",
    "suggested_n_iter = np.ceil(10**6/len(data_train_data))\n",
    "clf = SGDClassifier(loss='log', alpha=.0001, n_iter=50, penalty=\"l2\")\n",
    "benchmark(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = file(\"features.txt\",\"w\")\n",
    "\n",
    "for x in feature_names:\n",
    "    out.write(x.encode('utf-8','ignore')+\"\\n\")\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class index of EE02 is 34\n",
    "#class index of LC06 is 94\n",
    "#class index of EE99 is 47\n",
    "#class index of EA10 is 9 \n",
    "#class index of EF05 is 50 \n",
    "#\n",
    "CODE_INDEX = clf.classes_.tolist().index('EE14')\n",
    "CODE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EE02\n",
      "1.53800387477 3d\n",
      "1.63228134361 analysi\n",
      "1.70881888026 cloud\n",
      "1.52782369874 data\n",
      "1.31686778922 learn\n",
      "1.23723081528 manag\n",
      "1.2987756951 market\n",
      "1.26135604594 mobil\n",
      "1.78876945712 platform\n",
      "1.7069120214 softwar\n",
      "2.00206514621 sw\n",
      "1.26679179568 web\n",
      "1.58100307866 개발자\n",
      "1.76401415654 고객\n",
      "1.4221152699 공유\n",
      "1.33577778595 과정\n",
      "2.04288484033 관리\n",
      "1.435774204 관리자\n",
      "1.34185970961 구매\n",
      "1.76651210379 기능\n",
      "1.21183394259 내역\n",
      "1.36073905463 데이터\n",
      "1.50577911949 디드\n",
      "1.37907259094 마케팅\n",
      "1.79116460966 모바일\n",
      "1.36236947874 문서\n",
      "1.41723440859 보유\n",
      "1.47796186426 비용\n",
      "2.42864122576 소프트\n",
      "2.44022018702 소프트웨어\n",
      "2.34722952153 솔루션\n",
      "1.22888352847 실시간\n",
      "1.95531655258 엔진\n",
      "1.30565146131 오픈\n",
      "1.34030017058 온라인\n",
      "1.36857061292 운영체제\n",
      "2.19949840272 웨어\n",
      "1.20756084026 유저\n",
      "1.42051339564 융합기술고도화\n",
      "1.27463307125 이미지\n",
      "1.50058178073 임베디드\n",
      "1.43362201748 입력\n",
      "1.39416773254 자동\n",
      "1.4067433942 전문\n",
      "1.46837666544 전문가\n",
      "1.64888012043 지원\n",
      "1.45743705306 체크\n",
      "1.78531145051 추가\n",
      "1.46590194919 출시\n",
      "1.70585892825 컨텐츠\n",
      "1.51502761312 프로그램\n",
      "1.89084775999 플랫폼\n"
     ]
    }
   ],
   "source": [
    "#deceiving category? EE02?\n",
    "#Powerful features of EE02, the biggest category\n",
    "black_list = []\n",
    "print(clf.classes_[CODE_INDEX])\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(3>clf.coef_[CODE_INDEX][i]>1):\n",
    "        print(clf.coef_[CODE_INDEX][i],x)\n",
    "        black_list.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6364365261 film\n",
      "2.59125747492 health\n",
      "2.63322161012 medic\n",
      "2.67100666961 심장\n",
      "2.79196081601 의료\n",
      "3.61525651388 의료기기\n"
     ]
    }
   ],
   "source": [
    "white_list = []\n",
    "for i,x in enumerate(vectorizer.get_feature_names()):\n",
    "    if(clf.coef_[CODE_INDEX][i]>2):\n",
    "        print(clf.coef_[CODE_INDEX][i],x)\n",
    "        white_list.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LC04  센서 센서배열 배열 모바일 기기 기반 탄성 도플러 영상 영상진단기 진단기 개발\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(y_test[fail_list[0]],data_test_data[fail_list[0]])\n",
    "fail_data = []\n",
    "for x in fail_list:\n",
    "    fail_data.append(data_test_data[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 센서 센서배열 배열 모바일 기기 기반 탄성 도플러 영상 영상진단기 진단기 개발\n",
      "\n",
      "machine learning , deep learning , artificial intelligence , fund us , diabetic ret in opa thy , age related mac u lar degeneration , glaucoma , retinal vein occlusion , retinal artery occlusion 딥 딥러닝 러닝 기술 이용 안저 안저사진 사진 판독 원천 원천기술 확보 응용 머신 머신러닝 인공 인공지능 지능 당뇨 당뇨망막병증 망막 병증 노인 노인성황반변성 성황반 변성 녹내장 망막정맥폐쇄 정맥 폐쇄 망막동맥폐쇄 동맥 한국인 평균 평균수명 수명 증가 의학 의학연구 연구 방향 단순 연장 사회 전체 삶 질 보정 목표 시력 중요 요소 수의 사람 나이 나이관련황반 관련 황 반 등 저하 실명 유발 수 중대 질환 이환 이 로 손상 방법 정기적 검진 조기 진단 최근 보급 무산 무산동안 동안 사진촬영장비 촬영 장비 주요 안과 안과질환 민감도 숙련 안과의사 의사 진료 필요 이미지 분야 인식 기계 기계학습 학습 중 발전 의료 의료분야 적용 노력 시도 최고 최고수준 수준 임상 임상의사 상기 나 아가 이 바탕 질병 예측 예후 평가 시스템 구축 초석 세계적 수준의 환자 임상정보 정보 이브 정확 데이터 데이터베이스 베이스 후 개입 최소화 의미 알고리즘 개발 정상 정상안저 등 시작 다양 개별 망막질환 예 망막혈관폐쇄 혈관 유전성 유전성망막질환 의 자동화 모델 뿐 성능 시험용 상용 가능성 타진 기반 마련 현재 개인적 경험 역량 좌우 영역 양의 정량화 근거 이 정량적 측정 데 본 실제 일치 검정 성능개선 개선 고도화 각광 근래 의료영역 잠재력 기대 초기 단계 임상환자정보 연구진 실정 과제 자동 자동판독 기술적 돌파구 돌파구임 임 입증 경우 파급 향후 진행 뇌혈류 뇌혈류장애 장애 검출 개별적 연구가 보고 자체 어려움 연구자 연구자간의 간의 편차 동반 전신 전신질환 추정 뇌혈관 발생 산업 관심 투자 때 지금 연구과제 첨단 의료혁신 혁신 이정표\n",
      "\n",
      "continual blood pressure measurement , non kort ok off method , to no meter , usual blood pressure measurement , blood pressure measurement algorithm , hypertension 연속적 혈압 측정 가능 맥 맥파 파 분석 알고리즘 연구 연속 연속혈압측정 압박 혈압측정 혈압계 상시 상시혈압측정 고혈압 본 기존 적용 기반 방법 한계 해결 방식 제시 일반적  2 4 2 4 시간 시간 필요 당뇨병 환자 임산부 위험 대상자 고도 안전 시스템 구현 수 새 도출 데 목표 오실로 오실로메트릭방식 메트릭 문제점 문제점인 인 불가능 문제 방법론 유효성 검증 과정 주요 내용 기본적 혈관 혈류 때문 무리 압력 건강 성인  5 5 회 회 이상 권장 위험군 군 경우 자체 사람 포함 모든 상용 실제적 기술 활용 혈류을 을 임상 실험 성능 차원 정밀 데이터 주 이론 정립 설계 사용 피드백 피드백과정  1 1 년차 년 차 센서 마이크로 마이크로프로세서 프로세서 컴퓨터 이용 입증  2 2 년차 이 제안 실질적 실용 최종적 최상 최상위 위 권위 저널 출간 적합 논문 국내 국제 특허 특허을 결과 공학 관점 의료 기기 분야 변혁 중증 진단 치료 동시 시장 대체 신 신기술 확보 이제 후발 주자 우리 우리나라 나라 해외 선진 의료기기 업체 국가 경쟁력 우위\n",
      "\n",
      "physical activity monitoring , energy consumption , child and youth , acc el ero meter , obesity management 아동 청소년 비만 비만관리 관리 신체 신체활동 활동 측정 측정기반 기반 스마트 칼로리 트래킹 기술 개발 에너지 소비량 아동청소년 가속도 센서 예방 특화 알고리즘 실시간 제공 가능 활동량 제시 한국형 표준 목록 목록표 표 니스 활동데이터 데이터 패턴 활용 서비스 프로세스 개선 개선연구 연구 가능성 검토 시범 시범적용 적용 준비 상용 실현 기술이전 이전 유형 운동량 이로 인 계산 편리 수 동 임 임상 상 실험 수집 검증 연구결과물의 결과 물의 제고  1 1 차년 차년 국민 국민대 대 위탁 위탁수행 수행 기초 자료 문헌 문헌조사 조사 리스트 리스트업 업 분석 청소년단체 단체 연계 인증 인증프로그램 프로그램 학원 교육 장려 도구 최초 의미 야외 활성화 증가 유치원 학교의 체육 체육활동 시간 중장기 건강 증진 효과 흥미 흥미요소 요소 결합 컨텐츠 보상 보상체계 체계 유도 컴퓨터 게임 비디오 등 움직임 기존 활동적 요건 추가 몸 자연 운동 운동효과 기대 가미 제품 예 영역 장점 있음 다양 신 신시장 시장 창출 놀이 형성 스토리 개발시 시 저작권 등록 제작 기업 수익 발생\n",
      "\n",
      " 센서 센서배열 배열 모바일 기기 기반 탄성 도플러 영상 영상진단기 진단기 개발\n",
      "\n",
      "depth of anesthesia , signal processing , brain engineering , anesthesia , bio signals 차세대 마취 심도 측정 기술 개발 마취심도 신호 신호처리 처리 뇌 뇌공학 공학 생체 생체신호 임 임상의 상의 이공계 분야 협력 융합 연구 인체 반응 원천 수행 바탕 정확 반응성 중 각성 수술 후 심각 후유증 가능성 장비 사용 유지 현 문제점 개선 과학 발전 기전 패러다임 변화 속 측정진단 진단 원천기술 알고리즘 과정 부분 평가 적합 판별 뇌파 두뇌 표피 전체 구조 모델링 기법 위 연산 연산량 량 수 포함 주변 잡음 제거 임상 심의 융 융복합 복합 연구분야 의료 의료기술 중심 뇌파신호 분석 의식 해석 등 분야등 마취기전 부정확 새 전신 흡입 흡입마취 환자 상태 못 대부분 추종 측면 접근 근본 근본적인 적인 필 기존 해결 필요 테스트 안전성 확보 신뢰성 현재 극복 한국형 감지 관련 획 신 신성장동력 성장 동력 성장잠재력 잠재력 확충 확충마취 상관관계 부위 세계적 핵심 국내 산업 확대 기대 기대정확도 정확도 건강 서비스 질적 요소 긍정적 영향 영향마취심도 모니터 기술적 부가 부가가치 가치 제품 의료진 양측 모두 활용 때문 시장성 지속적 증대 예상 예상마취 특성 기초 기초기술 가능 가능교육 교육 복지 니스 엔터테인먼트 응용 응용가능뇌파 신호감지 뇌건강 핵심기술 다양 시작 있음\n",
      "\n",
      "bio sensor , electrode material , solid electrolyte , wireless communication , ultra low power , infected wound , ph sensor 바이오 바이오센서 센서 활용 감염 감염창상 창상 모니터링 시스템 개발 전극 전극물질 물질 고체 고체전해질 전해질 무선 무선통신 통신 저전력 창 창상의 상의 응용 기술 감지 송수신  1 1 차년도 차 년도 반응 이종 설계 전달 아날로그 회로  2 2 차년도 적용 가능 시트 안정적 성능 구현 고도화  3 3 차년도 특성 평가 헬스 헬스케어 케어 플랫폼 지원 측정 측정데이터 데이터 베이스  4 4 차년도 사업 무선통신기반 기반 시제품 제작 무선통신시스템 성능평가  5 5 차년도 응답 분석 안정성 향상 최적화 인증 창상부위 부위 염증 염증발생 발생 징후 변화 수 융복 패치 상태 교체 주기 효율적 예측 창상패 상패 남용 치료 효과 효과적임 적임 기능 부가 부가가치 가치 제품 국가 국가경쟁력 경쟁력\n",
      "\n",
      "dr m , healthcare . i ot . sensor 닥터 테스트 테스트베드 베드 시연 시나리오 개선 아이템 아이템간 간 연동 방안 연구 구성 구축 보완 시 개선방안 검토 기능 서비스 전시 요구 요구사항 사항 정립 추가 선정 개별 인터페이스 시스템 개발 시스템간의 간의 어뎁 어뎁터 터 외 기술적 활용 확장 가능성\n",
      "\n",
      "dv enc , heart flow quant if ica it on , d printer , computational flow dynamics , cardiac function 4 자기 공명 공명유속영상 유속 영상 이용 심혈관 질환 유동 규명 이 진단 치료 치료반응예측 반응 예측 연구 3 프린터 환자 특이 팬 팬텀 텀 전산 전산유체역학 유체 역학 임상 임상영상 코호트 검증 심장 심장유동 정량화 전산유체해석 해석 심장기능 기능 의학적 중요 혈류 1 2 이 분석 개발 - 4 데이터 입출력 모듈 시각화 혈류지표 지표 계산 전용 전용프로그램 프로그램 다양 정량적 인자 추출 통 효율적 임상적용 적용 프로 프로토콜 토 콜 최적화 분석결과 결과 해석결과 비교 혈류측정장치 측정 장치 텀실험 실험 간의 분 분석 석 예후 소프트 소프트웨어 웨어 평가 평가지표 우월성 증명 심장판막환자 판막 대동맥 대동맥질환 심근 심근증 증 레지스 레지스트리 트리 구축 형태 정보 혈액 혈액유동팬텀 제작 재질 등 고려 특화 혈류유동 혈류측정기 측정기 기본 기본검증 경 경피 피 치환 치환술 술 엽 엽성 성 기계 기계판막하 판 막하 조직 조직증식 증식 후성 심근증환자 대상 임상연구 바탕 피드백 기존 방법 심장혈류유동 한계 나 심장혈류 사차원 전임 기초 기초연구 토대 마련 향후 예상 영역 선도 선도적인 적인 역할 반영 수 새 경 경피 심근증환자등 환자군 군 데 기준 사용 분야 현재 수준 단계 발전\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = vectorizer.transform(fail_data)\n",
    "v_array = v.toarray()\n",
    "important_word = 80000*[0]\n",
    "buffer = 80000*[0]\n",
    "for i,doc in enumerate(fail_data):\n",
    "    print(doc)\n",
    "    #print(v.toarray()[i])\n",
    "    #rev_list =  reversed(np.argsort(v.toarray()[i]))\n",
    "    for j in range(len(v_array[i])):\n",
    "        if(v_array[i][j]>0.0):\n",
    "     #       print(index,feature_names[index])\n",
    "            buffer[j] = 1\n",
    "        \n",
    "    for j in range(len(buffer)):\n",
    "        if buffer[j] > 0:\n",
    "            important_word[j] += 1\n",
    "            buffer[j] = 0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 데이터\n",
      "5 센서\n",
      "5 임상\n",
      "5 적용\n",
      "6 측정\n"
     ]
    }
   ],
   "source": [
    "for i,word_id in enumerate(important_word):\n",
    "    if word_id > 4:\n",
    "        print(word_id,feature_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 140L)\n",
      "Max 0.673850471003 34 acronym\n",
      "[ 49 127 101   7  17  74 128 121  83  98 125 124 123 106  57 107  76  96\n",
      " 109   2  23  69 136  95  20  58 132 139  55 126  84  78  80 137 116  90\n",
      " 134  75  54  19  52  18   6  25 133  16 117 102 110 103  60  53  15  87\n",
      " 108 120 122 130  86 114 105  13 135  72 100  14  48  21  61  29 118 138\n",
      "  59   3  66  85  62  63  73 115  99   0   5  64  81 131  91 129  26  88\n",
      "  92  93 104  56  82  94  67  97  89  22 119  10  51 111  79  12 112  11\n",
      "   1   8  70  71  27   4  30  28 113  32  36  68  24  65  50  35  39  77\n",
      "  40  38  31  43  33   9  46  45  42  37  47  41  44  34] [u'addit' u'alm' u'airbag' u'abort' u'acc' u'aesthet' u'alon' u'aliz' u'ag'\n",
      " u'aid' u'alloc' u'allianc' u'allerg' u'ajax' u'administr' u'al' u'affect'\n",
      " u'ah' u'alarm' u'abbrevi' u'accord' u'advis' u'ambient' u'agricultur'\n",
      " u'access' u'admiss' u'alu' u'ami' u'adm' u'alloy' u'age' u'affin'\n",
      " u'africa' u'ambigu' u'ali' u'agnat' u'alzheim' u'af' u'adjust' u'accept'\n",
      " u'adher' u'acceler' u'abnorm' u'accur' u'alus' u'academi' u'alic'\n",
      " u'aircraft' u'albi' u'airplay' u'adolesc' u'adhes' u'academ' u'agger'\n",
      " u'ala' u'aliv' u'all' u'altern' u'agent' u'algebra' u'aiv' u'abus' u'am'\n",
      " u'aero' u'air' u'ac' u'addict' u'accessori' u'adopt' u'aconin' u'alien'\n",
      " u'amc' u'admixtur' u'abc' u'advers' u'agenc' u'adp' u'adult' u'aerospac'\n",
      " u'algorithm' u'ain' u'a' u'abl' u'advanc' u'aft' u'altitud' u'agno' u'alt'\n",
      " u'accuraci' u'aggreg' u'agnost' u'agreement' u'airstrip' u'admin' u'after'\n",
      " u'agri' u'advert' u'ai' u'agil' u'accid' u'align' u'absorb' u'adhd'\n",
      " u'alert' u'afp' u'abstract' u'alga' u'absorpt' u'abandon' u'abrupt' u'aec'\n",
      " u'aerial' u'ace' u'abil' u'acoust' u'achiev' u'algal' u'acquisit'\n",
      " u'action' u'advertis' u'account' u'adventur' u'address' u'act' u'actor'\n",
      " u'affili' u'actual' u'activex' u'acq' u'ad' u'acr' u'absolut' u'adc'\n",
      " u'adapt' u'acupunctur' u'activ' u'add' u'actuat' u'ada' u'acronym']\n"
     ]
    }
   ],
   "source": [
    "#print(v)\n",
    "prob = clf.predict_proba(v)\n",
    "print(prob.shape)\n",
    "Max = 0\n",
    "for i,x in enumerate(prob[0,:]):\n",
    "    if(x > 0.0001):\n",
    "#        print(i,x)\n",
    "        if(x > Max):\n",
    "            Max = x\n",
    "            index = i\n",
    "    \n",
    "print(\"Max\",Max,index,vectorizer.get_feature_names()[index])\n",
    "for word in np.argsort(prob):\n",
    "    print(word,feature_names[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base\n",
      "model\n",
      "simulator\n",
      "test\n",
      "격자\n",
      "계산\n",
      "관계식\n",
      "국방\n",
      "국토\n",
      "도움\n",
      "반사량\n",
      "비교\n",
      "시뮬레이터\n",
      "재질\n",
      "판독\n"
     ]
    }
   ],
   "source": [
    "\n",
    "table = pd.DataFrame(test_dtm.toarray())\n",
    "s = pd.Series([45])\n",
    "problems = pd.DataFrame()\n",
    "f_names = pd.Series(vectorizer.get_feature_names())\n",
    "for i,v in enumerate(s):\n",
    "    problems = problems.append(table.loc[s[i], table.loc[s[i]]>0],ignore_index = True)\n",
    "vocab = problems.T\n",
    "vocab['meaning']= f_names[vocab.index]\n",
    "fn_list = f_names.tolist()\n",
    "#vocab['meaning']= vocab['meaning'].apply(lambda x: x.encode(encoding='utf-8',errors=\"ignore\"))\n",
    "vocab = vocab[vocab[0]>0.1]\n",
    "#display(vocab)\n",
    "\n",
    "for i,x in enumerate(vocab['meaning']):\n",
    "    if x in black_list:\n",
    "        #print(\"Black L found\",i,x)\n",
    "        print(x)\n",
    "\n",
    "for i,x in enumerate(vocab['meaning']):\n",
    "    if x in white_list:\n",
    "        print(\"White L found\",i,x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc: (\n",
    "        english_stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame(train_dtm.toarray())\n",
    "s = pd.Series([59,60,61,62,63,64,65])\n",
    "problems = pd.DataFrame()\n",
    "f_names = pd.Series(vectorizer.get_feature_names())\n",
    "for i in range(6):\n",
    "    problems = problems.append(table.loc[s[i], table.loc[s[i]]>0],ignore_index = True)\n",
    "vocab = problems.T\n",
    "vocab['meaning']= f_names[vocab.index]\n",
    "fn_list = f_names.tolist()\n",
    "#vocab['meaning']= vocab['meaning'].apply(lambda x: x.encode('utf-8'))\n",
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
